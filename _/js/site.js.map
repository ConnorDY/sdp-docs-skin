{"version":3,"sources":["00-nav.js","03-page-versions.js","04-mobile-navbar.js","05-highlight.js","06-clipboard.js","07-on-this-page.js","08-lunr.js","09-search.js"],"names":["mdc","topAppBar","MDCTopAppBar","attachTo","document","querySelector","select","querySelectorAll","i","length","s","addEventListener","event","component","this","getAttribute","showSelector","options","selectedIndex","value","hideSelector","navShow","navHide","classList","remove","add","disabled","x","ripple","MDCRipple","item","target","panel","parentElement","nextElementSibling","contains","navToggle","getElementById","iconButton","MDCIconButtonToggle","mainContainer","navContainer","toggle","selector","e","stopPropagation","documentElement","window","innerWidth","navbarToggles","Array","prototype","slice","call","forEach","el","dataset","hljs","initHighlighting","codeBlocks","copyIcon","createElement","innerText","icon","cloneNode","insertBefore","childNodes","ClipboardJS","text","lines","parentNode","split","splice","join","on","trigger","_tippy","setContent","tippy","delegate","content","animation","theme","delay","placement","hideOnClick","onHidden","instance","headers","toc","header","li","tagName","setAttribute","h","id","scroll","top","offsetTop","left","behavior","setTimeout","appendChild","referenceElement","activeHeader","lastActiveHeader","referencePoint","getBoundingClientRect","activeId","global","step2list","step3list","v","C","re_mgr0","re_mgr1","re_meq1","re_s_v","re_1a","re2_1a","re_1b","re2_1b","re_1b_2","re2_1b_2","re3_1b_2","re4_1b_2","re_1c","re_2","re_3","re_4","re2_4","re_5","re_5_1","re3_5","root","factory","lunr","config","builder","Builder","pipeline","trimmer","stopWordFilter","stemmer","searchPipeline","build","porterStemmer","w","stem","suffix","firstch","re","re2","re3","re4","substr","toUpperCase","test","replace","fp","exec","toLowerCase","version","utils","warn","message","console","asString","obj","toString","clone","Object","create","keys","key","val","isArray","TypeError","FieldRef","docRef","fieldName","stringValue","_stringValue","joiner","fromString","n","indexOf","fieldRef","undefined","Set","elements","complete","intersect","other","union","empty","object","a","b","intersection","element","push","concat","idf","posting","documentCount","documentsWithTerm","Math","log","abs","Token","str","metadata","update","fn","tokenizer","map","t","trim","len","tokens","sliceEnd","sliceStart","sliceLength","charAt","match","separator","tokenMetadata","Pipeline","_stack","registeredFunctions","registerFunction","label","warnIfFunctionNotRegistered","load","serialised","fnName","Error","arguments","after","existingFn","newFn","pos","before","run","stackLength","memo","j","result","k","runString","token","reset","toJSON","Vector","_magnitude","positionForIndex","index","start","end","pivotPoint","floor","pivotIndex","insert","insertIdx","upsert","position","magnitude","sumOfSquares","elementsLength","sqrt","dot","otherVector","dotProduct","aLen","bLen","aVal","bVal","similarity","toArray","output","ational","tional","enci","anci","izer","bli","alli","entli","eli","ousli","ization","ation","ator","alism","iveness","fulness","ousness","aliti","iviti","biliti","logi","icate","ative","alize","iciti","ical","ful","ness","c","RegExp","generateStopWordFilter","stopWords","words","reduce","stopWord","TokenSet","final","edges","_nextId","fromArray","arr","finish","fromClause","clause","fromFuzzyString","term","editDistance","stack","node","editsRemaining","noEditNode","char","deletionNode","frame","pop","substitutionNode","insertionNode","transposeNode","charA","charB","next","prefix","edge","_str","labels","sort","qNode","qEdges","qLen","nEdges","nLen","q","qEdge","nEdge","previousWord","uncheckedNodes","minimizedNodes","word","commonPrefix","minimize","child","nextNode","parent","downTo","childKey","Index","attrs","invertedIndex","fieldVectors","tokenSet","fields","search","queryString","query","QueryParser","parse","Query","matchingFields","queryVectors","termFieldCache","requiredMatches","prohibitedMatches","clauses","terms","clauseMatches","usePipeline","m","termTokenSet","expandedTerms","presence","REQUIRED","field","expandedTerm","termIndex","_index","fieldPosting","matchingDocumentRefs","termField","matchingDocumentsSet","PROHIBITED","boost","l","fieldMatch","matchingDocumentRef","matchingFieldRef","MatchData","allRequiredMatches","allProhibitedMatches","matchingFieldRefs","results","matches","isNegated","docMatch","fieldVector","score","matchData","combine","ref","serializedIndex","serializedVectors","serializedInvertedIndex","tokenSetBuilder","tuple","_ref","_fields","_documents","fieldTermFrequencies","fieldLengths","_b","_k1","metadataWhitelist","attributes","RangeError","number","k1","doc","extractor","fieldTerms","metadataKey","calculateAverageFieldLengths","fieldRefs","numberOfFields","accumulator","documentsWithField","averageFieldLength","createFieldVectors","fieldRefsLength","termIdfCache","fieldLength","termFrequencies","termsLength","fieldBoost","docBoost","scoreWithPrecision","tf","round","createTokenSet","use","args","unshift","apply","clonedMetadata","metadataKeys","otherMatchData","allFields","wildcard","String","NONE","LEADING","TRAILING","OPTIONAL","QueryParseError","name","QueryLexer","lexemes","escapeCharPositions","state","lexText","sliceString","subSlices","emit","type","escapeCharacter","EOS","width","ignore","backup","acceptDigitRun","charCode","charCodeAt","more","FIELD","TERM","EDIT_DISTANCE","BOOST","PRESENCE","lexField","lexer","lexTerm","lexEditDistance","lexBoost","lexEOS","termSeparator","currentClause","lexemeIdx","parseClause","peekLexeme","consumeLexeme","lexeme","nextClause","completedClause","parser","parsePresence","parseField","parseTerm","errorMessage","nextLexeme","possibleFields","f","parseEditDistance","parseBoost","parseInt","isNaN","define","amd","exports","module","searchButton","searchCancelButton","searchClearButton","clearSearch","searchInput","dispatchEvent","KeyboardEvent","enterOrSpacebarPressed","code","keyCode","which","toggleSearch","searchResult","toolbarContainer","regularTopBar","searchTopBar","antoraLunr","body","highlightText","hits","highlightSpan","textEnd","contextAfter","contextBefore","createTextNode","highlightTitle","hash","title","titles","filter","titleEnd","createSearchResult","store","searchResultDataset","url","includes","substring","positions","highlightHit","documentTitle","documentHit","documentHitLink","href","hit","searchResultItem","createSearchResultItem","searchIndex","firstChild","removeChild","createNoResult","init","data","func","wait","immediate","timeout","assign","context","callNow","clearTimeout"],"mappings":"CAAA,WACA,aAGAA,IAAAC,UAAAC,aAAAC,SAAAC,SAAAC,cAAA,qBAKA,IADA,IAAAC,EAAAF,SAAAG,iBAAA,mBACAC,EAAA,EAAAA,EAAAF,EAAAG,OAAAD,IAAA,CACA,IAAAE,EAAAJ,EAAAE,GACAE,EAAAC,iBAAA,SAAA,SAAAC,GACA,IAAAC,EAAAC,KAAAC,aAAA,kBAEAC,EAAA,sCAAAH,EAAA,oBADAC,KAAAG,QAAAH,KAAAI,eAAAC,MACA,KACAC,EAAA,sCAAAP,EAAA,gBACAQ,EAAAjB,SAAAC,cAAAW,GACAM,EAAAlB,SAAAC,cAAAe,GACAC,EAAAE,UAAAC,OAAA,QACAF,EAAAC,UAAAE,IAAA,UAIA,IAAAf,EAAAO,QAAAR,SACAC,EAAAa,UAAAE,IAAA,kBACAf,EAAAgB,UAAA,GAKA,IAAAC,EAAAvB,SAAAG,iBAAA,6BACA,IAAAC,EAAA,EAAAA,EAAAmB,EAAAlB,OAAAD,IACAR,IAAA4B,OAAAC,UAAA1B,SAAAwB,EAAAnB,IACAmB,EAAAnB,GAAAG,iBAAA,QAAA,SAAAC,GACA,IAAAkB,EAAAlB,EAAAmB,OACAC,EAAAF,EAAAG,cAAAC,mBACAJ,EAAAP,UAAAY,SAAA,aACAL,EAAAP,UAAAC,OAAA,YACAQ,EAAAT,UAAAE,IAAA,UAEAK,EAAAP,UAAAE,IAAA,YACAO,EAAAT,UAAAC,OAAA,WAMA,IAAAY,EAAAhC,SAAAiC,eAAA,sBACArC,IAAAsC,WAAAC,oBAAApC,SAAAiC,GACAA,EAAAzB,iBAAA,QAAA,WAEA,IAAA6B,EAAApC,SAAAC,cAAA,QACAoC,EAAArC,SAAAC,cAAA,qBACAoC,EAAAlB,UAAAY,SAAA,SACAK,EAAAjB,UAAAE,IAAA,QACAgB,EAAAlB,UAAAC,OAAA,UAGAgB,EAAAjB,UAAAC,OAAA,QACAiB,EAAAlB,UAAAE,IAAA,WA3DA,GCAA,WACA,aAEA,IAAAiB,EAAAtC,SAAAC,cAAA,uCACA,GAAAqC,EAAA,CAEA,IAAAC,EAAAvC,SAAAC,cAAA,kBAEAqC,EAAA/B,iBAAA,QAAA,SAAAiC,GACAD,EAAApB,UAAAmB,OAAA,aAEAE,EAAAC,oBAGAzC,SAAA0C,gBAAAnC,iBAAA,QAAA,WACAgC,EAAApB,UAAAC,OAAA,gBAfA,GCAApB,SAAAO,iBAAA,mBAAA,WAEAoC,OAAAC,YAAA,MACA5C,SAAAC,cAAA,qBACAkB,UAAAE,IAAA,QAIA,IAAAwB,EAAAC,MAAAC,UAAAC,MAAAC,KAAAjD,SAAAG,iBAAA,kBAAA,GACA,IAAA0C,EAAAxC,QACAwC,EAAAK,QAAA,SAAAC,GACAA,EAAA5C,iBAAA,QAAA,SAAAiC,GACAA,EAAAC,kBACAU,EAAAhC,UAAAmB,OAAA,aACAtC,SAAAiC,eAAAkB,EAAAC,QAAAzB,QAAAR,UAAAmB,OAAA,aACAtC,SAAA0C,gBAAAvB,UAAAmB,OAAA,4BAMAK,OAAApC,iBAAA,SAAA,WAGA,GADAP,SAAAC,cAAA,iDACAkB,UAAAY,SAAA,QAAA,CAEA,IAAAK,EAAApC,SAAAC,cAAA,QACAmC,EAAAjB,UAAAY,SAAA,SACAK,EAAAjB,UAAAC,OAAA,QAIA,IAAAiB,EAAArC,SAAAC,cAAA,qBACA,KAAA0C,OAAAC,YACAP,EAAAlB,UAAAY,SAAA,SACAM,EAAAlB,UAAAC,OAAA,QAMAuB,OAAAC,WAAA,OACAP,EAAAlB,UAAAY,SAAA,SACAM,EAAAlB,UAAAE,IAAA,WCzCAgC,KAAAC,mBCFA,WACA,aAEA,IAAAC,EAAAvD,SAAAG,iBAAA,2BACAqD,EAAAxD,SAAAyD,cAAA,KACAD,EAAArC,UAAA,gCACAqC,EAAAE,UAAA,YACA,IAAA,IAAAtD,EAAA,EAAAA,EAAAmD,EAAAlD,OAAAD,IAAA,CACA,IAAAuD,EAAAH,EAAAI,WAAA,GACAL,EAAAnD,GAAAyD,aAAAF,EAAAJ,EAAAnD,GAAA0D,WAAA,IAIA,IAAAC,YAAA,iCAAA,CACAC,KAAA,SAAArC,GACA,IAAAsC,EAAAtC,EAAAuC,WAAAR,UAAAS,MAAA,MAEA,OADAF,EAAAG,OAAA,EAAA,GACAH,EAAAI,KAAA,SAIAC,GAAA,UAAA,SAAA9B,GACAA,EAAA+B,QAAAC,OAAAC,WAAA,aAGAC,MAAAC,SAAA,0BAAA,CACAhD,OAAA,iCACAiD,QAAA,oBACAC,UAAA,aACAC,MAAA,YACAC,MAAA,CAAA,IAAA,GACAC,UAAA,SACAC,aAAA,EACAC,SAAA,SAAAC,GACAA,EAAAV,WAAA,wBAlCA,GCAA,WACA,aAKA,IAFA,IAAAW,EAAApF,SAAAC,cAAA,kBAAAE,iBAAA,0BACAkF,EAAArF,SAAAiC,eAAA,OACA7B,EAAA,EAAAA,EAAAgF,EAAA/E,OAAAD,IAAA,CACA,IAAAkF,EAAAF,EAAAhF,GACAmF,EAAAvF,SAAAyD,cAAA,MACA8B,EAAApE,UAAAE,IAAA,YACAkE,EAAApE,UAAAE,IAAAiE,EAAAE,SACAD,EAAA7B,UAAA4B,EAAA5B,UACA6B,EAAAE,aAAA,WAAAH,EAAA3E,aAAA,OACA4E,EAAAhF,iBAAA,QAAA,WACA,IAAAmF,EAAAC,EAAAjF,KAAAC,aAAA,YACA+E,EAAA,QAAAC,EAAA3F,SAAAiC,eAAA0D,GACA3F,SAAAC,cAAA,MACA0C,OAAAiD,OAAA,CACAC,IAAAH,EAAAI,UAAA,GACAC,KAAA,EACAC,SAAA,WAEAN,EAAAvE,UAAAE,IAAA,iBACA4E,WAAA,WAAAP,EAAAvE,UAAAC,OAAA,kBAAA,OAEAiE,EAAAa,YAAAX,GAIA,IAAAY,EAAAnG,SAAAC,cAAA,WAAAiE,WACAvB,OAAApC,iBAAA,SAAA,WAGA,IAFA,IAAA6F,EAAAC,EAAArG,SAAAC,cAAA,oBACAqG,EAAAH,EAAAL,UAAA,MACA1F,EAAAgF,EAAA/E,OAAA,EAAA,GAAAD,EAAAA,IAAA,CAEA,GADAgF,EAAAhF,GAAAmG,wBAAAV,IACAS,EAAA,CACA,IAAAE,EAAApB,EAAAhF,GAAAO,aAAA,MACAyF,EAAApG,SAAAC,cAAA,uBAAAuG,EAAA,MACA,OAKAJ,GAAAA,IAAAC,IACAD,EAAAjF,UAAAE,IAAA,UACAgF,GACAA,EAAAlF,UAAAC,OAAA,aA9CA,GCMA,WAiCA,IAoCAqF,EAw2BAC,EAwBAC,EAWAC,EACAC,EAQAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EAEAC,EAEAC,EACAC,EAEAC,EACAC,EACAC,EA64EAC,EAAAC,EA71GAC,EAAA,SAAAC,GACA,IAAAC,EAAA,IAAAF,EAAAG,QAaA,OAXAD,EAAAE,SAAAnH,IACA+G,EAAAK,QACAL,EAAAM,eACAN,EAAAO,SAGAL,EAAAM,eAAAvH,IACA+G,EAAAO,SAGAN,EAAApF,KAAAqF,EAAAA,GACAA,EAAAO,SAo8BA,SAAAC,EAAAC,GACA,IAAAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAEA,GAAAP,EAAA1I,OAAA,EAAA,OAAA0I,EAiBA,GAdA,MADAG,EAAAH,EAAAQ,OAAA,EAAA,MAEAR,EAAAG,EAAAM,cAAAT,EAAAQ,OAAA,IAKAH,EAAAjC,GADAgC,EAAAjC,GAGAuC,KAAAV,GAAAA,EAAAA,EAAAW,QAAAP,EAAA,QACAC,EAAAK,KAAAV,KAAAA,EAAAA,EAAAW,QAAAN,EAAA,SAIAA,EAAA/B,GADA8B,EAAA/B,GAEAqC,KAAAV,GAAA,CACA,IAAAY,EAAAR,EAAAS,KAAAb,IACAI,EAAArC,GACA2C,KAAAE,EAAA,MACAR,EAAA7B,EACAyB,EAAAA,EAAAW,QAAAP,EAAA,UAEA,GAAAC,EAAAK,KAAAV,GAAA,CAEAC,GADAW,EAAAP,EAAAQ,KAAAb,IACA,IACAK,EAAAnC,GACAwC,KAAAT,KAGAK,EAAA7B,EACA8B,EAAA7B,GAFA2B,EAAA7B,GAGAkC,KAJAV,EAAAC,GAIAD,GAAA,IACAM,EAAAI,KAAAV,IAAAI,EAAA7B,EAAAyB,EAAAA,EAAAW,QAAAP,EAAA,KACAG,EAAAG,KAAAV,KAAAA,GAAA,MAuCA,IAlCAI,EAAAzB,GACA+B,KAAAV,KAGAA,GADAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,IACA,MAIAI,EAAAxB,GACA8B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GACAE,EAAAU,EAAA,IACAR,EAAArC,GACA2C,KAAAT,KACAD,EAAAC,EAAAtC,EAAAuC,MAKAE,EAAAvB,GACA6B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GACAE,EAAAU,EAAA,IACAR,EAAArC,GACA2C,KAAAT,KACAD,EAAAC,EAAArC,EAAAsC,KAMAG,EAAAtB,GADAqB,EAAAtB,GAEA4B,KAAAV,GAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,IACAI,EAAApC,GACA0C,KAAAT,KACAD,EAAAC,QAEA,GAAAI,EAAAK,KAAAV,GAAA,CAEAC,GADAW,EAAAP,EAAAQ,KAAAb,IACA,GAAAY,EAAA,IACAP,EAAArC,GACA0C,KAAAT,KACAD,EAAAC,GA8BA,OAzBAG,EAAApB,GACA0B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GAEAK,EAAApC,EACAqC,EAAApB,IAFAkB,EAAApC,GAGA0C,KAAAT,IAAAI,EAAAK,KAAAT,KAAAK,EAAAI,KAAAT,MACAD,EAAAC,IAKAI,EAAArC,GADAoC,EAAAnB,GAEAyB,KAAAV,IAAAK,EAAAK,KAAAV,KACAI,EAAA7B,EACAyB,EAAAA,EAAAW,QAAAP,EAAA,KAKA,KAAAD,IACAH,EAAAG,EAAAW,cAAAd,EAAAQ,OAAA,IAGAR,EA9jCAX,EAAA0B,QAAA,QAUA1B,EAAA2B,MAAA,GASA3B,EAAA2B,MAAAC,MAAAvD,EAQA/F,KANA,SAAAuJ,GACAxD,EAAAyD,SAAAA,QAAAF,MACAE,QAAAF,KAAAC,KAiBA7B,EAAA2B,MAAAI,SAAA,SAAAC,GACA,OAAAA,MAAAA,EACA,GAEAA,EAAAC,YAoBAjC,EAAA2B,MAAAO,MAAA,SAAAF,GACA,GAAAA,MAAAA,EACA,OAAAA,EAMA,IAHA,IAAAE,EAAAC,OAAAC,OAAA,MACAC,EAAAF,OAAAE,KAAAL,GAEAhK,EAAA,EAAAA,EAAAqK,EAAApK,OAAAD,IAAA,CACA,IAAAsK,EAAAD,EAAArK,GACAuK,EAAAP,EAAAM,GAEA,GAAA5H,MAAA8H,QAAAD,GACAL,EAAAI,GAAAC,EAAA3H,YADA,CAKA,GAAA,iBAAA2H,GACA,iBAAAA,GACA,kBAAAA,EAKA,MAAA,IAAAE,UAAA,yDAJAP,EAAAI,GAAAC,GAOA,OAAAL,GAEAlC,EAAA0C,SAAA,SAAAC,EAAAC,EAAAC,GACAvK,KAAAqK,OAAAA,EACArK,KAAAsK,UAAAA,EACAtK,KAAAwK,aAAAD,GAGA7C,EAAA0C,SAAAK,OAAA,IAEA/C,EAAA0C,SAAAM,WAAA,SAAA9K,GACA,IAAA+K,EAAA/K,EAAAgL,QAAAlD,EAAA0C,SAAAK,QAEA,IAAA,IAAAE,EACA,KAAA,6BAGA,IAAAE,EAAAjL,EAAA0C,MAAA,EAAAqI,GACAN,EAAAzK,EAAA0C,MAAAqI,EAAA,GAEA,OAAA,IAAAjD,EAAA0C,SAAAC,EAAAQ,EAAAjL,IAGA8H,EAAA0C,SAAA/H,UAAAsH,SAAA,WAKA,OAJAmB,MAAA9K,KAAAwK,eACAxK,KAAAwK,aAAAxK,KAAAsK,UAAA5C,EAAA0C,SAAAK,OAAAzK,KAAAqK,QAGArK,KAAAwK,cAYA9C,EAAAqD,IAAA,SAAAC,GAGA,GAFAhL,KAAAgL,SAAAnB,OAAAC,OAAA,MAEAkB,EAAA,CACAhL,KAAAL,OAAAqL,EAAArL,OAEA,IAAA,IAAAD,EAAA,EAAAA,EAAAM,KAAAL,OAAAD,IACAM,KAAAgL,SAAAA,EAAAtL,KAAA,OAGAM,KAAAL,OAAA,GAWA+H,EAAAqD,IAAAE,SAAA,CACAC,UAAA,SAAAC,GACA,OAAAA,GAGAC,MAAA,SAAAD,GACA,OAAAA,GAGA9J,SAAA,WACA,OAAA,IAWAqG,EAAAqD,IAAAM,MAAA,CACAH,UAAA,WACA,OAAAlL,MAGAoL,MAAA,SAAAD,GACA,OAAAA,GAGA9J,SAAA,WACA,OAAA,IAUAqG,EAAAqD,IAAA1I,UAAAhB,SAAA,SAAAiK,GACA,QAAAtL,KAAAgL,SAAAM,IAWA5D,EAAAqD,IAAA1I,UAAA6I,UAAA,SAAAC,GACA,IAAAI,EAAAC,EAAAR,EAAAS,EAAA,GAEA,GAAAN,IAAAzD,EAAAqD,IAAAE,SACA,OAAAjL,KAGA,GAAAmL,IAAAzD,EAAAqD,IAAAM,MACA,OAAAF,EAKAK,EAFAxL,KAAAL,OAAAwL,EAAAxL,QACA4L,EAAAvL,KACAmL,IAEAI,EAAAJ,EACAnL,MAGAgL,EAAAnB,OAAAE,KAAAwB,EAAAP,UAEA,IAAA,IAAAtL,EAAA,EAAAA,EAAAsL,EAAArL,OAAAD,IAAA,CACA,IAAAgM,EAAAV,EAAAtL,GACAgM,KAAAF,EAAAR,UACAS,EAAAE,KAAAD,GAIA,OAAA,IAAAhE,EAAAqD,IAAAU,IAUA/D,EAAAqD,IAAA1I,UAAA+I,MAAA,SAAAD,GACA,OAAAA,IAAAzD,EAAAqD,IAAAE,SACAvD,EAAAqD,IAAAE,SAGAE,IAAAzD,EAAAqD,IAAAM,MACArL,KAGA,IAAA0H,EAAAqD,IAAAlB,OAAAE,KAAA/J,KAAAgL,UAAAY,OAAA/B,OAAAE,KAAAoB,EAAAH,aAUAtD,EAAAmE,IAAA,SAAAC,EAAAC,GACA,IAAAC,EAAA,EAEA,IAAA,IAAA1B,KAAAwB,EACA,UAAAxB,IACA0B,GAAAnC,OAAAE,KAAA+B,EAAAxB,IAAA3K,QAGA,IAAAkB,GAAAkL,EAAAC,EAAA,KAAAA,EAAA,IAEA,OAAAC,KAAAC,IAAA,EAAAD,KAAAE,IAAAtL,KAWA6G,EAAA0E,MAAA,SAAAC,EAAAC,GACAtM,KAAAqM,IAAAA,GAAA,GACArM,KAAAsM,SAAAA,GAAA,IAQA5E,EAAA0E,MAAA/J,UAAAsH,SAAA,WACA,OAAA3J,KAAAqM,KAuBA3E,EAAA0E,MAAA/J,UAAAkK,OAAA,SAAAC,GAEA,OADAxM,KAAAqM,IAAAG,EAAAxM,KAAAqM,IAAArM,KAAAsM,UACAtM,MAUA0H,EAAA0E,MAAA/J,UAAAuH,MAAA,SAAA4C,GAEA,OADAA,EAAAA,GAAA,SAAA5M,GAAA,OAAAA,GACA,IAAA8H,EAAA0E,MAAAI,EAAAxM,KAAAqM,IAAArM,KAAAsM,UAAAtM,KAAAsM,WAyBA5E,EAAA+E,UAAA,SAAA/C,EAAA4C,GACA,GAAA,MAAA5C,GAAAoB,MAAApB,EACA,MAAA,GAGA,GAAAtH,MAAA8H,QAAAR,GACA,OAAAA,EAAAgD,IAAA,SAAAC,GACA,OAAA,IAAAjF,EAAA0E,MACA1E,EAAA2B,MAAAI,SAAAkD,GAAAxD,cACAzB,EAAA2B,MAAAO,MAAA0C,MASA,IAJA,IAAAD,EAAA3C,EAAAC,WAAAiD,OAAAzD,cACA0D,EAAAR,EAAA1M,OACAmN,EAAA,GAEAC,EAAA,EAAAC,EAAA,EAAAD,GAAAF,EAAAE,IAAA,CACA,IACAE,EAAAF,EAAAC,EAEA,GAHAX,EAAAa,OAAAH,GAGAI,MAAAzF,EAAA+E,UAAAW,YAAAL,GAAAF,EAAA,CAEA,GAAA,EAAAI,EAAA,CACA,IAAAI,EAAA3F,EAAA2B,MAAAO,MAAA0C,IAAA,GACAe,EAAA,SAAA,CAAAL,EAAAC,GACAI,EAAA,MAAAP,EAAAnN,OAEAmN,EAAAnB,KACA,IAAAjE,EAAA0E,MACAC,EAAA/J,MAAA0K,EAAAD,GACAM,IAKAL,EAAAD,EAAA,GAKA,OAAAD,GAUApF,EAAA+E,UAAAW,UAAA,UAmCA1F,EAAA4F,SAAA,WACAtN,KAAAuN,OAAA,IAGA7F,EAAA4F,SAAAE,oBAAA3D,OAAAC,OAAA,MAmCApC,EAAA4F,SAAAG,iBAAA,SAAAjB,EAAAkB,GACAA,KAAA1N,KAAAwN,qBACA9F,EAAA2B,MAAAC,KAAA,6CAAAoE,GAGAlB,EAAAkB,MAAAA,EACAhG,EAAA4F,SAAAE,oBAAAhB,EAAAkB,OAAAlB,GASA9E,EAAA4F,SAAAK,4BAAA,SAAAnB,GACAA,EAAAkB,OAAAlB,EAAAkB,SAAA1N,KAAAwN,qBAGA9F,EAAA2B,MAAAC,KAAA,kGAAAkD,IAcA9E,EAAA4F,SAAAM,KAAA,SAAAC,GACA,IAAA/F,EAAA,IAAAJ,EAAA4F,SAYA,OAVAO,EAAArL,QAAA,SAAAsL,GACA,IAAAtB,EAAA9E,EAAA4F,SAAAE,oBAAAM,GAEA,IAAAtB,EAGA,MAAA,IAAAuB,MAAA,sCAAAD,GAFAhG,EAAAnH,IAAA6L,KAMA1E,GAUAJ,EAAA4F,SAAAjL,UAAA1B,IAAA,WACAyB,MAAAC,UAAAC,MAAAC,KAAAyL,WAEAxL,QAAA,SAAAgK,GACA9E,EAAA4F,SAAAK,4BAAAnB,GACAxM,KAAAuN,OAAA5B,KAAAa,IACAxM,OAYA0H,EAAA4F,SAAAjL,UAAA4L,MAAA,SAAAC,EAAAC,GACAzG,EAAA4F,SAAAK,4BAAAQ,GAEA,IAAAC,EAAApO,KAAAuN,OAAA3C,QAAAsD,GACA,IAAA,GAAAE,EACA,MAAA,IAAAL,MAAA,0BAGAK,GAAA,EACApO,KAAAuN,OAAA7J,OAAA0K,EAAA,EAAAD,IAYAzG,EAAA4F,SAAAjL,UAAAgM,OAAA,SAAAH,EAAAC,GACAzG,EAAA4F,SAAAK,4BAAAQ,GAEA,IAAAC,EAAApO,KAAAuN,OAAA3C,QAAAsD,GACA,IAAA,GAAAE,EACA,MAAA,IAAAL,MAAA,0BAGA/N,KAAAuN,OAAA7J,OAAA0K,EAAA,EAAAD,IAQAzG,EAAA4F,SAAAjL,UAAA3B,OAAA,SAAA8L,GACA,IAAA4B,EAAApO,KAAAuN,OAAA3C,QAAA4B,IACA,GAAA4B,GAIApO,KAAAuN,OAAA7J,OAAA0K,EAAA,IAUA1G,EAAA4F,SAAAjL,UAAAiM,IAAA,SAAAxB,GAGA,IAFA,IAAAyB,EAAAvO,KAAAuN,OAAA5N,OAEAD,EAAA,EAAAA,EAAA6O,EAAA7O,IAAA,CAIA,IAHA,IAAA8M,EAAAxM,KAAAuN,OAAA7N,GACA8O,EAAA,GAEAC,EAAA,EAAAA,EAAA3B,EAAAnN,OAAA8O,IAAA,CACA,IAAAC,EAAAlC,EAAAM,EAAA2B,GAAAA,EAAA3B,GAEA,QAAA,IAAA4B,GAAA,KAAAA,EAEA,GAAAA,aAAAtM,MACA,IAAA,IAAAuM,EAAA,EAAAA,EAAAD,EAAA/O,OAAAgP,IACAH,EAAA7C,KAAA+C,EAAAC,SAGAH,EAAA7C,KAAA+C,GAIA5B,EAAA0B,EAGA,OAAA1B,GAaApF,EAAA4F,SAAAjL,UAAAuM,UAAA,SAAAvC,EAAAC,GACA,IAAAuC,EAAA,IAAAnH,EAAA0E,MAAAC,EAAAC,GAEA,OAAAtM,KAAAsO,IAAA,CAAAO,IAAAnC,IAAA,SAAAC,GACA,OAAAA,EAAAhD,cAQAjC,EAAA4F,SAAAjL,UAAAyM,MAAA,WACA9O,KAAAuN,OAAA,IAUA7F,EAAA4F,SAAAjL,UAAA0M,OAAA,WACA,OAAA/O,KAAAuN,OAAAb,IAAA,SAAAF,GAGA,OAFA9E,EAAA4F,SAAAK,4BAAAnB,GAEAA,EAAAkB,SAwBAhG,EAAAsH,OAAA,SAAAhE,GACAhL,KAAAiP,WAAA,EACAjP,KAAAgL,SAAAA,GAAA,IAcAtD,EAAAsH,OAAA3M,UAAA6M,iBAAA,SAAAC,GAEA,GAAA,GAAAnP,KAAAgL,SAAArL,OACA,OAAA,EASA,IANA,IAAAyP,EAAA,EACAC,EAAArP,KAAAgL,SAAArL,OAAA,EACAsN,EAAAoC,EAAAD,EACAE,EAAArD,KAAAsD,MAAAtC,EAAA,GACAuC,EAAAxP,KAAAgL,SAAA,EAAAsE,GAEA,EAAArC,IACAuC,EAAAL,IACAC,EAAAE,GAGAH,EAAAK,IACAH,EAAAC,GAGAE,GAAAL,IAIAlC,EAAAoC,EAAAD,EACAE,EAAAF,EAAAnD,KAAAsD,MAAAtC,EAAA,GACAuC,EAAAxP,KAAAgL,SAAA,EAAAsE,GAGA,OAAAE,GAAAL,GAIAA,EAAAK,EAHA,EAAAF,EAOAE,EAAAL,EACA,GAAAG,EAAA,QADA,GAcA5H,EAAAsH,OAAA3M,UAAAoN,OAAA,SAAAC,EAAAzF,GACAjK,KAAA2P,OAAAD,EAAAzF,EAAA,WACA,KAAA,qBAYAvC,EAAAsH,OAAA3M,UAAAsN,OAAA,SAAAD,EAAAzF,EAAAuC,GACAxM,KAAAiP,WAAA,EACA,IAAAW,EAAA5P,KAAAkP,iBAAAQ,GAEA1P,KAAAgL,SAAA4E,IAAAF,EACA1P,KAAAgL,SAAA4E,EAAA,GAAApD,EAAAxM,KAAAgL,SAAA4E,EAAA,GAAA3F,GAEAjK,KAAAgL,SAAAtH,OAAAkM,EAAA,EAAAF,EAAAzF,IASAvC,EAAAsH,OAAA3M,UAAAwN,UAAA,WACA,GAAA7P,KAAAiP,WAAA,OAAAjP,KAAAiP,WAKA,IAHA,IAAAa,EAAA,EACAC,EAAA/P,KAAAgL,SAAArL,OAEAD,EAAA,EAAAA,EAAAqQ,EAAArQ,GAAA,EAAA,CACA,IAAAuK,EAAAjK,KAAAgL,SAAAtL,GACAoQ,GAAA7F,EAAAA,EAGA,OAAAjK,KAAAiP,WAAAhD,KAAA+D,KAAAF,IASApI,EAAAsH,OAAA3M,UAAA4N,IAAA,SAAAC,GAOA,IANA,IAAAC,EAAA,EACA5E,EAAAvL,KAAAgL,SAAAQ,EAAA0E,EAAAlF,SACAoF,EAAA7E,EAAA5L,OAAA0Q,EAAA7E,EAAA7L,OACA2Q,EAAA,EAAAC,EAAA,EACA7Q,EAAA,EAAA+O,EAAA,EAEA/O,EAAA0Q,GAAA3B,EAAA4B,IACAC,EAAA/E,EAAA7L,KAAA6Q,EAAA/E,EAAAiD,IAEA/O,GAAA,EACA6Q,EAAAD,EACA7B,GAAA,EACA6B,GAAAC,IACAJ,GAAA5E,EAAA7L,EAAA,GAAA8L,EAAAiD,EAAA,GACA/O,GAAA,EACA+O,GAAA,GAIA,OAAA0B,GAUAzI,EAAAsH,OAAA3M,UAAAmO,WAAA,SAAAN,GACA,OAAAlQ,KAAAiQ,IAAAC,GAAAlQ,KAAA6P,aAAA,GAQAnI,EAAAsH,OAAA3M,UAAAoO,QAAA,WAGA,IAFA,IAAAC,EAAA,IAAAtO,MAAApC,KAAAgL,SAAArL,OAAA,GAEAD,EAAA,EAAA+O,EAAA,EAAA/O,EAAAM,KAAAgL,SAAArL,OAAAD,GAAA,EAAA+O,IACAiC,EAAAjC,GAAAzO,KAAAgL,SAAAtL,GAGA,OAAAgR,GAQAhJ,EAAAsH,OAAA3M,UAAA0M,OAAA,WACA,OAAA/O,KAAAgL,UAoBAtD,EAAAO,SACAjC,EAAA,CACA2K,QAAA,MACAC,OAAA,OACAC,KAAA,OACAC,KAAA,OACAC,KAAA,MACAC,IAAA,MACAC,KAAA,KACAC,MAAA,MACAC,IAAA,IACAC,MAAA,MACAC,QAAA,MACAC,MAAA,MACAC,KAAA,MACAC,MAAA,KACAC,QAAA,MACAC,QAAA,MACAC,QAAA,MACAC,MAAA,KACAC,MAAA,MACAC,OAAA,MACAC,KAAA,OAGA9L,EAAA,CACA+L,MAAA,KACAC,MAAA,GACAC,MAAA,KACAC,MAAA,KACAC,KAAA,KACAC,IAAA,GACAC,KAAA,IAIApM,EAAA,WACAC,EAAAoM,qBAQAnM,EAAA,IAAAoM,OALA,4DAMAnM,EAAA,IAAAmM,OAJA,8FAKAlM,EAAA,IAAAkM,OANA,gFAOAjM,EAAA,IAAAiM,OALA,kCAOAhM,EAAA,kBACAC,EAAA,iBACAC,EAAA,aACAC,EAAA,kBACAC,EAAA,KACAC,EAAA,cACAC,EAAA,IAAA0L,OAAA,sBACAzL,EAAA,IAAAyL,OAAA,IAAArM,EAAAD,EAAA,gBAEAc,EAAA,mBACAC,EAAA,2IAEAC,EAAA,iDAEAC,EAAA,sFACAC,EAAA,oBAEAC,EAAA,WACAC,EAAA,MACAC,EAAA,IAAAiL,OAAA,IAAArM,EAAAD,EAAA,gBAkIA,SAAA2I,GACA,OAAAA,EAAAtC,OAAAnE,KAIAV,EAAA4F,SAAAG,iBAAA/F,EAAAO,QAAA,WAmBAP,EAAA+K,uBAAA,SAAAC,GACA,IAAAC,EAAAD,EAAAE,OAAA,SAAApE,EAAAqE,GAEA,OADArE,EAAAqE,GAAAA,EACArE,GACA,IAEA,OAAA,SAAAK,GACA,GAAAA,GAAA8D,EAAA9D,EAAAlF,cAAAkF,EAAAlF,WAAA,OAAAkF,IAiBAnH,EAAAM,eAAAN,EAAA+K,uBAAA,CACA,IACA,OACA,QACA,SACA,QACA,MACA,SACA,OACA,KACA,QACA,KACA,MACA,MACA,MACA,KACA,KACA,KACA,UACA,OACA,MACA,KACA,MACA,SACA,QACA,OACA,MACA,KACA,OACA,SACA,OACA,OACA,QACA,MACA,OACA,MACA,MACA,MACA,MACA,OACA,KACA,MACA,OACA,MACA,MACA,MACA,UACA,IACA,KACA,KACA,OACA,KACA,KACA,MACA,OACA,QACA,MACA,OACA,SACA,MACA,KACA,QACA,OACA,OACA,KACA,UACA,KACA,MACA,MACA,KACA,MACA,QACA,KACA,OACA,KACA,QACA,MACA,MACA,SACA,OACA,MACA,OACA,MACA,SACA,QACA,KACA,OACA,OACA,OACA,MACA,QACA,OACA,OACA,QACA,QACA,OACA,OACA,MACA,KACA,MACA,OACA,KACA,QACA,MACA,KACA,OACA,OACA,OACA,QACA,QACA,QACA,MACA,OACA,MACA,OACA,OACA,QACA,MACA,MACA,SAGA/K,EAAA4F,SAAAG,iBAAA/F,EAAAM,eAAA,kBAqBAN,EAAAK,QAAA,SAAA8G,GACA,OAAAA,EAAAtC,OAAA,SAAA3M,GACA,OAAAA,EAAAoJ,QAAA,OAAA,IAAAA,QAAA,OAAA,OAIAtB,EAAA4F,SAAAG,iBAAA/F,EAAAK,QAAA,WA2BAL,EAAAoL,SAAA,WACA9S,KAAA+S,OAAA,EACA/S,KAAAgT,MAAA,GACAhT,KAAAiF,GAAAyC,EAAAoL,SAAAG,QACAvL,EAAAoL,SAAAG,SAAA,GAWAvL,EAAAoL,SAAAG,QAAA,EASAvL,EAAAoL,SAAAI,UAAA,SAAAC,GAGA,IAFA,IAAAvL,EAAA,IAAAF,EAAAoL,SAAAjL,QAEAnI,EAAA,EAAAmN,EAAAsG,EAAAxT,OAAAD,EAAAmN,EAAAnN,IACAkI,EAAA6H,OAAA0D,EAAAzT,IAIA,OADAkI,EAAAwL,SACAxL,EAAAJ,MAYAE,EAAAoL,SAAAO,WAAA,SAAAC,GACA,MAAA,iBAAAA,EACA5L,EAAAoL,SAAAS,gBAAAD,EAAAE,KAAAF,EAAAG,cAEA/L,EAAAoL,SAAApI,WAAA4I,EAAAE,OAmBA9L,EAAAoL,SAAAS,gBAAA,SAAAlH,EAAAoH,GASA,IARA,IAAAjM,EAAA,IAAAE,EAAAoL,SAEAY,EAAA,CAAA,CACAC,KAAAnM,EACAoM,eAAAH,EACApH,IAAAA,IAGAqH,EAAA/T,QAAA,CACA,IAKAkU,EAwBAC,EACAC,EA9BAC,EAAAN,EAAAO,MAGA,GAAA,EAAAD,EAAA3H,IAAA1M,QACAmU,EAAAE,EAAA3H,IAAAa,OAAA,MAGA8G,EAAAL,KAAAX,MACAa,EAAAG,EAAAL,KAAAX,MAAAc,IAEAD,EAAA,IAAAnM,EAAAoL,SACAkB,EAAAL,KAAAX,MAAAc,GAAAD,GAGA,GAAAG,EAAA3H,IAAA1M,OACAkU,EAAAd,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAE,EACAD,eAAAI,EAAAJ,eACAvH,IAAA2H,EAAA3H,IAAA/J,MAAA,KAQA,GAAA,EAAA0R,EAAAJ,gBAAA,EAAAI,EAAA3H,IAAA1M,QACAmU,EAAAE,EAAA3H,IAAAa,OAAA,MAGA8G,EAAAL,KAAAX,MACAe,EAAAC,EAAAL,KAAAX,MAAAc,IAEAC,EAAA,IAAArM,EAAAoL,SACAkB,EAAAL,KAAAX,MAAAc,GAAAC,GAGAC,EAAA3H,IAAA1M,QAAA,EACAoU,EAAAhB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAI,EACAH,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,IAAA/J,MAAA,KAcA,GAPA,EAAA0R,EAAAJ,gBAAA,GAAAI,EAAA3H,IAAA1M,SACAqU,EAAAL,KAAAZ,OAAA,GAMA,EAAAiB,EAAAJ,gBAAA,GAAAI,EAAA3H,IAAA1M,OAAA,CACA,GAAA,MAAAqU,EAAAL,KAAAX,MACA,IAAAkB,EAAAF,EAAAL,KAAAX,MAAA,SACA,CACAkB,EAAA,IAAAxM,EAAAoL,SACAkB,EAAAL,KAAAX,MAAA,KAAAkB,EAGA,GAAAF,EAAA3H,IAAA1M,OACAuU,EAAAnB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAO,EACAN,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,IAAA/J,MAAA,KAOA,GAAA,EAAA0R,EAAAJ,eAAA,CACA,GAAA,MAAAI,EAAAL,KAAAX,MACA,IAAAmB,EAAAH,EAAAL,KAAAX,MAAA,SACA,CACAmB,EAAA,IAAAzM,EAAAoL,SACAkB,EAAAL,KAAAX,MAAA,KAAAmB,EAGA,GAAAH,EAAA3H,IAAA1M,OACAwU,EAAApB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAQ,EACAP,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,MAQA,GAAA,EAAA2H,EAAAJ,gBAAA,EAAAI,EAAA3H,IAAA1M,OAAA,CACA,IAEAyU,EAFAC,EAAAL,EAAA3H,IAAAa,OAAA,GACAoH,EAAAN,EAAA3H,IAAAa,OAAA,GAGAoH,KAAAN,EAAAL,KAAAX,MACAoB,EAAAJ,EAAAL,KAAAX,MAAAsB,IAEAF,EAAA,IAAA1M,EAAAoL,SACAkB,EAAAL,KAAAX,MAAAsB,GAAAF,GAGA,GAAAJ,EAAA3H,IAAA1M,OACAyU,EAAArB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAS,EACAR,eAAAI,EAAAJ,eAAA,EACAvH,IAAAgI,EAAAL,EAAA3H,IAAA/J,MAAA,MAMA,OAAAkF,GAaAE,EAAAoL,SAAApI,WAAA,SAAA2B,GAYA,IAXA,IAAAsH,EAAA,IAAAjM,EAAAoL,SACAtL,EAAAmM,EAUAjU,EAAA,EAAAmN,EAAAR,EAAA1M,OAAAD,EAAAmN,EAAAnN,IAAA,CACA,IAAAoU,EAAAzH,EAAA3M,GACAqT,EAAArT,GAAAmN,EAAA,EAEA,GAAA,KAAAiH,GACAH,EAAAX,MAAAc,GAAAH,GACAZ,MAAAA,MAEA,CACA,IAAAwB,EAAA,IAAA7M,EAAAoL,SACAyB,EAAAxB,MAAAA,EAEAY,EAAAX,MAAAc,GAAAS,EACAZ,EAAAY,GAIA,OAAA/M,GASAE,EAAAoL,SAAAzQ,UAAAoO,QAAA,WAQA,IAPA,IAAAkC,EAAA,GAEAe,EAAA,CAAA,CACAc,OAAA,GACAb,KAAA3T,OAGA0T,EAAA/T,QAAA,CACA,IAAAqU,EAAAN,EAAAO,MACAjB,EAAAnJ,OAAAE,KAAAiK,EAAAL,KAAAX,OACAnG,EAAAmG,EAAArT,OAEAqU,EAAAL,KAAAZ,QAKAiB,EAAAQ,OAAAtH,OAAA,GACAyF,EAAAhH,KAAAqI,EAAAQ,SAGA,IAAA,IAAA9U,EAAA,EAAAA,EAAAmN,EAAAnN,IAAA,CACA,IAAA+U,EAAAzB,EAAAtT,GAEAgU,EAAA/H,KAAA,CACA6I,OAAAR,EAAAQ,OAAA5I,OAAA6I,GACAd,KAAAK,EAAAL,KAAAX,MAAAyB,MAKA,OAAA9B,GAaAjL,EAAAoL,SAAAzQ,UAAAsH,SAAA,WASA,GAAA3J,KAAA0U,KACA,OAAA1U,KAAA0U,KAOA,IAJA,IAAArI,EAAArM,KAAA+S,MAAA,IAAA,IACA4B,EAAA9K,OAAAE,KAAA/J,KAAAgT,OAAA4B,OACA/H,EAAA8H,EAAAhV,OAEAD,EAAA,EAAAA,EAAAmN,EAAAnN,IAAA,CACA,IAAAgO,EAAAiH,EAAAjV,GAGA2M,EAAAA,EAAAqB,EAFA1N,KAAAgT,MAAAtF,GAEAzI,GAGA,OAAAoH,GAaA3E,EAAAoL,SAAAzQ,UAAA6I,UAAA,SAAAM,GAUA,IATA,IAAAkF,EAAA,IAAAhJ,EAAAoL,SACAkB,OAAAlJ,EAEA4I,EAAA,CAAA,CACAmB,MAAArJ,EACAkF,OAAAA,EACAiD,KAAA3T,OAGA0T,EAAA/T,QAAA,CACAqU,EAAAN,EAAAO,MAWA,IALA,IAAAa,EAAAjL,OAAAE,KAAAiK,EAAAa,MAAA7B,OACA+B,EAAAD,EAAAnV,OACAqV,EAAAnL,OAAAE,KAAAiK,EAAAL,KAAAX,OACAiC,EAAAD,EAAArV,OAEAuV,EAAA,EAAAA,EAAAH,EAAAG,IAGA,IAFA,IAAAC,EAAAL,EAAAI,GAEAvK,EAAA,EAAAA,EAAAsK,EAAAtK,IAAA,CACA,IAAAyK,EAAAJ,EAAArK,GAEA,GAAAyK,GAAAD,GAAA,KAAAA,EAAA,CACA,IAAAxB,EAAAK,EAAAL,KAAAX,MAAAoC,GACAP,EAAAb,EAAAa,MAAA7B,MAAAmC,GACApC,EAAAY,EAAAZ,OAAA8B,EAAA9B,MACAwB,OAAAzJ,EAEAsK,KAAApB,EAAAtD,OAAAsC,OAIAuB,EAAAP,EAAAtD,OAAAsC,MAAAoC,IACArC,MAAAwB,EAAAxB,OAAAA,IAMAwB,EAAA,IAAA7M,EAAAoL,UACAC,MAAAA,EACAiB,EAAAtD,OAAAsC,MAAAoC,GAAAb,GAGAb,EAAA/H,KAAA,CACAkJ,MAAAA,EACAnE,OAAA6D,EACAZ,KAAAA,MAOA,OAAAjD,GAEAhJ,EAAAoL,SAAAjL,QAAA,WACA7H,KAAAqV,aAAA,GACArV,KAAAwH,KAAA,IAAAE,EAAAoL,SACA9S,KAAAsV,eAAA,GACAtV,KAAAuV,eAAA,IAGA7N,EAAAoL,SAAAjL,QAAAxF,UAAAoN,OAAA,SAAA+F,GACA,IAAA7B,EACA8B,EAAA,EAEA,GAAAD,EAAAxV,KAAAqV,aACA,MAAA,IAAAtH,MAAA,+BAGA,IAAA,IAAArO,EAAA,EAAAA,EAAA8V,EAAA7V,QAAAD,EAAAM,KAAAqV,aAAA1V,QACA6V,EAAA9V,IAAAM,KAAAqV,aAAA3V,GADAA,IAEA+V,IAGAzV,KAAA0V,SAAAD,GAGA9B,EADA,GAAA3T,KAAAsV,eAAA3V,OACAK,KAAAwH,KAEAxH,KAAAsV,eAAAtV,KAAAsV,eAAA3V,OAAA,GAAAgW,MAGA,IAAAjW,EAAA+V,EAAA/V,EAAA8V,EAAA7V,OAAAD,IAAA,CACA,IAAAkW,EAAA,IAAAlO,EAAAoL,SACAgB,EAAA0B,EAAA9V,GAEAiU,EAAAX,MAAAc,GAAA8B,EAEA5V,KAAAsV,eAAA3J,KAAA,CACAkK,OAAAlC,EACAG,KAAAA,EACA6B,MAAAC,IAGAjC,EAAAiC,EAGAjC,EAAAZ,OAAA,EACA/S,KAAAqV,aAAAG,GAGA9N,EAAAoL,SAAAjL,QAAAxF,UAAA+Q,OAAA,WACApT,KAAA0V,SAAA,IAGAhO,EAAAoL,SAAAjL,QAAAxF,UAAAqT,SAAA,SAAAI,GACA,IAAA,IAAApW,EAAAM,KAAAsV,eAAA3V,OAAA,EAAAmW,GAAApW,EAAAA,IAAA,CACA,IAAAiU,EAAA3T,KAAAsV,eAAA5V,GACAqW,EAAApC,EAAAgC,MAAAhM,WAEAoM,KAAA/V,KAAAuV,eACA5B,EAAAkC,OAAA7C,MAAAW,EAAAG,MAAA9T,KAAAuV,eAAAQ,IAIApC,EAAAgC,MAAAjB,KAAAqB,EAEA/V,KAAAuV,eAAAQ,GAAApC,EAAAgC,OAGA3V,KAAAsV,eAAArB,QAwBAvM,EAAAsO,MAAA,SAAAC,GACAjW,KAAAkW,cAAAD,EAAAC,cACAlW,KAAAmW,aAAAF,EAAAE,aACAnW,KAAAoW,SAAAH,EAAAG,SACApW,KAAAqW,OAAAJ,EAAAI,OACArW,KAAA8H,SAAAmO,EAAAnO,UA0EAJ,EAAAsO,MAAA3T,UAAAiU,OAAA,SAAAC,GACA,OAAAvW,KAAAwW,MAAA,SAAAA,GACA,IAAA9O,EAAA+O,YAAAF,EAAAC,GACAE,WA6BAhP,EAAAsO,MAAA3T,UAAAmU,MAAA,SAAAhK,GAoBA,IAZA,IAAAgK,EAAA,IAAA9O,EAAAiP,MAAA3W,KAAAqW,QACAO,EAAA/M,OAAAC,OAAA,MACA+M,EAAAhN,OAAAC,OAAA,MACAgN,EAAAjN,OAAAC,OAAA,MACAiN,EAAAlN,OAAAC,OAAA,MACAkN,EAAAnN,OAAAC,OAAA,MAOApK,EAAA,EAAAA,EAAAM,KAAAqW,OAAA1W,OAAAD,IACAmX,EAAA7W,KAAAqW,OAAA3W,IAAA,IAAAgI,EAAAsH,OAGAxC,EAAAjK,KAAAiU,EAAAA,GAEA,IAAA9W,EAAA,EAAAA,EAAA8W,EAAAS,QAAAtX,OAAAD,IAAA,CASA,IAAA4T,EAAAkD,EAAAS,QAAAvX,GACAwX,EAAA,KACAC,EAAAzP,EAAAqD,IAAAE,SAGAiM,EADA5D,EAAA8D,YACApX,KAAA8H,SAAA8G,UAAA0E,EAAAE,KAAA,CACA6C,OAAA/C,EAAA+C,SAGA,CAAA/C,EAAAE,MAGA,IAAA,IAAA6D,EAAA,EAAAA,EAAAH,EAAAvX,OAAA0X,IAAA,CACA,IAAA7D,EAAA0D,EAAAG,GAQA/D,EAAAE,KAAAA,EAOA,IAAA8D,EAAA5P,EAAAoL,SAAAO,WAAAC,GACAiE,EAAAvX,KAAAoW,SAAAlL,UAAAoM,GAAA7G,UAQA,GAAA,IAAA8G,EAAA5X,QAAA2T,EAAAkE,WAAA9P,EAAAiP,MAAAa,SAAAC,SAAA,CACA,IAAA,IAAA9I,EAAA,EAAAA,EAAA2E,EAAA+C,OAAA1W,OAAAgP,IAAA,CAEAoI,EADAW,EAAApE,EAAA+C,OAAA1H,IACAjH,EAAAqD,IAAAM,MAGA,MAGA,IAAA,IAAAoD,EAAA,EAAAA,EAAA8I,EAAA5X,OAAA8O,IAKA,CAAA,IAAAkJ,EAAAJ,EAAA9I,GACA3C,EAAA9L,KAAAkW,cAAAyB,GACAC,EAAA9L,EAAA+L,OAEA,IAAAlJ,EAAA,EAAAA,EAAA2E,EAAA+C,OAAA1W,OAAAgP,IAAA,CASA,IACAmJ,EAAAhM,EADA4L,EAAApE,EAAA+C,OAAA1H,IAEAoJ,EAAAlO,OAAAE,KAAA+N,GACAE,EAAAL,EAAA,IAAAD,EACAO,EAAA,IAAAvQ,EAAAqD,IAAAgN,GAoBA,GAbAzE,EAAAkE,UAAA9P,EAAAiP,MAAAa,SAAAC,WACAN,EAAAA,EAAA/L,MAAA6M,QAEAnN,IAAAiM,EAAAW,KACAX,EAAAW,GAAAhQ,EAAAqD,IAAAE,WASAqI,EAAAkE,UAAA9P,EAAAiP,MAAAa,SAAAU,YA4BA,GANArB,EAAAa,GAAA/H,OAAAiI,EAAAtE,EAAA6E,MAAA,SAAA5M,EAAAC,GAAA,OAAAD,EAAAC,KAMAsL,EAAAkB,GAAA,CAIA,IAAA,IAAAI,EAAA,EAAAA,EAAAL,EAAApY,OAAAyY,IAAA,CAOA,IAGAC,EAHAC,EAAAP,EAAAK,GACAG,EAAA,IAAA7Q,EAAA0C,SAAAkO,EAAAZ,GACApL,EAAAwL,EAAAQ,QAGAxN,KAAAuN,EAAAzB,EAAA2B,IACA3B,EAAA2B,GAAA,IAAA7Q,EAAA8Q,UAAAb,EAAAD,EAAApL,GAEA+L,EAAA1X,IAAAgX,EAAAD,EAAApL,GAKAwK,EAAAkB,IAAA,aAnDAlN,IAAAkM,EAAAU,KACAV,EAAAU,GAAAhQ,EAAAqD,IAAAM,OAGA2L,EAAAU,GAAAV,EAAAU,GAAAtM,MAAA6M,KA0DA,GAAA3E,EAAAkE,WAAA9P,EAAAiP,MAAAa,SAAAC,SACA,IAAA9I,EAAA,EAAAA,EAAA2E,EAAA+C,OAAA1W,OAAAgP,IAAA,CAEAoI,EADAW,EAAApE,EAAA+C,OAAA1H,IACAoI,EAAAW,GAAAxM,UAAAiM,IAUA,IAAAsB,EAAA/Q,EAAAqD,IAAAE,SACAyN,EAAAhR,EAAAqD,IAAAM,MAEA,IAAA3L,EAAA,EAAAA,EAAAM,KAAAqW,OAAA1W,OAAAD,IAAA,CACA,IAAAgY,EAEAX,EAFAW,EAAA1X,KAAAqW,OAAA3W,MAGA+Y,EAAAA,EAAAvN,UAAA6L,EAAAW,KAGAV,EAAAU,KACAgB,EAAAA,EAAAtN,MAAA4L,EAAAU,KAIA,IAAAiB,EAAA9O,OAAAE,KAAA6M,GACAgC,EAAA,GACAC,EAAAhP,OAAAC,OAAA,MAYA,GAAA0M,EAAAsC,YAAA,CACAH,EAAA9O,OAAAE,KAAA/J,KAAAmW,cAEA,IAAAzW,EAAA,EAAAA,EAAAiZ,EAAAhZ,OAAAD,IAAA,CACA6Y,EAAAI,EAAAjZ,GAAA,IACAmL,EAAAnD,EAAA0C,SAAAM,WAAA6N,GACA3B,EAAA2B,GAAA,IAAA7Q,EAAA8Q,WAIA,IAAA9Y,EAAA,EAAAA,EAAAiZ,EAAAhZ,OAAAD,IAAA,CASA,IACA2K,GADAQ,EAAAnD,EAAA0C,SAAAM,WAAAiO,EAAAjZ,KACA2K,OAEA,GAAAoO,EAAApX,SAAAgJ,KAIAqO,EAAArX,SAAAgJ,GAAA,CAIA,IAEA0O,EAFAC,EAAAhZ,KAAAmW,aAAAtL,GACAoO,EAAApC,EAAAhM,EAAAP,WAAAkG,WAAAwI,GAGA,QAAAlO,KAAAiO,EAAAF,EAAAxO,IACA0O,EAAAE,OAAAA,EACAF,EAAAG,UAAAC,QAAAvC,EAAA/L,QACA,CACA,IAAAsC,EAAA,CACAiM,IAAA/O,EACA4O,MAAAA,EACAC,UAAAtC,EAAA/L,IAEAgO,EAAAxO,GAAA8C,EACAyL,EAAAjN,KAAAwB,KAOA,OAAAyL,EAAAhE,KAAA,SAAArJ,EAAAC,GACA,OAAAA,EAAAyN,MAAA1N,EAAA0N,SAYAvR,EAAAsO,MAAA3T,UAAA0M,OAAA,WACA,IAAAmH,EAAArM,OAAAE,KAAA/J,KAAAkW,eACAtB,OACAlI,IAAA,SAAA8G,GACA,MAAA,CAAAA,EAAAxT,KAAAkW,cAAA1C,KACAxT,MAEAmW,EAAAtM,OAAAE,KAAA/J,KAAAmW,cACAzJ,IAAA,SAAA0M,GACA,MAAA,CAAAA,EAAApZ,KAAAmW,aAAAiD,GAAArK,WACA/O,MAEA,MAAA,CACAoJ,QAAA1B,EAAA0B,QACAiN,OAAArW,KAAAqW,OACAF,aAAAA,EACAD,cAAAA,EACApO,SAAA9H,KAAA8H,SAAAiH,WAUArH,EAAAsO,MAAApI,KAAA,SAAAyL,GACA,IAAApD,EAAA,GACAE,EAAA,GACAmD,EAAAD,EAAAlD,aACAD,EAAA,GACAqD,EAAAF,EAAAnD,cACAsD,EAAA,IAAA9R,EAAAoL,SAAAjL,QACAC,EAAAJ,EAAA4F,SAAAM,KAAAyL,EAAAvR,UAEAuR,EAAAjQ,SAAA1B,EAAA0B,SACA1B,EAAA2B,MAAAC,KAAA,4EAAA5B,EAAA0B,QAAA,sCAAAiQ,EAAAjQ,QAAA,KAGA,IAAA,IAAA1J,EAAA,EAAAA,EAAA4Z,EAAA3Z,OAAAD,IAAA,CACA,IACA0Z,GADAK,EAAAH,EAAA5Z,IACA,GACAsL,EAAAyO,EAAA,GAEAtD,EAAAiD,GAAA,IAAA1R,EAAAsH,OAAAhE,GAGA,IAAAtL,EAAA,EAAAA,EAAA6Z,EAAA5Z,OAAAD,IAAA,CACA,IAAA+Z,EACAjG,GADAiG,EAAAF,EAAA7Z,IACA,GACAoM,EAAA2N,EAAA,GAEAD,EAAA/J,OAAA+D,GACA0C,EAAA1C,GAAA1H,EAYA,OATA0N,EAAApG,SAEA6C,EAAAI,OAAAgD,EAAAhD,OAEAJ,EAAAE,aAAAA,EACAF,EAAAC,cAAAA,EACAD,EAAAG,SAAAoD,EAAAhS,KACAyO,EAAAnO,SAAAA,EAEA,IAAAJ,EAAAsO,MAAAC,IA+BAvO,EAAAG,QAAA,WACA7H,KAAA0Z,KAAA,KACA1Z,KAAA2Z,QAAA9P,OAAAC,OAAA,MACA9J,KAAA4Z,WAAA/P,OAAAC,OAAA,MACA9J,KAAAkW,cAAArM,OAAAC,OAAA,MACA9J,KAAA6Z,qBAAA,GACA7Z,KAAA8Z,aAAA,GACA9Z,KAAAyM,UAAA/E,EAAA+E,UACAzM,KAAA8H,SAAA,IAAAJ,EAAA4F,SACAtN,KAAAkI,eAAA,IAAAR,EAAA4F,SACAtN,KAAA+L,cAAA,EACA/L,KAAA+Z,GAAA,IACA/Z,KAAAga,IAAA,IACAha,KAAA4X,UAAA,EACA5X,KAAAia,kBAAA,IAeAvS,EAAAG,QAAAxF,UAAA+W,IAAA,SAAAA,GACApZ,KAAA0Z,KAAAN,GAmCA1R,EAAAG,QAAAxF,UAAAqV,MAAA,SAAApN,EAAA4P,GACA,GAAA,KAAAnR,KAAAuB,GACA,MAAA,IAAA6P,WAAA,UAAA7P,EAAA,oCAGAtK,KAAA2Z,QAAArP,GAAA4P,GAAA,IAWAxS,EAAAG,QAAAxF,UAAAmJ,EAAA,SAAA4O,GAEApa,KAAA+Z,GADAK,EAAA,EACA,EACA,EAAAA,EACA,EAEAA,GAWA1S,EAAAG,QAAAxF,UAAAgY,GAAA,SAAAD,GACApa,KAAAga,IAAAI,GAoBA1S,EAAAG,QAAAxF,UAAA1B,IAAA,SAAA2Z,EAAAJ,GACA,IAAA7P,EAAAiQ,EAAAta,KAAA0Z,MACArD,EAAAxM,OAAAE,KAAA/J,KAAA2Z,SAEA3Z,KAAA4Z,WAAAvP,GAAA6P,GAAA,GACAla,KAAA+L,eAAA,EAEA,IAAA,IAAArM,EAAA,EAAAA,EAAA2W,EAAA1W,OAAAD,IAAA,CACA,IAAA4K,EAAA+L,EAAA3W,GACA6a,EAAAva,KAAA2Z,QAAArP,GAAAiQ,UACA7C,EAAA6C,EAAAA,EAAAD,GAAAA,EAAAhQ,GACAwC,EAAA9M,KAAAyM,UAAAiL,EAAA,CACArB,OAAA,CAAA/L,KAEA4M,EAAAlX,KAAA8H,SAAAwG,IAAAxB,GACAjC,EAAA,IAAAnD,EAAA0C,SAAAC,EAAAC,GACAkQ,EAAA3Q,OAAAC,OAAA,MAEA9J,KAAA6Z,qBAAAhP,GAAA2P,EACAxa,KAAA8Z,aAAAjP,GAAA,EAGA7K,KAAA8Z,aAAAjP,IAAAqM,EAAAvX,OAGA,IAAA,IAAA8O,EAAA,EAAAA,EAAAyI,EAAAvX,OAAA8O,IAAA,CACA,IAAA+E,EAAA0D,EAAAzI,GAUA,GARA3D,MAAA0P,EAAAhH,KACAgH,EAAAhH,GAAA,GAGAgH,EAAAhH,IAAA,EAIA1I,MAAA9K,KAAAkW,cAAA1C,GAAA,CACA,IAAA1H,EAAAjC,OAAAC,OAAA,MACAgC,EAAA,OAAA9L,KAAA4X,UACA5X,KAAA4X,WAAA,EAEA,IAAA,IAAAjJ,EAAA,EAAAA,EAAA0H,EAAA1W,OAAAgP,IACA7C,EAAAuK,EAAA1H,IAAA9E,OAAAC,OAAA,MAGA9J,KAAAkW,cAAA1C,GAAA1H,EAIAhB,MAAA9K,KAAAkW,cAAA1C,GAAAlJ,GAAAD,KACArK,KAAAkW,cAAA1C,GAAAlJ,GAAAD,GAAAR,OAAAC,OAAA,OAKA,IAAA,IAAAsO,EAAA,EAAAA,EAAApY,KAAAia,kBAAAta,OAAAyY,IAAA,CACA,IAAAqC,EAAAza,KAAAia,kBAAA7B,GACA9L,EAAAkH,EAAAlH,SAAAmO,GAEA3P,MAAA9K,KAAAkW,cAAA1C,GAAAlJ,GAAAD,GAAAoQ,KACAza,KAAAkW,cAAA1C,GAAAlJ,GAAAD,GAAAoQ,GAAA,IAGAza,KAAAkW,cAAA1C,GAAAlJ,GAAAD,GAAAoQ,GAAA9O,KAAAW,OAYA5E,EAAAG,QAAAxF,UAAAqY,6BAAA,WAOA,IALA,IAAAC,EAAA9Q,OAAAE,KAAA/J,KAAA8Z,cACAc,EAAAD,EAAAhb,OACAkb,EAAA,GACAC,EAAA,GAEApb,EAAA,EAAAA,EAAAkb,EAAAlb,IAAA,CACA,IAAAmL,EAAAnD,EAAA0C,SAAAM,WAAAiQ,EAAAjb,IACAgY,EAAA7M,EAAAP,UAEAwQ,EAAApD,KAAAoD,EAAApD,GAAA,GACAoD,EAAApD,IAAA,EAEAmD,EAAAnD,KAAAmD,EAAAnD,GAAA,GACAmD,EAAAnD,IAAA1X,KAAA8Z,aAAAjP,GAGA,IAAAwL,EAAAxM,OAAAE,KAAA/J,KAAA2Z,SAEA,IAAAja,EAAA,EAAAA,EAAA2W,EAAA1W,OAAAD,IAAA,CACA,IAAA4K,EAAA+L,EAAA3W,GACAmb,EAAAvQ,GAAAuQ,EAAAvQ,GAAAwQ,EAAAxQ,GAGAtK,KAAA+a,mBAAAF,GAQAnT,EAAAG,QAAAxF,UAAA2Y,mBAAA,WAMA,IALA,IAAA7E,EAAA,GACAwE,EAAA9Q,OAAAE,KAAA/J,KAAA6Z,sBACAoB,EAAAN,EAAAhb,OACAub,EAAArR,OAAAC,OAAA,MAEApK,EAAA,EAAAA,EAAAub,EAAAvb,IAAA,CAaA,IAZA,IAAAmL,EAAAnD,EAAA0C,SAAAM,WAAAiQ,EAAAjb,IACA4K,EAAAO,EAAAP,UACA6Q,EAAAnb,KAAA8Z,aAAAjP,GACAmO,EAAA,IAAAtR,EAAAsH,OACAoM,EAAApb,KAAA6Z,qBAAAhP,GACAqM,EAAArN,OAAAE,KAAAqR,GACAC,EAAAnE,EAAAvX,OAGA2b,EAAAtb,KAAA2Z,QAAArP,GAAA6N,OAAA,EACAoD,EAAAvb,KAAA4Z,WAAA/O,EAAAR,QAAA8N,OAAA,EAEA1J,EAAA,EAAAA,EAAA4M,EAAA5M,IAAA,CACA,IAGA5C,EAAAoN,EAAAuC,EAHAhI,EAAA0D,EAAAzI,GACAgN,EAAAL,EAAA5H,GACAoE,EAAA5X,KAAAkW,cAAA1C,GAAAqE,YAGA/M,IAAAoQ,EAAA1H,IACA3H,EAAAnE,EAAAmE,IAAA7L,KAAAkW,cAAA1C,GAAAxT,KAAA+L,eACAmP,EAAA1H,GAAA3H,GAEAA,EAAAqP,EAAA1H,GAGAyF,EAAApN,IAAA7L,KAAAga,IAAA,GAAAyB,IAAAzb,KAAAga,KAAA,EAAAha,KAAA+Z,GAAA/Z,KAAA+Z,IAAAoB,EAAAnb,KAAA+a,mBAAAzQ,KAAAmR,GACAxC,GAAAqC,EACArC,GAAAsC,EACAC,EAAAvP,KAAAyP,MAAA,IAAAzC,GAAA,IAQAD,EAAAvJ,OAAAmI,EAAA4D,GAGArF,EAAAtL,GAAAmO,EAGAhZ,KAAAmW,aAAAA,GAQAzO,EAAAG,QAAAxF,UAAAsZ,eAAA,WACA3b,KAAAoW,SAAA1O,EAAAoL,SAAAI,UACArJ,OAAAE,KAAA/J,KAAAkW,eAAAtB,SAYAlN,EAAAG,QAAAxF,UAAA8F,MAAA,WAKA,OAJAnI,KAAA0a,+BACA1a,KAAAgb,qBACAhb,KAAA2b,iBAEA,IAAAjU,EAAAsO,MAAA,CACAE,cAAAlW,KAAAkW,cACAC,aAAAnW,KAAAmW,aACAC,SAAApW,KAAAoW,SACAC,OAAAxM,OAAAE,KAAA/J,KAAA2Z,SACA7R,SAAA9H,KAAAkI,kBAkBAR,EAAAG,QAAAxF,UAAAuZ,IAAA,SAAApP,GACA,IAAAqP,EAAAzZ,MAAAC,UAAAC,MAAAC,KAAAyL,UAAA,GACA6N,EAAAC,QAAA9b,MACAwM,EAAAuP,MAAA/b,KAAA6b,IAcAnU,EAAA8Q,UAAA,SAAAhF,EAAAkE,EAAApL,GASA,IARA,IAAA0P,EAAAnS,OAAAC,OAAA,MACAmS,EAAApS,OAAAE,KAAAuC,GAAA,IAOA5M,EAAA,EAAAA,EAAAuc,EAAAtc,OAAAD,IAAA,CACA,IAAAsK,EAAAiS,EAAAvc,GACAsc,EAAAhS,GAAAsC,EAAAtC,GAAA1H,QAGAtC,KAAAsM,SAAAzC,OAAAC,OAAA,WAEAgB,IAAA0I,IACAxT,KAAAsM,SAAAkH,GAAA3J,OAAAC,OAAA,MACA9J,KAAAsM,SAAAkH,GAAAkE,GAAAsE,IAaAtU,EAAA8Q,UAAAnW,UAAA8W,QAAA,SAAA+C,GAGA,IAFA,IAAAhF,EAAArN,OAAAE,KAAAmS,EAAA5P,UAEA5M,EAAA,EAAAA,EAAAwX,EAAAvX,OAAAD,IAAA,CACA,IAAA8T,EAAA0D,EAAAxX,GACA2W,EAAAxM,OAAAE,KAAAmS,EAAA5P,SAAAkH,IAEA1I,MAAA9K,KAAAsM,SAAAkH,KACAxT,KAAAsM,SAAAkH,GAAA3J,OAAAC,OAAA,OAGA,IAAA,IAAA2E,EAAA,EAAAA,EAAA4H,EAAA1W,OAAA8O,IAAA,CACA,IAAAiJ,EAAArB,EAAA5H,GACA1E,EAAAF,OAAAE,KAAAmS,EAAA5P,SAAAkH,GAAAkE,IAEA5M,MAAA9K,KAAAsM,SAAAkH,GAAAkE,KACA1X,KAAAsM,SAAAkH,GAAAkE,GAAA7N,OAAAC,OAAA,OAGA,IAAA,IAAA6E,EAAA,EAAAA,EAAA5E,EAAApK,OAAAgP,IAAA,CACA,IAAA3E,EAAAD,EAAA4E,GAEA7D,MAAA9K,KAAAsM,SAAAkH,GAAAkE,GAAA1N,GACAhK,KAAAsM,SAAAkH,GAAAkE,GAAA1N,GAAAkS,EAAA5P,SAAAkH,GAAAkE,GAAA1N,GAEAhK,KAAAsM,SAAAkH,GAAAkE,GAAA1N,GAAAhK,KAAAsM,SAAAkH,GAAAkE,GAAA1N,GAAA4B,OAAAsQ,EAAA5P,SAAAkH,GAAAkE,GAAA1N,QAeAtC,EAAA8Q,UAAAnW,UAAA1B,IAAA,SAAA6S,EAAAkE,EAAApL,GACA,KAAAkH,KAAAxT,KAAAsM,UAGA,OAFAtM,KAAAsM,SAAAkH,GAAA3J,OAAAC,OAAA,WACA9J,KAAAsM,SAAAkH,GAAAkE,GAAApL,GAIA,GAAAoL,KAAA1X,KAAAsM,SAAAkH,GAOA,IAFA,IAAAyI,EAAApS,OAAAE,KAAAuC,GAEA5M,EAAA,EAAAA,EAAAuc,EAAAtc,OAAAD,IAAA,CACA,IAAAsK,EAAAiS,EAAAvc,GAEAsK,KAAAhK,KAAAsM,SAAAkH,GAAAkE,GACA1X,KAAAsM,SAAAkH,GAAAkE,GAAA1N,GAAAhK,KAAAsM,SAAAkH,GAAAkE,GAAA1N,GAAA4B,OAAAU,EAAAtC,IAEAhK,KAAAsM,SAAAkH,GAAAkE,GAAA1N,GAAAsC,EAAAtC,QAZAhK,KAAAsM,SAAAkH,GAAAkE,GAAApL,GA2BA5E,EAAAiP,MAAA,SAAAwF,GACAnc,KAAAiX,QAAA,GACAjX,KAAAmc,UAAAA,GA2BAzU,EAAAiP,MAAAyF,SAAA,IAAAC,OAAA,KACA3U,EAAAiP,MAAAyF,SAAAE,KAAA,EACA5U,EAAAiP,MAAAyF,SAAAG,QAAA,EACA7U,EAAAiP,MAAAyF,SAAAI,SAAA,EAaA9U,EAAAiP,MAAAa,SAAA,CAIAiF,SAAA,EAMAhF,SAAA,EAMAS,WAAA,GA0BAxQ,EAAAiP,MAAAtU,UAAAiR,OAAA,SAAAA,GA+BA,MA9BA,WAAAA,IACAA,EAAA+C,OAAArW,KAAAmc,WAGA,UAAA7I,IACAA,EAAA6E,MAAA,GAGA,gBAAA7E,IACAA,EAAA8D,aAAA,GAGA,aAAA9D,IACAA,EAAA8I,SAAA1U,EAAAiP,MAAAyF,SAAAE,MAGAhJ,EAAA8I,SAAA1U,EAAAiP,MAAAyF,SAAAG,SAAAjJ,EAAAE,KAAAtG,OAAA,IAAAxF,EAAAiP,MAAAyF,WACA9I,EAAAE,KAAA,IAAAF,EAAAE,MAGAF,EAAA8I,SAAA1U,EAAAiP,MAAAyF,SAAAI,UAAAlJ,EAAAE,KAAAlR,OAAA,IAAAoF,EAAAiP,MAAAyF,WACA9I,EAAAE,KAAAF,EAAAE,KAAA,KAGA,aAAAF,IACAA,EAAAkE,SAAA9P,EAAAiP,MAAAa,SAAAiF,UAGAzc,KAAAiX,QAAAtL,KAAA2H,GAEAtT,MAUA0H,EAAAiP,MAAAtU,UAAAyW,UAAA,WACA,IAAA,IAAApZ,EAAA,EAAAA,EAAAM,KAAAiX,QAAAtX,OAAAD,IACA,GAAAM,KAAAiX,QAAAvX,GAAA8X,UAAA9P,EAAAiP,MAAAa,SAAAU,WACA,OAAA,EAIA,OAAA,GA6BAxQ,EAAAiP,MAAAtU,UAAAmR,KAAA,SAAAA,EAAArT,GACA,GAAAiC,MAAA8H,QAAAsJ,GAEA,OADAA,EAAAhR,QAAA,SAAAmK,GAAA3M,KAAAwT,KAAA7G,EAAAjF,EAAA2B,MAAAO,MAAAzJ,KAAAH,MACAA,KAGA,IAAAsT,EAAAnT,GAAA,GAKA,OAJAmT,EAAAE,KAAAA,EAAA7J,WAEA3J,KAAAsT,OAAAA,GAEAtT,MAEA0H,EAAAgV,gBAAA,SAAAnT,EAAA6F,EAAAC,GACArP,KAAA2c,KAAA,kBACA3c,KAAAuJ,QAAAA,EACAvJ,KAAAoP,MAAAA,EACApP,KAAAqP,IAAAA,GAGA3H,EAAAgV,gBAAAra,UAAA,IAAA0L,MACArG,EAAAkV,WAAA,SAAAvQ,GACArM,KAAA6c,QAAA,GACA7c,KAAAqM,IAAAA,EACArM,KAAAL,OAAA0M,EAAA1M,OACAK,KAAAoO,IAAA,EACApO,KAAAoP,MAAA,EACApP,KAAA8c,oBAAA,IAGApV,EAAAkV,WAAAva,UAAAiM,IAAA,WAGA,IAFA,IAAAyO,EAAArV,EAAAkV,WAAAI,QAEAD,GACAA,EAAAA,EAAA/c,OAIA0H,EAAAkV,WAAAva,UAAA4a,YAAA,WAKA,IAJA,IAAAC,EAAA,GACAlQ,EAAAhN,KAAAoP,MACArC,EAAA/M,KAAAoO,IAEA1O,EAAA,EAAAA,EAAAM,KAAA8c,oBAAAnd,OAAAD,IACAqN,EAAA/M,KAAA8c,oBAAApd,GACAwd,EAAAvR,KAAA3L,KAAAqM,IAAA/J,MAAA0K,EAAAD,IACAC,EAAAD,EAAA,EAMA,OAHAmQ,EAAAvR,KAAA3L,KAAAqM,IAAA/J,MAAA0K,EAAAhN,KAAAoO,MACApO,KAAA8c,oBAAAnd,OAAA,EAEAud,EAAAvZ,KAAA,KAGA+D,EAAAkV,WAAAva,UAAA8a,KAAA,SAAAC,GACApd,KAAA6c,QAAAlR,KAAA,CACAyR,KAAAA,EACA/Q,IAAArM,KAAAid,cACA7N,MAAApP,KAAAoP,MACAC,IAAArP,KAAAoO,MAGApO,KAAAoP,MAAApP,KAAAoO,KAGA1G,EAAAkV,WAAAva,UAAAgb,gBAAA,WACArd,KAAA8c,oBAAAnR,KAAA3L,KAAAoO,IAAA,GACApO,KAAAoO,KAAA,GAGA1G,EAAAkV,WAAAva,UAAAkS,KAAA,WACA,GAAAvU,KAAAoO,KAAApO,KAAAL,OACA,OAAA+H,EAAAkV,WAAAU,IAGA,IAAAxJ,EAAA9T,KAAAqM,IAAAa,OAAAlN,KAAAoO,KAEA,OADApO,KAAAoO,KAAA,EACA0F,GAGApM,EAAAkV,WAAAva,UAAAkb,MAAA,WACA,OAAAvd,KAAAoO,IAAApO,KAAAoP,OAGA1H,EAAAkV,WAAAva,UAAAmb,OAAA,WACAxd,KAAAoP,OAAApP,KAAAoO,MACApO,KAAAoO,KAAA,GAGApO,KAAAoP,MAAApP,KAAAoO,KAGA1G,EAAAkV,WAAAva,UAAAob,OAAA,aACAzd,KAAAoO,KAGA1G,EAAAkV,WAAAva,UAAAqb,eAAA,WAGA,IAFA,IAAA5J,EAAA6J,EAKA,IADAA,GADA7J,EAAA9T,KAAAuU,QACAqJ,WAAA,KACAD,EAAA,KAEA7J,GAAApM,EAAAkV,WAAAU,KACAtd,KAAAyd,UAIA/V,EAAAkV,WAAAva,UAAAwb,KAAA,WACA,OAAA7d,KAAAoO,IAAApO,KAAAL,QAGA+H,EAAAkV,WAAAU,IAAA,MACA5V,EAAAkV,WAAAkB,MAAA,QACApW,EAAAkV,WAAAmB,KAAA,OACArW,EAAAkV,WAAAoB,cAAA,gBACAtW,EAAAkV,WAAAqB,MAAA,QACAvW,EAAAkV,WAAAsB,SAAA,WAEAxW,EAAAkV,WAAAuB,SAAA,SAAAC,GAIA,OAHAA,EAAAX,SACAW,EAAAjB,KAAAzV,EAAAkV,WAAAkB,OACAM,EAAAZ,SACA9V,EAAAkV,WAAAI,SAGAtV,EAAAkV,WAAAyB,QAAA,SAAAD,GAQA,GAPA,EAAAA,EAAAb,UACAa,EAAAX,SACAW,EAAAjB,KAAAzV,EAAAkV,WAAAmB,OAGAK,EAAAZ,SAEAY,EAAAP,OACA,OAAAnW,EAAAkV,WAAAI,SAIAtV,EAAAkV,WAAA0B,gBAAA,SAAAF,GAIA,OAHAA,EAAAZ,SACAY,EAAAV,iBACAU,EAAAjB,KAAAzV,EAAAkV,WAAAoB,eACAtW,EAAAkV,WAAAI,SAGAtV,EAAAkV,WAAA2B,SAAA,SAAAH,GAIA,OAHAA,EAAAZ,SACAY,EAAAV,iBACAU,EAAAjB,KAAAzV,EAAAkV,WAAAqB,OACAvW,EAAAkV,WAAAI,SAGAtV,EAAAkV,WAAA4B,OAAA,SAAAJ,GACA,EAAAA,EAAAb,SACAa,EAAAjB,KAAAzV,EAAAkV,WAAAmB,OAeArW,EAAAkV,WAAA6B,cAAA/W,EAAA+E,UAAAW,UAEA1F,EAAAkV,WAAAI,QAAA,SAAAoB,GACA,OAAA,CACA,IAAAtK,EAAAsK,EAAA7J,OAEA,GAAAT,GAAApM,EAAAkV,WAAAU,IACA,OAAA5V,EAAAkV,WAAA4B,OAIA,GAAA,IAAA1K,EAAA8J,WAAA,GAAA,CAKA,GAAA,KAAA9J,EACA,OAAApM,EAAAkV,WAAAuB,SAGA,GAAA,KAAArK,EAKA,OAJAsK,EAAAX,SACA,EAAAW,EAAAb,SACAa,EAAAjB,KAAAzV,EAAAkV,WAAAmB,MAEArW,EAAAkV,WAAA0B,gBAGA,GAAA,KAAAxK,EAKA,OAJAsK,EAAAX,SACA,EAAAW,EAAAb,SACAa,EAAAjB,KAAAzV,EAAAkV,WAAAmB,MAEArW,EAAAkV,WAAA2B,SAMA,GAAA,KAAAzK,GAAA,IAAAsK,EAAAb,QAEA,OADAa,EAAAjB,KAAAzV,EAAAkV,WAAAsB,UACAxW,EAAAkV,WAAAI,QAMA,GAAA,KAAAlJ,GAAA,IAAAsK,EAAAb,QAEA,OADAa,EAAAjB,KAAAzV,EAAAkV,WAAAsB,UACAxW,EAAAkV,WAAAI,QAGA,GAAAlJ,EAAA3G,MAAAzF,EAAAkV,WAAA6B,eACA,OAAA/W,EAAAkV,WAAAyB,aAzCAD,EAAAf,oBA8CA3V,EAAA+O,YAAA,SAAApK,EAAAmK,GACAxW,KAAAoe,MAAA,IAAA1W,EAAAkV,WAAAvQ,GACArM,KAAAwW,MAAAA,EACAxW,KAAA0e,cAAA,GACA1e,KAAA2e,UAAA,GAGAjX,EAAA+O,YAAApU,UAAAqU,MAAA,WACA1W,KAAAoe,MAAA9P,MACAtO,KAAA6c,QAAA7c,KAAAoe,MAAAvB,QAIA,IAFA,IAAAE,EAAArV,EAAA+O,YAAAmI,YAEA7B,GACAA,EAAAA,EAAA/c,MAGA,OAAAA,KAAAwW,OAGA9O,EAAA+O,YAAApU,UAAAwc,WAAA,WACA,OAAA7e,KAAA6c,QAAA7c,KAAA2e,YAGAjX,EAAA+O,YAAApU,UAAAyc,cAAA,WACA,IAAAC,EAAA/e,KAAA6e,aAEA,OADA7e,KAAA2e,WAAA,EACAI,GAGArX,EAAA+O,YAAApU,UAAA2c,WAAA,WACA,IAAAC,EAAAjf,KAAA0e,cACA1e,KAAAwW,MAAAlD,OAAA2L,GACAjf,KAAA0e,cAAA,IAGAhX,EAAA+O,YAAAmI,YAAA,SAAAM,GACA,IAAAH,EAAAG,EAAAL,aAEA,GAAA/T,MAAAiU,EAIA,OAAAA,EAAA3B,MACA,KAAA1V,EAAAkV,WAAAsB,SACA,OAAAxW,EAAA+O,YAAA0I,cACA,KAAAzX,EAAAkV,WAAAkB,MACA,OAAApW,EAAA+O,YAAA2I,WACA,KAAA1X,EAAAkV,WAAAmB,KACA,OAAArW,EAAA+O,YAAA4I,UACA,QACA,IAAAC,EAAA,4CAAAP,EAAA3B,KAMA,MAJA,GAAA2B,EAAA1S,IAAA1M,SACA2f,GAAA,gBAAAP,EAAA1S,IAAA,KAGA,IAAA3E,EAAAgV,gBAAA4C,EAAAP,EAAA3P,MAAA2P,EAAA1P,OAIA3H,EAAA+O,YAAA0I,cAAA,SAAAD,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAAhU,MAAAiU,EAAA,CAIA,OAAAA,EAAA1S,KACA,IAAA,IACA6S,EAAAR,cAAAlH,SAAA9P,EAAAiP,MAAAa,SAAAU,WACA,MACA,IAAA,IACAgH,EAAAR,cAAAlH,SAAA9P,EAAAiP,MAAAa,SAAAC,SACA,MACA,QACA,IAAA6H,EAAA,kCAAAP,EAAA1S,IAAA,IACA,MAAA,IAAA3E,EAAAgV,gBAAA4C,EAAAP,EAAA3P,MAAA2P,EAAA1P,KAGA,IAAAkQ,EAAAL,EAAAL,aAEA,GAAA/T,MAAAyU,EAAA,CACAD,EAAA,yCACA,MAAA,IAAA5X,EAAAgV,gBAAA4C,EAAAP,EAAA3P,MAAA2P,EAAA1P,KAGA,OAAAkQ,EAAAnC,MACA,KAAA1V,EAAAkV,WAAAkB,MACA,OAAApW,EAAA+O,YAAA2I,WACA,KAAA1X,EAAAkV,WAAAmB,KACA,OAAArW,EAAA+O,YAAA4I,UACA,QACAC,EAAA,mCAAAC,EAAAnC,KAAA,IACA,MAAA,IAAA1V,EAAAgV,gBAAA4C,EAAAC,EAAAnQ,MAAAmQ,EAAAlQ,QAIA3H,EAAA+O,YAAA2I,WAAA,SAAAF,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAAhU,MAAAiU,EAAA,CAIA,IAAA,GAAAG,EAAA1I,MAAA2F,UAAAvR,QAAAmU,EAAA1S,KAAA,CACA,IAAAmT,EAAAN,EAAA1I,MAAA2F,UAAAzP,IAAA,SAAA+S,GAAA,MAAA,IAAAA,EAAA,MAAA9b,KAAA,MACA2b,EAAA,uBAAAP,EAAA1S,IAAA,uBAAAmT,EAEA,MAAA,IAAA9X,EAAAgV,gBAAA4C,EAAAP,EAAA3P,MAAA2P,EAAA1P,KAGA6P,EAAAR,cAAArI,OAAA,CAAA0I,EAAA1S,KAEA,IAAAkT,EAAAL,EAAAL,aAEA,GAAA/T,MAAAyU,EAAA,CACAD,EAAA,gCACA,MAAA,IAAA5X,EAAAgV,gBAAA4C,EAAAP,EAAA3P,MAAA2P,EAAA1P,KAGA,OAAAkQ,EAAAnC,MACA,KAAA1V,EAAAkV,WAAAmB,KACA,OAAArW,EAAA+O,YAAA4I,UACA,QACAC,EAAA,0BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAA1V,EAAAgV,gBAAA4C,EAAAC,EAAAnQ,MAAAmQ,EAAAlQ,QAIA3H,EAAA+O,YAAA4I,UAAA,SAAAH,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAAhU,MAAAiU,EAAA,CAIAG,EAAAR,cAAAlL,KAAAuL,EAAA1S,IAAAlD,eAEA,GAAA4V,EAAA1S,IAAAzB,QAAA,OACAsU,EAAAR,cAAAtH,aAAA,GAGA,IAAAmI,EAAAL,EAAAL,aAEA,GAAA/T,MAAAyU,EAKA,OAAAA,EAAAnC,MACA,KAAA1V,EAAAkV,WAAAmB,KAEA,OADAmB,EAAAF,aACAtX,EAAA+O,YAAA4I,UACA,KAAA3X,EAAAkV,WAAAkB,MAEA,OADAoB,EAAAF,aACAtX,EAAA+O,YAAA2I,WACA,KAAA1X,EAAAkV,WAAAoB,cACA,OAAAtW,EAAA+O,YAAAiJ,kBACA,KAAAhY,EAAAkV,WAAAqB,MACA,OAAAvW,EAAA+O,YAAAkJ,WACA,KAAAjY,EAAAkV,WAAAsB,SAEA,OADAgB,EAAAF,aACAtX,EAAA+O,YAAA0I,cACA,QACA,IAAAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAA1V,EAAAgV,gBAAA4C,EAAAC,EAAAnQ,MAAAmQ,EAAAlQ,UApBA6P,EAAAF,eAwBAtX,EAAA+O,YAAAiJ,kBAAA,SAAAR,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAAhU,MAAAiU,EAAA,CAIA,IAAAtL,EAAAmM,SAAAb,EAAA1S,IAAA,IAEA,GAAAwT,MAAApM,GAAA,CACA,IAAA6L,EAAA,gCACA,MAAA,IAAA5X,EAAAgV,gBAAA4C,EAAAP,EAAA3P,MAAA2P,EAAA1P,KAGA6P,EAAAR,cAAAjL,aAAAA,EAEA,IAAA8L,EAAAL,EAAAL,aAEA,GAAA/T,MAAAyU,EAKA,OAAAA,EAAAnC,MACA,KAAA1V,EAAAkV,WAAAmB,KAEA,OADAmB,EAAAF,aACAtX,EAAA+O,YAAA4I,UACA,KAAA3X,EAAAkV,WAAAkB,MAEA,OADAoB,EAAAF,aACAtX,EAAA+O,YAAA2I,WACA,KAAA1X,EAAAkV,WAAAoB,cACA,OAAAtW,EAAA+O,YAAAiJ,kBACA,KAAAhY,EAAAkV,WAAAqB,MACA,OAAAvW,EAAA+O,YAAAkJ,WACA,KAAAjY,EAAAkV,WAAAsB,SAEA,OADAgB,EAAAF,aACAtX,EAAA+O,YAAA0I,cACA,QACAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAA1V,EAAAgV,gBAAA4C,EAAAC,EAAAnQ,MAAAmQ,EAAAlQ,UApBA6P,EAAAF,eAwBAtX,EAAA+O,YAAAkJ,WAAA,SAAAT,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAAhU,MAAAiU,EAAA,CAIA,IAAA5G,EAAAyH,SAAAb,EAAA1S,IAAA,IAEA,GAAAwT,MAAA1H,GAAA,CACA,IAAAmH,EAAA,wBACA,MAAA,IAAA5X,EAAAgV,gBAAA4C,EAAAP,EAAA3P,MAAA2P,EAAA1P,KAGA6P,EAAAR,cAAAvG,MAAAA,EAEA,IAAAoH,EAAAL,EAAAL,aAEA,GAAA/T,MAAAyU,EAKA,OAAAA,EAAAnC,MACA,KAAA1V,EAAAkV,WAAAmB,KAEA,OADAmB,EAAAF,aACAtX,EAAA+O,YAAA4I,UACA,KAAA3X,EAAAkV,WAAAkB,MAEA,OADAoB,EAAAF,aACAtX,EAAA+O,YAAA2I,WACA,KAAA1X,EAAAkV,WAAAoB,cACA,OAAAtW,EAAA+O,YAAAiJ,kBACA,KAAAhY,EAAAkV,WAAAqB,MACA,OAAAvW,EAAA+O,YAAAkJ,WACA,KAAAjY,EAAAkV,WAAAsB,SAEA,OADAgB,EAAAF,aACAtX,EAAA+O,YAAA0I,cACA,QACAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAA1V,EAAAgV,gBAAA4C,EAAAC,EAAAnQ,MAAAmQ,EAAAlQ,UApBA6P,EAAAF,eA4BAxX,EAeAxH,KAfAyH,EAeA,WAMA,OAAAC,GApBA,mBAAAoY,QAAAA,OAAAC,IAEAD,OAAArY,GACA,iBAAAuY,QAMAC,OAAAD,QAAAvY,IAGAD,EAAAE,KAAAD,IA34GA,GCNAnI,SAAAO,iBAAA,mBAAA,WACA,IAAAqgB,EAAA5gB,SAAAC,cAAA,2BACA4gB,EAAA7gB,SAAAC,cAAA,sCACA6gB,EAAA9gB,SAAAC,cAAA,uCAEA,SAAA8gB,IACA,IAAAC,EAAAhhB,SAAAiC,eAAA,gBACA+e,EAAAjgB,MAAA,GACAigB,EAAAC,cAAA,IAAAC,cAAA,YAGA,SAAAC,EAAA3e,GAEA,IAAA4e,EAAA5e,EAAA6e,SAAA7e,EAAA8e,MAIA,OAHA,KAGAF,GAFA,KAEAA,EAGA,SAAAG,IACA,IAAAnf,EAAApC,SAAAC,cAAA,QACAoC,EAAArC,SAAAC,cAAA,qBACAuhB,EAAAxhB,SAAAC,cAAA,gCACAwhB,EAAAzhB,SAAAC,cAAA,YACAuhB,EAAArgB,UAAAY,SAAA,SACAyf,EAAArgB,UAAAC,OAAA,QACAgB,EAAAjB,UAAAE,IAAA,QACAgB,EAAAlB,UAAAE,IAAA,QACAogB,EAAAtgB,UAAAE,IAAA,UAEAmgB,EAAArgB,UAAAE,IAAA,QACAe,EAAAjB,UAAAC,OAAA,QAGA,KAAAuB,OAAAC,WACAP,EAAAlB,UAAAC,OAAA,QAEAqgB,EAAAtgB,UAAAC,OAAA,SAIA,IAAAsgB,EAAA1hB,SAAAC,cAAA,yBACA0hB,EAAA3hB,SAAAC,cAAA,iDACAyhB,EAAAvgB,UAAAY,SAAA,SACA2f,EAAAvgB,UAAAC,OAAA,QACAugB,EAAAxgB,UAAAE,IAAA,UAEAqgB,EAAAvgB,UAAAE,IAAA,QACAsgB,EAAAxgB,UAAAC,OAAA,SAKAwf,EAAArgB,iBAAA,QAAAghB,GACAX,EAAArgB,iBAAA,WAAA,SAAAiC,GACA2e,EAAA3e,IACA+e,MAGA,iBAAA5e,QACAie,EAAArgB,iBAAA,eAAAghB,GAIAV,EAAAtgB,iBAAA,QAAAghB,GACAV,EAAAtgB,iBAAA,WAAA,SAAAiC,GACA2e,EAAA3e,IACA+e,MAGA,iBAAA5e,QACAke,EAAAtgB,iBAAA,eAAAghB,GAIAT,EAAAvgB,iBAAA,QAAAwgB,GACAD,EAAAvgB,iBAAA,WAAA,SAAAiC,GACA2e,EAAA3e,IACAue,MAGA,iBAAApe,QACAme,EAAAvgB,iBAAA,eAAAwgB,KAMApe,OAAAif,WAAA,SAAAxZ,GACA,IAAA4Y,EAAAhhB,SAAAiC,eAAA,gBACAuf,EAAAxhB,SAAAyD,cAAA,OACAoe,EAAA7hB,SAAAC,cAAA,SAKA,SAAA6hB,EAAA9G,EAAA1K,GACA,IAAAyR,EAAA,GACAjS,EAAAQ,EAAA,GACAjQ,EAAAiQ,EAAA,GAEAtM,EAAAgX,EAAAhX,KACAge,EAAAhiB,SAAAyD,cAAA,QACAue,EAAA7gB,UAAAE,IAAA,2BACA2gB,EAAAte,UAAAM,EAAAuF,OAAAuG,EAAAzP,GAEA,IAAA0P,EAAAD,EAAAzP,EACA4hB,EAAAje,EAAA3D,OAAA,EAEA6hB,EAAAD,EAAAlS,EADA,GACAkS,EAAAlS,EADA,GAEAoS,EAAArS,EAFA,GAEA,EAAA,EAAAA,EAFA,GAgBA,OAbA,IAAAA,GAAAC,IAAAkS,EACAF,EAAA1V,KAAA2V,GACA,IAAAlS,GACAiS,EAAA1V,KAAA2V,GACAD,EAAA1V,KAAArM,SAAAoiB,eAAApe,EAAAuF,OAAAwG,EAAAmS,MACAnS,IAAAkS,GACAF,EAAA1V,KAAArM,SAAAoiB,eAAApe,EAAAuF,OAAA,EAAAuG,KACAiS,EAAA1V,KAAA2V,KAEAD,EAAA1V,KAAArM,SAAAoiB,eAAA,MAAApe,EAAAuF,OAAA4Y,EAAArS,EAAAqS,KACAJ,EAAA1V,KAAA2V,GACAD,EAAA1V,KAAArM,SAAAoiB,eAAApe,EAAAuF,OAAAwG,EAAAmS,EAAAnS,GAAA,SAEAgS,EAGA,SAAAM,EAAAC,EAAAtH,EAAA1K,GACA,IAMAiS,EANAR,EAAA,GACAjS,EAAAQ,EAAA,GACAjQ,EAAAiQ,EAAA,GAEA0R,EAAAhiB,SAAAyD,cAAA,QACAue,EAAA7gB,UAAAE,IAAA,2BAGAkhB,EADAD,EACAtH,EAAAwH,OAAAC,OAAA,SAAA/gB,GACA,OAAAA,EAAAiE,KAAA2c,IACA,GAAAte,KAEAgX,EAAAuH,MAEAP,EAAAte,UAAA6e,EAAAhZ,OAAAuG,EAAAzP,GAEA,IAAA0P,EAAAD,EAAAzP,EACAqiB,EAAAH,EAAAliB,OAAA,EAcA,OAbA,IAAAyP,GAAAC,IAAA2S,EACAX,EAAA1V,KAAA2V,GACA,IAAAlS,GACAiS,EAAA1V,KAAA2V,GACAD,EAAA1V,KAAArM,SAAAoiB,eAAAG,EAAAhZ,OAAAlJ,EAAAqiB,MACA3S,IAAA2S,GACAX,EAAA1V,KAAArM,SAAAoiB,eAAAG,EAAAhZ,OAAA,EAAAuG,KACAiS,EAAA1V,KAAA2V,KAEAD,EAAA1V,KAAArM,SAAAoiB,eAAAG,EAAAhZ,OAAA,EAAAuG,KACAiS,EAAA1V,KAAA2V,GACAD,EAAA1V,KAAArM,SAAAoiB,eAAAG,EAAAhZ,OAAAwG,EAAA2S,MAEAX,EAsBA,SAAAY,EAAAvT,EAAAwT,EAAAC,GACAzT,EAAAlM,QAAA,SAAAxB,GACA,IACA4gB,EADAQ,EAAAphB,EAAAoY,IAEAgJ,EAAAC,SAAA,OACAT,EAAAQ,EAAAE,UAAAF,EAAAxX,QAAA,KAAA,GACAwX,EAAAA,EAAApZ,QAAA,IAAA4Y,EAAA,KAEA,IAAAtH,EAAA4H,EAAAE,GAEAf,EA7BA,SAAA/U,EAAAsV,EAAAtH,GACA,IAAA+G,EAAA,GACA,IAAA,IAAAxS,KAAAvC,EAAA,CACA,IAAA+J,EAAA/J,EAAAuC,GACA,IAAA,IAAA6I,KAAArB,EAAA,CACA,IAAAkM,EAAAlM,EAAAqB,GACA,GAAA6K,EAAA3S,SAAA,CACA,IAAAA,EAAA2S,EAAA3S,SAAA,GACA,UAAA8H,EACA2J,EAAAM,EAAAC,EAAAtH,EAAA1K,GACA,SAAA8H,IACA2J,EAAAD,EAAA9G,EAAA1K,MAKA,OAAAyR,EAaAmB,CADAxhB,EAAAkY,UAAA5M,SACAsV,EAAAtH,GACA6H,EAAA3c,YAIA,SAAA8U,EAAAtZ,EAAAqgB,GACA,IAAAoB,EAAAnjB,SAAAyD,cAAA,OACA0f,EAAAhiB,UAAAE,IAAA,gCACA8hB,EAAAzf,UAAAsX,EAAAuH,MACA,IAAAa,EAAApjB,SAAAyD,cAAA,OACA2f,EAAAjiB,UAAAE,IAAA,8BACA,IAAAgiB,EAAArjB,SAAAyD,cAAA,KACA4f,EAAAC,KAAA5hB,EAAAoY,IACAsJ,EAAAld,YAAAmd,GACAtB,EAAA7e,QAAA,SAAAqgB,GACAF,EAAAnd,YAAAqd,KAEA,IAAAC,EAAAxjB,SAAAyD,cAAA,OAIA,OAHA+f,EAAAriB,UAAAE,IAAA,sBACAmiB,EAAAtd,YAAAid,GACAK,EAAAtd,YAAAkd,GACAI,EApBAC,CAAAzI,EAAAtZ,EAAAqgB,MAmDA,SAAA2B,EAAA7T,EAAA+S,EAAA5e,GAEA,KAAAwd,EAAAmC,YACAnC,EAAAoC,YAAApC,EAAAmC,YAEA,GAAA,KAAA3f,EAAAsJ,OAAA,CAGA,IAxBAuC,EAAA7L,EAEAoL,EAsBAA,GAxBApL,EAwBAA,EArBA,GADAoL,GAFAS,EAwBAA,GAtBAmH,OAAAhT,IACA3D,QAKA,GADA+O,EAAAS,EAAAmH,OAAAhT,EAAA,MACA3D,OAJA+O,EAQAA,EAAAS,EAAAmH,OAAA,IAAAhT,EAAA,MAaA6e,EAAA7iB,SAAAyD,cAAA,OACAof,EAAA1hB,UAAAE,IAAA,yBACAmgB,EAAAtb,YAAA2c,GACA,EAAAzT,EAAA/O,OACAsiB,EAAAvT,EAAAwT,EAAAC,GAEAA,EAAA3c,YA3CA,SAAAlC,GACA,IAAAwf,EAAAxjB,SAAAyD,cAAA,OACA+f,EAAAriB,UAAAE,IAAA,sBACA,IAAA+hB,EAAApjB,SAAAyD,cAAA,OACA2f,EAAAjiB,UAAAE,IAAA,8BACA,IAAA4I,EAAAjK,SAAAyD,cAAA,UAIA,OAHAwG,EAAAvG,UAAA,+BAAAM,EAAA,IACAof,EAAAld,YAAA+D,GACAuZ,EAAAtd,YAAAkd,GACAI,EAkCAK,CAAA7f,KA6BA,OAnMAwd,EAAArgB,UAAAE,IAAA,+BACAmgB,EAAArgB,UAAAE,IAAA,QACAwgB,EAAAhe,aAAA2d,EAAAK,EAAA8B,YAiMA,CACAG,KAVA,SAAAC,GACA,IAjBAC,EAAAC,EAAAC,EACAC,EAgBAtU,EAAAtF,OAAA6Z,OAAA,CAAAvU,MAAAzH,EAAAsO,MAAApI,KAAAyV,EAAAlU,OAAA+S,MAAAmB,EAAAnB,QACA5L,GAlBAgN,EAkBA,WACAN,EAAA7T,EAAAA,MAAAA,EAAA+S,MAAA5B,EAAAjgB,QAnBAkjB,EAoBA,IAlBA,WACA,IAAAI,EAAA3jB,KACA6b,EAAA7N,UAKA4V,EAAAJ,IAAAC,EACAI,aAAAJ,GACAA,EAAAle,WANA,WACAke,EAAA,KACAD,GAAAF,EAAAvH,MAAA4H,EAAA9H,IAIA0H,GACAK,GAAAN,EAAAvH,MAAA4H,EAAA9H,KAUAyE,EAAAzgB,iBAAA,UAAAyW,KApMA,CA0MArU,OAAAyF","file":"site.js","sourcesContent":[";(function () {\n  'use strict'\n\n  //header \n  mdc.topAppBar.MDCTopAppBar.attachTo(document.querySelector('.mdc-top-app-bar'))\n\n  // nav \n  /// version select box\n  var select = document.querySelectorAll('.select-version')\n  for(var i = 0; i < select.length; i++){\n    var s = select[i]\n    s.addEventListener('change', function(event){\n      var component = this.getAttribute('data-component')\n      var version = this.options[this.selectedIndex].value\n      var showSelector = '.nav-container div[data-component=\"' + component + '\"][data-version=\"' + version + '\"]'\n      var hideSelector = '.nav-container div[data-component=\"' + component + '\"]:not(.hide)'\n      var navShow = document.querySelector(showSelector)\n      var navHide = document.querySelector(hideSelector)\n      navShow.classList.remove('hide')\n      navHide.classList.add('hide')\n    })\n\n    // Disable select if there is only one version\n    if (s.options.length === 1) {\n      s.classList.add('single-version');\n      s.disabled = true;\n    }\n  }\n\n  /// nav-tree\n  var x = document.querySelectorAll('.nav-item .material-icons'); \n  for(var i = 0; i < x.length; i++){\n    mdc.ripple.MDCRipple.attachTo(x[i])\n    x[i].addEventListener('click', function(event){\n      var item = event.target\n      var panel = item.parentElement.nextElementSibling\n      if(item.classList.contains('expanded')){\n        item.classList.remove('expanded')\n        panel.classList.add('hide')\n      } else{\n        item.classList.add('expanded')\n        panel.classList.remove('hide')\n      }\n    })\n  }\n\n  // toolbar menu button \n  var navToggle = document.getElementById('toolbar-nav-toggle')\n  mdc.iconButton.MDCIconButtonToggle.attachTo(navToggle)\n  navToggle.addEventListener('click', function(){\n    // Toggle navigation and main content together\n    var mainContainer = document.querySelector('main')\n    var navContainer = document.querySelector('div.nav-container')\n    if(navContainer.classList.contains('hide')){\n      mainContainer.classList.add('hide')\n      navContainer.classList.remove('hide')\n\n    } else{\n      mainContainer.classList.remove('hide')\n      navContainer.classList.add('hide')\n    }\n  })\n\n})()\n",";(function () {\n  'use strict'\n\n  var toggle = document.querySelector('.page-versions .version-menu-toggle')\n  if (!toggle) return\n\n  var selector = document.querySelector('.page-versions')\n\n  toggle.addEventListener('click', function (e) {\n    selector.classList.toggle('is-active')\n    // don't let this event get smothered\n    e.stopPropagation()\n  })\n\n  document.documentElement.addEventListener('click', function () {\n    selector.classList.remove('is-active')\n  })\n})()\n","document.addEventListener('DOMContentLoaded', function () {\n  // Hide navbar on mobile\n  if (window.innerWidth <= 1024) {\n    var navContainer = document.querySelector('div.nav-container')\n    navContainer.classList.add('hide')\n  }\n\n  // Add event listeners to hamburger icons\n  var navbarToggles = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0)\n  if (navbarToggles.length === 0) return\n  navbarToggles.forEach(function (el) {\n    el.addEventListener('click', function (e) {\n      e.stopPropagation()\n      el.classList.toggle('is-active')\n      document.getElementById(el.dataset.target).classList.toggle('is-active')\n      document.documentElement.classList.toggle('is-clipped--navbar')\n    })\n  })\n})\n\n\nwindow.addEventListener('resize', function () {\n  // Only expand/unhide elements on resize if search isn't open\n  var searchTopBar = document.querySelector('.mdc-top-app-bar__row.sdp-top-app-bar__search')\n  if (searchTopBar.classList.contains('hide')) {\n    // Unhide main content\n    var mainContainer = document.querySelector('main')\n    if (mainContainer.classList.contains('hide')) {\n      mainContainer.classList.remove('hide')\n    }\n\n    // Expand navbar if window is resized from mobile to desktop\n    var navContainer = document.querySelector('div.nav-container')\n    if (window.innerWidth > 1024) {\n      if (navContainer.classList.contains('hide')) {\n        navContainer.classList.remove('hide')\n      }\n    }\n  }\n\n  // Hide navbar if window is resized from desktop to mobile\n  if (window.innerWidth < 1025) {\n    if (!navContainer.classList.contains('hide')) {\n      navContainer.classList.add('hide')\n    }\n  }\n});\n",";(function () {\n  \n  hljs.initHighlighting()\n\n})()\n  ",";(function () {\n    'use strict'\n    // <i class=\"material-icons mdc-icon-button search\" tabindex=\"0\" role=\"button\">search</i>\n    var codeBlocks = document.querySelectorAll('.doc .listingblock code')\n    var copyIcon = document.createElement('i')\n    copyIcon.classList = 'material-icons codeCopyButton'\n    copyIcon.innerText = 'file_copy'\n    for (var i = 0; i < codeBlocks.length; i++) {\n      var icon = copyIcon.cloneNode(true)\n      codeBlocks[i].insertBefore(icon, codeBlocks[i].childNodes[0])\n    }\n \n    /*global ClipboardJS*/\n    var clipboard = new ClipboardJS('.material-icons.codeCopyButton', {\n      text: function (target) { \n        var lines = target.parentNode.innerText.split(\"\\n\")\n        lines.splice(0,1)\n        return lines.join(\"\\n\") \n      },\n    })\n  \n    clipboard.on('success', function (e) {\n      e.trigger._tippy.setContent('copied!')\n    })\n  \n    tippy.delegate('.doc .listingblock code', {\n      target: '.material-icons.codeCopyButton',\n      content: 'copy to clipboard',\n      animation: 'shift-away',\n      theme: 'clipboard',\n      delay: [500, 0],\n      placement: 'bottom',\n      hideOnClick: false,\n      onHidden: function (instance) {\n        instance.setContent('copy to clipboard')\n      },\n    })\n  })()\n  ",";(function () {\n  'use strict'\n\n  // create table of contents \n  var headers = document.querySelector('.doc .contents').querySelectorAll('h1, h2, h3, h4, h5, h6')\n  var toc = document.getElementById('toc')\n  for(var i = 0; i < headers.length; i++){\n      var header = headers[i]        \n      var li = document.createElement('li')\n      li.classList.add('toc-item')\n      li.classList.add(header.tagName)\n      li.innerText = header.innerText \n      li.setAttribute('headerId', header.getAttribute('id'))\n      li.addEventListener('click', function() {\n          var h, id = this.getAttribute('headerId')\n          if(id != 'null'){ h = document.getElementById(id) } \n          else { h = document.querySelector('h1') }\n          window.scroll({\n              top: h.offsetTop + 30, // 30 to account for fixed header height \n              left: 0,\n              behavior: 'smooth'\n          })\n          h.classList.add('toc-highlight')\n          setTimeout(function(){ h.classList.remove('toc-highlight') }, 2000)\n      })\n      toc.appendChild(li)\n  }\n\n  // enable highlighted toc\n  var referenceElement = document.querySelector('article').parentNode\n  window.addEventListener('scroll', function () {\n    var activeHeader, lastActiveHeader = document.querySelector('.toc-item.active')\n    var referencePoint = referenceElement.offsetTop + 108.1 \n    for (var i = (headers.length - 1); i >= 0; i--) {\n      var hTop = headers[i].getBoundingClientRect().top\n      if (hTop < referencePoint) {\n        var activeId = headers[i].getAttribute('id')\n        activeHeader = document.querySelector('.toc-item[headerId=\"' + activeId + '\"]')\n        break\n      }\n    }\n\n    // there is currently an active header and it has changed\n    if(activeHeader && activeHeader !== lastActiveHeader){\n      activeHeader.classList.add('active')\n      if(lastActiveHeader){\n        lastActiveHeader.classList.remove('active')\n      }\n    }\n  })\n\n})()\n  ","/**\n * lunr - http://lunrjs.com - A bit like Solr, but much smaller and not as bright - 2.3.3\n * Copyright (C) 2018 Oliver Nightingale\n * @license MIT\n */\n\n;(function(){\n\n  /**\n   * A convenience function for configuring and constructing\n   * a new lunr Index.\n   *\n   * A lunr.Builder instance is created and the pipeline setup\n   * with a trimmer, stop word filter and stemmer.\n   *\n   * This builder object is yielded to the configuration function\n   * that is passed as a parameter, allowing the list of fields\n   * and other builder parameters to be customised.\n   *\n   * All documents _must_ be added within the passed config function.\n   *\n   * @example\n   * var idx = lunr(function () {\n   *   this.field('title')\n   *   this.field('body')\n   *   this.ref('id')\n   *\n   *   documents.forEach(function (doc) {\n   *     this.add(doc)\n   *   }, this)\n   * })\n   *\n   * @see {@link lunr.Builder}\n   * @see {@link lunr.Pipeline}\n   * @see {@link lunr.trimmer}\n   * @see {@link lunr.stopWordFilter}\n   * @see {@link lunr.stemmer}\n   * @namespace {function} lunr\n   */\n  var lunr = function (config) {\n    var builder = new lunr.Builder\n  \n    builder.pipeline.add(\n      lunr.trimmer,\n      lunr.stopWordFilter,\n      lunr.stemmer\n    )\n  \n    builder.searchPipeline.add(\n      lunr.stemmer\n    )\n  \n    config.call(builder, builder)\n    return builder.build()\n  }\n  \n  lunr.version = \"2.3.3\"\n  /*!\n   * lunr.utils\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A namespace containing utils for the rest of the lunr library\n   * @namespace lunr.utils\n   */\n  lunr.utils = {}\n  \n  /**\n   * Print a warning message to the console.\n   *\n   * @param {String} message The message to be printed.\n   * @memberOf lunr.utils\n   * @function\n   */\n  lunr.utils.warn = (function (global) {\n    /* eslint-disable no-console */\n    return function (message) {\n      if (global.console && console.warn) {\n        console.warn(message)\n      }\n    }\n    /* eslint-enable no-console */\n  })(this)\n  \n  /**\n   * Convert an object to a string.\n   *\n   * In the case of `null` and `undefined` the function returns\n   * the empty string, in all other cases the result of calling\n   * `toString` on the passed object is returned.\n   *\n   * @param {Any} obj The object to convert to a string.\n   * @return {String} string representation of the passed object.\n   * @memberOf lunr.utils\n   */\n  lunr.utils.asString = function (obj) {\n    if (obj === void 0 || obj === null) {\n      return \"\"\n    } else {\n      return obj.toString()\n    }\n  }\n  \n  /**\n   * Clones an object.\n   *\n   * Will create a copy of an existing object such that any mutations\n   * on the copy cannot affect the original.\n   *\n   * Only shallow objects are supported, passing a nested object to this\n   * function will cause a TypeError.\n   *\n   * Objects with primitives, and arrays of primitives are supported.\n   *\n   * @param {Object} obj The object to clone.\n   * @return {Object} a clone of the passed object.\n   * @throws {TypeError} when a nested object is passed.\n   * @memberOf Utils\n   */\n  lunr.utils.clone = function (obj) {\n    if (obj === null || obj === undefined) {\n      return obj\n    }\n  \n    var clone = Object.create(null),\n        keys = Object.keys(obj)\n  \n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i],\n          val = obj[key]\n  \n      if (Array.isArray(val)) {\n        clone[key] = val.slice()\n        continue\n      }\n  \n      if (typeof val === 'string' ||\n          typeof val === 'number' ||\n          typeof val === 'boolean') {\n        clone[key] = val\n        continue\n      }\n  \n      throw new TypeError(\"clone is not deep and does not support nested objects\")\n    }\n  \n    return clone\n  }\n  lunr.FieldRef = function (docRef, fieldName, stringValue) {\n    this.docRef = docRef\n    this.fieldName = fieldName\n    this._stringValue = stringValue\n  }\n  \n  lunr.FieldRef.joiner = \"/\"\n  \n  lunr.FieldRef.fromString = function (s) {\n    var n = s.indexOf(lunr.FieldRef.joiner)\n  \n    if (n === -1) {\n      throw \"malformed field ref string\"\n    }\n  \n    var fieldRef = s.slice(0, n),\n        docRef = s.slice(n + 1)\n  \n    return new lunr.FieldRef (docRef, fieldRef, s)\n  }\n  \n  lunr.FieldRef.prototype.toString = function () {\n    if (this._stringValue == undefined) {\n      this._stringValue = this.fieldName + lunr.FieldRef.joiner + this.docRef\n    }\n  \n    return this._stringValue\n  }\n  /*!\n   * lunr.Set\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A lunr set.\n   *\n   * @constructor\n   */\n  lunr.Set = function (elements) {\n    this.elements = Object.create(null)\n  \n    if (elements) {\n      this.length = elements.length\n  \n      for (var i = 0; i < this.length; i++) {\n        this.elements[elements[i]] = true\n      }\n    } else {\n      this.length = 0\n    }\n  }\n  \n  /**\n   * A complete set that contains all elements.\n   *\n   * @static\n   * @readonly\n   * @type {lunr.Set}\n   */\n  lunr.Set.complete = {\n    intersect: function (other) {\n      return other\n    },\n  \n    union: function (other) {\n      return other\n    },\n  \n    contains: function () {\n      return true\n    }\n  }\n  \n  /**\n   * An empty set that contains no elements.\n   *\n   * @static\n   * @readonly\n   * @type {lunr.Set}\n   */\n  lunr.Set.empty = {\n    intersect: function () {\n      return this\n    },\n  \n    union: function (other) {\n      return other\n    },\n  \n    contains: function () {\n      return false\n    }\n  }\n  \n  /**\n   * Returns true if this set contains the specified object.\n   *\n   * @param {object} object - Object whose presence in this set is to be tested.\n   * @returns {boolean} - True if this set contains the specified object.\n   */\n  lunr.Set.prototype.contains = function (object) {\n    return !!this.elements[object]\n  }\n  \n  /**\n   * Returns a new set containing only the elements that are present in both\n   * this set and the specified set.\n   *\n   * @param {lunr.Set} other - set to intersect with this set.\n   * @returns {lunr.Set} a new set that is the intersection of this and the specified set.\n   */\n  \n  lunr.Set.prototype.intersect = function (other) {\n    var a, b, elements, intersection = []\n  \n    if (other === lunr.Set.complete) {\n      return this\n    }\n  \n    if (other === lunr.Set.empty) {\n      return other\n    }\n  \n    if (this.length < other.length) {\n      a = this\n      b = other\n    } else {\n      a = other\n      b = this\n    }\n  \n    elements = Object.keys(a.elements)\n  \n    for (var i = 0; i < elements.length; i++) {\n      var element = elements[i]\n      if (element in b.elements) {\n        intersection.push(element)\n      }\n    }\n  \n    return new lunr.Set (intersection)\n  }\n  \n  /**\n   * Returns a new set combining the elements of this and the specified set.\n   *\n   * @param {lunr.Set} other - set to union with this set.\n   * @return {lunr.Set} a new set that is the union of this and the specified set.\n   */\n  \n  lunr.Set.prototype.union = function (other) {\n    if (other === lunr.Set.complete) {\n      return lunr.Set.complete\n    }\n  \n    if (other === lunr.Set.empty) {\n      return this\n    }\n  \n    return new lunr.Set(Object.keys(this.elements).concat(Object.keys(other.elements)))\n  }\n  /**\n   * A function to calculate the inverse document frequency for\n   * a posting. This is shared between the builder and the index\n   *\n   * @private\n   * @param {object} posting - The posting for a given term\n   * @param {number} documentCount - The total number of documents.\n   */\n  lunr.idf = function (posting, documentCount) {\n    var documentsWithTerm = 0\n  \n    for (var fieldName in posting) {\n      if (fieldName == '_index') continue // Ignore the term index, its not a field\n      documentsWithTerm += Object.keys(posting[fieldName]).length\n    }\n  \n    var x = (documentCount - documentsWithTerm + 0.5) / (documentsWithTerm + 0.5)\n  \n    return Math.log(1 + Math.abs(x))\n  }\n  \n  /**\n   * A token wraps a string representation of a token\n   * as it is passed through the text processing pipeline.\n   *\n   * @constructor\n   * @param {string} [str=''] - The string token being wrapped.\n   * @param {object} [metadata={}] - Metadata associated with this token.\n   */\n  lunr.Token = function (str, metadata) {\n    this.str = str || \"\"\n    this.metadata = metadata || {}\n  }\n  \n  /**\n   * Returns the token string that is being wrapped by this object.\n   *\n   * @returns {string}\n   */\n  lunr.Token.prototype.toString = function () {\n    return this.str\n  }\n  \n  /**\n   * A token update function is used when updating or optionally\n   * when cloning a token.\n   *\n   * @callback lunr.Token~updateFunction\n   * @param {string} str - The string representation of the token.\n   * @param {Object} metadata - All metadata associated with this token.\n   */\n  \n  /**\n   * Applies the given function to the wrapped string token.\n   *\n   * @example\n   * token.update(function (str, metadata) {\n   *   return str.toUpperCase()\n   * })\n   *\n   * @param {lunr.Token~updateFunction} fn - A function to apply to the token string.\n   * @returns {lunr.Token}\n   */\n  lunr.Token.prototype.update = function (fn) {\n    this.str = fn(this.str, this.metadata)\n    return this\n  }\n  \n  /**\n   * Creates a clone of this token. Optionally a function can be\n   * applied to the cloned token.\n   *\n   * @param {lunr.Token~updateFunction} [fn] - An optional function to apply to the cloned token.\n   * @returns {lunr.Token}\n   */\n  lunr.Token.prototype.clone = function (fn) {\n    fn = fn || function (s) { return s }\n    return new lunr.Token (fn(this.str, this.metadata), this.metadata)\n  }\n  /*!\n   * lunr.tokenizer\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A function for splitting a string into tokens ready to be inserted into\n   * the search index. Uses `lunr.tokenizer.separator` to split strings, change\n   * the value of this property to change how strings are split into tokens.\n   *\n   * This tokenizer will convert its parameter to a string by calling `toString` and\n   * then will split this string on the character in `lunr.tokenizer.separator`.\n   * Arrays will have their elements converted to strings and wrapped in a lunr.Token.\n   *\n   * Optional metadata can be passed to the tokenizer, this metadata will be cloned and\n   * added as metadata to every token that is created from the object to be tokenized.\n   *\n   * @static\n   * @param {?(string|object|object[])} obj - The object to convert into tokens\n   * @param {?object} metadata - Optional metadata to associate with every token\n   * @returns {lunr.Token[]}\n   * @see {@link lunr.Pipeline}\n   */\n  lunr.tokenizer = function (obj, metadata) {\n    if (obj == null || obj == undefined) {\n      return []\n    }\n  \n    if (Array.isArray(obj)) {\n      return obj.map(function (t) {\n        return new lunr.Token(\n          lunr.utils.asString(t).toLowerCase(),\n          lunr.utils.clone(metadata)\n        )\n      })\n    }\n  \n    var str = obj.toString().trim().toLowerCase(),\n        len = str.length,\n        tokens = []\n  \n    for (var sliceEnd = 0, sliceStart = 0; sliceEnd <= len; sliceEnd++) {\n      var char = str.charAt(sliceEnd),\n          sliceLength = sliceEnd - sliceStart\n  \n      if ((char.match(lunr.tokenizer.separator) || sliceEnd == len)) {\n  \n        if (sliceLength > 0) {\n          var tokenMetadata = lunr.utils.clone(metadata) || {}\n          tokenMetadata[\"position\"] = [sliceStart, sliceLength]\n          tokenMetadata[\"index\"] = tokens.length\n  \n          tokens.push(\n            new lunr.Token (\n              str.slice(sliceStart, sliceEnd),\n              tokenMetadata\n            )\n          )\n        }\n  \n        sliceStart = sliceEnd + 1\n      }\n  \n    }\n  \n    return tokens\n  }\n  \n  /**\n   * The separator used to split a string into tokens. Override this property to change the behaviour of\n   * `lunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\n   *\n   * @static\n   * @see lunr.tokenizer\n   */\n  lunr.tokenizer.separator = /[\\s\\-]+/\n  /*!\n   * lunr.Pipeline\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * lunr.Pipelines maintain an ordered list of functions to be applied to all\n   * tokens in documents entering the search index and queries being ran against\n   * the index.\n   *\n   * An instance of lunr.Index created with the lunr shortcut will contain a\n   * pipeline with a stop word filter and an English language stemmer. Extra\n   * functions can be added before or after either of these functions or these\n   * default functions can be removed.\n   *\n   * When run the pipeline will call each function in turn, passing a token, the\n   * index of that token in the original list of all tokens and finally a list of\n   * all the original tokens.\n   *\n   * The output of functions in the pipeline will be passed to the next function\n   * in the pipeline. To exclude a token from entering the index the function\n   * should return undefined, the rest of the pipeline will not be called with\n   * this token.\n   *\n   * For serialisation of pipelines to work, all functions used in an instance of\n   * a pipeline should be registered with lunr.Pipeline. Registered functions can\n   * then be loaded. If trying to load a serialised pipeline that uses functions\n   * that are not registered an error will be thrown.\n   *\n   * If not planning on serialising the pipeline then registering pipeline functions\n   * is not necessary.\n   *\n   * @constructor\n   */\n  lunr.Pipeline = function () {\n    this._stack = []\n  }\n  \n  lunr.Pipeline.registeredFunctions = Object.create(null)\n  \n  /**\n   * A pipeline function maps lunr.Token to lunr.Token. A lunr.Token contains the token\n   * string as well as all known metadata. A pipeline function can mutate the token string\n   * or mutate (or add) metadata for a given token.\n   *\n   * A pipeline function can indicate that the passed token should be discarded by returning\n   * null. This token will not be passed to any downstream pipeline functions and will not be\n   * added to the index.\n   *\n   * Multiple tokens can be returned by returning an array of tokens. Each token will be passed\n   * to any downstream pipeline functions and all will returned tokens will be added to the index.\n   *\n   * Any number of pipeline functions may be chained together using a lunr.Pipeline.\n   *\n   * @interface lunr.PipelineFunction\n   * @param {lunr.Token} token - A token from the document being processed.\n   * @param {number} i - The index of this token in the complete list of tokens for this document/field.\n   * @param {lunr.Token[]} tokens - All tokens for this document/field.\n   * @returns {(?lunr.Token|lunr.Token[])}\n   */\n  \n  /**\n   * Register a function with the pipeline.\n   *\n   * Functions that are used in the pipeline should be registered if the pipeline\n   * needs to be serialised, or a serialised pipeline needs to be loaded.\n   *\n   * Registering a function does not add it to a pipeline, functions must still be\n   * added to instances of the pipeline for them to be used when running a pipeline.\n   *\n   * @param {lunr.PipelineFunction} fn - The function to check for.\n   * @param {String} label - The label to register this function with\n   */\n  lunr.Pipeline.registerFunction = function (fn, label) {\n    if (label in this.registeredFunctions) {\n      lunr.utils.warn('Overwriting existing registered function: ' + label)\n    }\n  \n    fn.label = label\n    lunr.Pipeline.registeredFunctions[fn.label] = fn\n  }\n  \n  /**\n   * Warns if the function is not registered as a Pipeline function.\n   *\n   * @param {lunr.PipelineFunction} fn - The function to check for.\n   * @private\n   */\n  lunr.Pipeline.warnIfFunctionNotRegistered = function (fn) {\n    var isRegistered = fn.label && (fn.label in this.registeredFunctions)\n  \n    if (!isRegistered) {\n      lunr.utils.warn('Function is not registered with pipeline. This may cause problems when serialising the index.\\n', fn)\n    }\n  }\n  \n  /**\n   * Loads a previously serialised pipeline.\n   *\n   * All functions to be loaded must already be registered with lunr.Pipeline.\n   * If any function from the serialised data has not been registered then an\n   * error will be thrown.\n   *\n   * @param {Object} serialised - The serialised pipeline to load.\n   * @returns {lunr.Pipeline}\n   */\n  lunr.Pipeline.load = function (serialised) {\n    var pipeline = new lunr.Pipeline\n  \n    serialised.forEach(function (fnName) {\n      var fn = lunr.Pipeline.registeredFunctions[fnName]\n  \n      if (fn) {\n        pipeline.add(fn)\n      } else {\n        throw new Error('Cannot load unregistered function: ' + fnName)\n      }\n    })\n  \n    return pipeline\n  }\n  \n  /**\n   * Adds new functions to the end of the pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction[]} functions - Any number of functions to add to the pipeline.\n   */\n  lunr.Pipeline.prototype.add = function () {\n    var fns = Array.prototype.slice.call(arguments)\n  \n    fns.forEach(function (fn) {\n      lunr.Pipeline.warnIfFunctionNotRegistered(fn)\n      this._stack.push(fn)\n    }, this)\n  }\n  \n  /**\n   * Adds a single function after a function that already exists in the\n   * pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n   * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n   */\n  lunr.Pipeline.prototype.after = function (existingFn, newFn) {\n    lunr.Pipeline.warnIfFunctionNotRegistered(newFn)\n  \n    var pos = this._stack.indexOf(existingFn)\n    if (pos == -1) {\n      throw new Error('Cannot find existingFn')\n    }\n  \n    pos = pos + 1\n    this._stack.splice(pos, 0, newFn)\n  }\n  \n  /**\n   * Adds a single function before a function that already exists in the\n   * pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n   * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n   */\n  lunr.Pipeline.prototype.before = function (existingFn, newFn) {\n    lunr.Pipeline.warnIfFunctionNotRegistered(newFn)\n  \n    var pos = this._stack.indexOf(existingFn)\n    if (pos == -1) {\n      throw new Error('Cannot find existingFn')\n    }\n  \n    this._stack.splice(pos, 0, newFn)\n  }\n  \n  /**\n   * Removes a function from the pipeline.\n   *\n   * @param {lunr.PipelineFunction} fn The function to remove from the pipeline.\n   */\n  lunr.Pipeline.prototype.remove = function (fn) {\n    var pos = this._stack.indexOf(fn)\n    if (pos == -1) {\n      return\n    }\n  \n    this._stack.splice(pos, 1)\n  }\n  \n  /**\n   * Runs the current list of functions that make up the pipeline against the\n   * passed tokens.\n   *\n   * @param {Array} tokens The tokens to run through the pipeline.\n   * @returns {Array}\n   */\n  lunr.Pipeline.prototype.run = function (tokens) {\n    var stackLength = this._stack.length\n  \n    for (var i = 0; i < stackLength; i++) {\n      var fn = this._stack[i]\n      var memo = []\n  \n      for (var j = 0; j < tokens.length; j++) {\n        var result = fn(tokens[j], j, tokens)\n  \n        if (result === void 0 || result === '') continue\n  \n        if (result instanceof Array) {\n          for (var k = 0; k < result.length; k++) {\n            memo.push(result[k])\n          }\n        } else {\n          memo.push(result)\n        }\n      }\n  \n      tokens = memo\n    }\n  \n    return tokens\n  }\n  \n  /**\n   * Convenience method for passing a string through a pipeline and getting\n   * strings out. This method takes care of wrapping the passed string in a\n   * token and mapping the resulting tokens back to strings.\n   *\n   * @param {string} str - The string to pass through the pipeline.\n   * @param {?object} metadata - Optional metadata to associate with the token\n   * passed to the pipeline.\n   * @returns {string[]}\n   */\n  lunr.Pipeline.prototype.runString = function (str, metadata) {\n    var token = new lunr.Token (str, metadata)\n  \n    return this.run([token]).map(function (t) {\n      return t.toString()\n    })\n  }\n  \n  /**\n   * Resets the pipeline by removing any existing processors.\n   *\n   */\n  lunr.Pipeline.prototype.reset = function () {\n    this._stack = []\n  }\n  \n  /**\n   * Returns a representation of the pipeline ready for serialisation.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @returns {Array}\n   */\n  lunr.Pipeline.prototype.toJSON = function () {\n    return this._stack.map(function (fn) {\n      lunr.Pipeline.warnIfFunctionNotRegistered(fn)\n  \n      return fn.label\n    })\n  }\n  /*!\n   * lunr.Vector\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A vector is used to construct the vector space of documents and queries. These\n   * vectors support operations to determine the similarity between two documents or\n   * a document and a query.\n   *\n   * Normally no parameters are required for initializing a vector, but in the case of\n   * loading a previously dumped vector the raw elements can be provided to the constructor.\n   *\n   * For performance reasons vectors are implemented with a flat array, where an elements\n   * index is immediately followed by its value. E.g. [index, value, index, value]. This\n   * allows the underlying array to be as sparse as possible and still offer decent\n   * performance when being used for vector calculations.\n   *\n   * @constructor\n   * @param {Number[]} [elements] - The flat list of element index and element value pairs.\n   */\n  lunr.Vector = function (elements) {\n    this._magnitude = 0\n    this.elements = elements || []\n  }\n  \n  \n  /**\n   * Calculates the position within the vector to insert a given index.\n   *\n   * This is used internally by insert and upsert. If there are duplicate indexes then\n   * the position is returned as if the value for that index were to be updated, but it\n   * is the callers responsibility to check whether there is a duplicate at that index\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @returns {Number}\n   */\n  lunr.Vector.prototype.positionForIndex = function (index) {\n    // For an empty vector the tuple can be inserted at the beginning\n    if (this.elements.length == 0) {\n      return 0\n    }\n  \n    var start = 0,\n        end = this.elements.length / 2,\n        sliceLength = end - start,\n        pivotPoint = Math.floor(sliceLength / 2),\n        pivotIndex = this.elements[pivotPoint * 2]\n  \n    while (sliceLength > 1) {\n      if (pivotIndex < index) {\n        start = pivotPoint\n      }\n  \n      if (pivotIndex > index) {\n        end = pivotPoint\n      }\n  \n      if (pivotIndex == index) {\n        break\n      }\n  \n      sliceLength = end - start\n      pivotPoint = start + Math.floor(sliceLength / 2)\n      pivotIndex = this.elements[pivotPoint * 2]\n    }\n  \n    if (pivotIndex == index) {\n      return pivotPoint * 2\n    }\n  \n    if (pivotIndex > index) {\n      return pivotPoint * 2\n    }\n  \n    if (pivotIndex < index) {\n      return (pivotPoint + 1) * 2\n    }\n  }\n  \n  /**\n   * Inserts an element at an index within the vector.\n   *\n   * Does not allow duplicates, will throw an error if there is already an entry\n   * for this index.\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @param {Number} val - The value to be inserted into the vector.\n   */\n  lunr.Vector.prototype.insert = function (insertIdx, val) {\n    this.upsert(insertIdx, val, function () {\n      throw \"duplicate index\"\n    })\n  }\n  \n  /**\n   * Inserts or updates an existing index within the vector.\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @param {Number} val - The value to be inserted into the vector.\n   * @param {function} fn - A function that is called for updates, the existing value and the\n   * requested value are passed as arguments\n   */\n  lunr.Vector.prototype.upsert = function (insertIdx, val, fn) {\n    this._magnitude = 0\n    var position = this.positionForIndex(insertIdx)\n  \n    if (this.elements[position] == insertIdx) {\n      this.elements[position + 1] = fn(this.elements[position + 1], val)\n    } else {\n      this.elements.splice(position, 0, insertIdx, val)\n    }\n  }\n  \n  /**\n   * Calculates the magnitude of this vector.\n   *\n   * @returns {Number}\n   */\n  lunr.Vector.prototype.magnitude = function () {\n    if (this._magnitude) return this._magnitude\n  \n    var sumOfSquares = 0,\n        elementsLength = this.elements.length\n  \n    for (var i = 1; i < elementsLength; i += 2) {\n      var val = this.elements[i]\n      sumOfSquares += val * val\n    }\n  \n    return this._magnitude = Math.sqrt(sumOfSquares)\n  }\n  \n  /**\n   * Calculates the dot product of this vector and another vector.\n   *\n   * @param {lunr.Vector} otherVector - The vector to compute the dot product with.\n   * @returns {Number}\n   */\n  lunr.Vector.prototype.dot = function (otherVector) {\n    var dotProduct = 0,\n        a = this.elements, b = otherVector.elements,\n        aLen = a.length, bLen = b.length,\n        aVal = 0, bVal = 0,\n        i = 0, j = 0\n  \n    while (i < aLen && j < bLen) {\n      aVal = a[i], bVal = b[j]\n      if (aVal < bVal) {\n        i += 2\n      } else if (aVal > bVal) {\n        j += 2\n      } else if (aVal == bVal) {\n        dotProduct += a[i + 1] * b[j + 1]\n        i += 2\n        j += 2\n      }\n    }\n  \n    return dotProduct\n  }\n  \n  /**\n   * Calculates the similarity between this vector and another vector.\n   *\n   * @param {lunr.Vector} otherVector - The other vector to calculate the\n   * similarity with.\n   * @returns {Number}\n   */\n  lunr.Vector.prototype.similarity = function (otherVector) {\n    return this.dot(otherVector) / this.magnitude() || 0\n  }\n  \n  /**\n   * Converts the vector to an array of the elements within the vector.\n   *\n   * @returns {Number[]}\n   */\n  lunr.Vector.prototype.toArray = function () {\n    var output = new Array (this.elements.length / 2)\n  \n    for (var i = 1, j = 0; i < this.elements.length; i += 2, j++) {\n      output[j] = this.elements[i]\n    }\n  \n    return output\n  }\n  \n  /**\n   * A JSON serializable representation of the vector.\n   *\n   * @returns {Number[]}\n   */\n  lunr.Vector.prototype.toJSON = function () {\n    return this.elements\n  }\n  /* eslint-disable */\n  /*!\n   * lunr.stemmer\n   * Copyright (C) 2018 Oliver Nightingale\n   * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n   */\n  \n  /**\n   * lunr.stemmer is an english language stemmer, this is a JavaScript\n   * implementation of the PorterStemmer taken from http://tartarus.org/~martin\n   *\n   * @static\n   * @implements {lunr.PipelineFunction}\n   * @param {lunr.Token} token - The string to stem\n   * @returns {lunr.Token}\n   * @see {@link lunr.Pipeline}\n   * @function\n   */\n  lunr.stemmer = (function(){\n    var step2list = {\n        \"ational\" : \"ate\",\n        \"tional\" : \"tion\",\n        \"enci\" : \"ence\",\n        \"anci\" : \"ance\",\n        \"izer\" : \"ize\",\n        \"bli\" : \"ble\",\n        \"alli\" : \"al\",\n        \"entli\" : \"ent\",\n        \"eli\" : \"e\",\n        \"ousli\" : \"ous\",\n        \"ization\" : \"ize\",\n        \"ation\" : \"ate\",\n        \"ator\" : \"ate\",\n        \"alism\" : \"al\",\n        \"iveness\" : \"ive\",\n        \"fulness\" : \"ful\",\n        \"ousness\" : \"ous\",\n        \"aliti\" : \"al\",\n        \"iviti\" : \"ive\",\n        \"biliti\" : \"ble\",\n        \"logi\" : \"log\"\n      },\n  \n      step3list = {\n        \"icate\" : \"ic\",\n        \"ative\" : \"\",\n        \"alize\" : \"al\",\n        \"iciti\" : \"ic\",\n        \"ical\" : \"ic\",\n        \"ful\" : \"\",\n        \"ness\" : \"\"\n      },\n  \n      c = \"[^aeiou]\",          // consonant\n      v = \"[aeiouy]\",          // vowel\n      C = c + \"[^aeiouy]*\",    // consonant sequence\n      V = v + \"[aeiou]*\",      // vowel sequence\n  \n      mgr0 = \"^(\" + C + \")?\" + V + C,               // [C]VC... is m>0\n      meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\",  // [C]VC[V] is m=1\n      mgr1 = \"^(\" + C + \")?\" + V + C + V + C,       // [C]VCVC... is m>1\n      s_v = \"^(\" + C + \")?\" + v;                   // vowel in stem\n  \n    var re_mgr0 = new RegExp(mgr0);\n    var re_mgr1 = new RegExp(mgr1);\n    var re_meq1 = new RegExp(meq1);\n    var re_s_v = new RegExp(s_v);\n  \n    var re_1a = /^(.+?)(ss|i)es$/;\n    var re2_1a = /^(.+?)([^s])s$/;\n    var re_1b = /^(.+?)eed$/;\n    var re2_1b = /^(.+?)(ed|ing)$/;\n    var re_1b_2 = /.$/;\n    var re2_1b_2 = /(at|bl|iz)$/;\n    var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n    var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n  \n    var re_1c = /^(.+?[^aeiou])y$/;\n    var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n  \n    var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n  \n    var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n    var re2_4 = /^(.+?)(s|t)(ion)$/;\n  \n    var re_5 = /^(.+?)e$/;\n    var re_5_1 = /ll$/;\n    var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n  \n    var porterStemmer = function porterStemmer(w) {\n      var stem,\n        suffix,\n        firstch,\n        re,\n        re2,\n        re3,\n        re4;\n  \n      if (w.length < 3) { return w; }\n  \n      firstch = w.substr(0,1);\n      if (firstch == \"y\") {\n        w = firstch.toUpperCase() + w.substr(1);\n      }\n  \n      // Step 1a\n      re = re_1a\n      re2 = re2_1a;\n  \n      if (re.test(w)) { w = w.replace(re,\"$1$2\"); }\n      else if (re2.test(w)) { w = w.replace(re2,\"$1$2\"); }\n  \n      // Step 1b\n      re = re_1b;\n      re2 = re2_1b;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        re = re_mgr0;\n        if (re.test(fp[1])) {\n          re = re_1b_2;\n          w = w.replace(re,\"\");\n        }\n      } else if (re2.test(w)) {\n        var fp = re2.exec(w);\n        stem = fp[1];\n        re2 = re_s_v;\n        if (re2.test(stem)) {\n          w = stem;\n          re2 = re2_1b_2;\n          re3 = re3_1b_2;\n          re4 = re4_1b_2;\n          if (re2.test(w)) { w = w + \"e\"; }\n          else if (re3.test(w)) { re = re_1b_2; w = w.replace(re,\"\"); }\n          else if (re4.test(w)) { w = w + \"e\"; }\n        }\n      }\n  \n      // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\n      re = re_1c;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        w = stem + \"i\";\n      }\n  \n      // Step 2\n      re = re_2;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        suffix = fp[2];\n        re = re_mgr0;\n        if (re.test(stem)) {\n          w = stem + step2list[suffix];\n        }\n      }\n  \n      // Step 3\n      re = re_3;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        suffix = fp[2];\n        re = re_mgr0;\n        if (re.test(stem)) {\n          w = stem + step3list[suffix];\n        }\n      }\n  \n      // Step 4\n      re = re_4;\n      re2 = re2_4;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        re = re_mgr1;\n        if (re.test(stem)) {\n          w = stem;\n        }\n      } else if (re2.test(w)) {\n        var fp = re2.exec(w);\n        stem = fp[1] + fp[2];\n        re2 = re_mgr1;\n        if (re2.test(stem)) {\n          w = stem;\n        }\n      }\n  \n      // Step 5\n      re = re_5;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        re = re_mgr1;\n        re2 = re_meq1;\n        re3 = re3_5;\n        if (re.test(stem) || (re2.test(stem) && !(re3.test(stem)))) {\n          w = stem;\n        }\n      }\n  \n      re = re_5_1;\n      re2 = re_mgr1;\n      if (re.test(w) && re2.test(w)) {\n        re = re_1b_2;\n        w = w.replace(re,\"\");\n      }\n  \n      // and turn initial Y back to y\n  \n      if (firstch == \"y\") {\n        w = firstch.toLowerCase() + w.substr(1);\n      }\n  \n      return w;\n    };\n  \n    return function (token) {\n      return token.update(porterStemmer);\n    }\n  })();\n  \n  lunr.Pipeline.registerFunction(lunr.stemmer, 'stemmer')\n  /*!\n   * lunr.stopWordFilter\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * lunr.generateStopWordFilter builds a stopWordFilter function from the provided\n   * list of stop words.\n   *\n   * The built in lunr.stopWordFilter is built using this generator and can be used\n   * to generate custom stopWordFilters for applications or non English languages.\n   *\n   * @function\n   * @param {Array} token The token to pass through the filter\n   * @returns {lunr.PipelineFunction}\n   * @see lunr.Pipeline\n   * @see lunr.stopWordFilter\n   */\n  lunr.generateStopWordFilter = function (stopWords) {\n    var words = stopWords.reduce(function (memo, stopWord) {\n      memo[stopWord] = stopWord\n      return memo\n    }, {})\n  \n    return function (token) {\n      if (token && words[token.toString()] !== token.toString()) return token\n    }\n  }\n  \n  /**\n   * lunr.stopWordFilter is an English language stop word list filter, any words\n   * contained in the list will not be passed through the filter.\n   *\n   * This is intended to be used in the Pipeline. If the token does not pass the\n   * filter then undefined will be returned.\n   *\n   * @function\n   * @implements {lunr.PipelineFunction}\n   * @params {lunr.Token} token - A token to check for being a stop word.\n   * @returns {lunr.Token}\n   * @see {@link lunr.Pipeline}\n   */\n  lunr.stopWordFilter = lunr.generateStopWordFilter([\n    'a',\n    'able',\n    'about',\n    'across',\n    'after',\n    'all',\n    'almost',\n    'also',\n    'am',\n    'among',\n    'an',\n    'and',\n    'any',\n    'are',\n    'as',\n    'at',\n    'be',\n    'because',\n    'been',\n    'but',\n    'by',\n    'can',\n    'cannot',\n    'could',\n    'dear',\n    'did',\n    'do',\n    'does',\n    'either',\n    'else',\n    'ever',\n    'every',\n    'for',\n    'from',\n    'get',\n    'got',\n    'had',\n    'has',\n    'have',\n    'he',\n    'her',\n    'hers',\n    'him',\n    'his',\n    'how',\n    'however',\n    'i',\n    'if',\n    'in',\n    'into',\n    'is',\n    'it',\n    'its',\n    'just',\n    'least',\n    'let',\n    'like',\n    'likely',\n    'may',\n    'me',\n    'might',\n    'most',\n    'must',\n    'my',\n    'neither',\n    'no',\n    'nor',\n    'not',\n    'of',\n    'off',\n    'often',\n    'on',\n    'only',\n    'or',\n    'other',\n    'our',\n    'own',\n    'rather',\n    'said',\n    'say',\n    'says',\n    'she',\n    'should',\n    'since',\n    'so',\n    'some',\n    'than',\n    'that',\n    'the',\n    'their',\n    'them',\n    'then',\n    'there',\n    'these',\n    'they',\n    'this',\n    'tis',\n    'to',\n    'too',\n    'twas',\n    'us',\n    'wants',\n    'was',\n    'we',\n    'were',\n    'what',\n    'when',\n    'where',\n    'which',\n    'while',\n    'who',\n    'whom',\n    'why',\n    'will',\n    'with',\n    'would',\n    'yet',\n    'you',\n    'your'\n  ])\n  \n  lunr.Pipeline.registerFunction(lunr.stopWordFilter, 'stopWordFilter')\n  /*!\n   * lunr.trimmer\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * lunr.trimmer is a pipeline function for trimming non word\n   * characters from the beginning and end of tokens before they\n   * enter the index.\n   *\n   * This implementation may not work correctly for non latin\n   * characters and should either be removed or adapted for use\n   * with languages with non-latin characters.\n   *\n   * @static\n   * @implements {lunr.PipelineFunction}\n   * @param {lunr.Token} token The token to pass through the filter\n   * @returns {lunr.Token}\n   * @see lunr.Pipeline\n   */\n  lunr.trimmer = function (token) {\n    return token.update(function (s) {\n      return s.replace(/^\\W+/, '').replace(/\\W+$/, '')\n    })\n  }\n  \n  lunr.Pipeline.registerFunction(lunr.trimmer, 'trimmer')\n  /*!\n   * lunr.TokenSet\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A token set is used to store the unique list of all tokens\n   * within an index. Token sets are also used to represent an\n   * incoming query to the index, this query token set and index\n   * token set are then intersected to find which tokens to look\n   * up in the inverted index.\n   *\n   * A token set can hold multiple tokens, as in the case of the\n   * index token set, or it can hold a single token as in the\n   * case of a simple query token set.\n   *\n   * Additionally token sets are used to perform wildcard matching.\n   * Leading, contained and trailing wildcards are supported, and\n   * from this edit distance matching can also be provided.\n   *\n   * Token sets are implemented as a minimal finite state automata,\n   * where both common prefixes and suffixes are shared between tokens.\n   * This helps to reduce the space used for storing the token set.\n   *\n   * @constructor\n   */\n  lunr.TokenSet = function () {\n    this.final = false\n    this.edges = {}\n    this.id = lunr.TokenSet._nextId\n    lunr.TokenSet._nextId += 1\n  }\n  \n  /**\n   * Keeps track of the next, auto increment, identifier to assign\n   * to a new tokenSet.\n   *\n   * TokenSets require a unique identifier to be correctly minimised.\n   *\n   * @private\n   */\n  lunr.TokenSet._nextId = 1\n  \n  /**\n   * Creates a TokenSet instance from the given sorted array of words.\n   *\n   * @param {String[]} arr - A sorted array of strings to create the set from.\n   * @returns {lunr.TokenSet}\n   * @throws Will throw an error if the input array is not sorted.\n   */\n  lunr.TokenSet.fromArray = function (arr) {\n    var builder = new lunr.TokenSet.Builder\n  \n    for (var i = 0, len = arr.length; i < len; i++) {\n      builder.insert(arr[i])\n    }\n  \n    builder.finish()\n    return builder.root\n  }\n  \n  /**\n   * Creates a token set from a query clause.\n   *\n   * @private\n   * @param {Object} clause - A single clause from lunr.Query.\n   * @param {string} clause.term - The query clause term.\n   * @param {number} [clause.editDistance] - The optional edit distance for the term.\n   * @returns {lunr.TokenSet}\n   */\n  lunr.TokenSet.fromClause = function (clause) {\n    if ('editDistance' in clause) {\n      return lunr.TokenSet.fromFuzzyString(clause.term, clause.editDistance)\n    } else {\n      return lunr.TokenSet.fromString(clause.term)\n    }\n  }\n  \n  /**\n   * Creates a token set representing a single string with a specified\n   * edit distance.\n   *\n   * Insertions, deletions, substitutions and transpositions are each\n   * treated as an edit distance of 1.\n   *\n   * Increasing the allowed edit distance will have a dramatic impact\n   * on the performance of both creating and intersecting these TokenSets.\n   * It is advised to keep the edit distance less than 3.\n   *\n   * @param {string} str - The string to create the token set from.\n   * @param {number} editDistance - The allowed edit distance to match.\n   * @returns {lunr.Vector}\n   */\n  lunr.TokenSet.fromFuzzyString = function (str, editDistance) {\n    var root = new lunr.TokenSet\n  \n    var stack = [{\n      node: root,\n      editsRemaining: editDistance,\n      str: str\n    }]\n  \n    while (stack.length) {\n      var frame = stack.pop()\n  \n      // no edit\n      if (frame.str.length > 0) {\n        var char = frame.str.charAt(0),\n            noEditNode\n  \n        if (char in frame.node.edges) {\n          noEditNode = frame.node.edges[char]\n        } else {\n          noEditNode = new lunr.TokenSet\n          frame.node.edges[char] = noEditNode\n        }\n  \n        if (frame.str.length == 1) {\n          noEditNode.final = true\n        } else {\n          stack.push({\n            node: noEditNode,\n            editsRemaining: frame.editsRemaining,\n            str: frame.str.slice(1)\n          })\n        }\n      }\n  \n      // deletion\n      // can only do a deletion if we have enough edits remaining\n      // and if there are characters left to delete in the string\n      if (frame.editsRemaining > 0 && frame.str.length > 1) {\n        var char = frame.str.charAt(1),\n            deletionNode\n  \n        if (char in frame.node.edges) {\n          deletionNode = frame.node.edges[char]\n        } else {\n          deletionNode = new lunr.TokenSet\n          frame.node.edges[char] = deletionNode\n        }\n  \n        if (frame.str.length <= 2) {\n          deletionNode.final = true\n        } else {\n          stack.push({\n            node: deletionNode,\n            editsRemaining: frame.editsRemaining - 1,\n            str: frame.str.slice(2)\n          })\n        }\n      }\n  \n      // deletion\n      // just removing the last character from the str\n      if (frame.editsRemaining > 0 && frame.str.length == 1) {\n        frame.node.final = true\n      }\n  \n      // substitution\n      // can only do a substitution if we have enough edits remaining\n      // and if there are characters left to substitute\n      if (frame.editsRemaining > 0 && frame.str.length >= 1) {\n        if (\"*\" in frame.node.edges) {\n          var substitutionNode = frame.node.edges[\"*\"]\n        } else {\n          var substitutionNode = new lunr.TokenSet\n          frame.node.edges[\"*\"] = substitutionNode\n        }\n  \n        if (frame.str.length == 1) {\n          substitutionNode.final = true\n        } else {\n          stack.push({\n            node: substitutionNode,\n            editsRemaining: frame.editsRemaining - 1,\n            str: frame.str.slice(1)\n          })\n        }\n      }\n  \n      // insertion\n      // can only do insertion if there are edits remaining\n      if (frame.editsRemaining > 0) {\n        if (\"*\" in frame.node.edges) {\n          var insertionNode = frame.node.edges[\"*\"]\n        } else {\n          var insertionNode = new lunr.TokenSet\n          frame.node.edges[\"*\"] = insertionNode\n        }\n  \n        if (frame.str.length == 0) {\n          insertionNode.final = true\n        } else {\n          stack.push({\n            node: insertionNode,\n            editsRemaining: frame.editsRemaining - 1,\n            str: frame.str\n          })\n        }\n      }\n  \n      // transposition\n      // can only do a transposition if there are edits remaining\n      // and there are enough characters to transpose\n      if (frame.editsRemaining > 0 && frame.str.length > 1) {\n        var charA = frame.str.charAt(0),\n            charB = frame.str.charAt(1),\n            transposeNode\n  \n        if (charB in frame.node.edges) {\n          transposeNode = frame.node.edges[charB]\n        } else {\n          transposeNode = new lunr.TokenSet\n          frame.node.edges[charB] = transposeNode\n        }\n  \n        if (frame.str.length == 1) {\n          transposeNode.final = true\n        } else {\n          stack.push({\n            node: transposeNode,\n            editsRemaining: frame.editsRemaining - 1,\n            str: charA + frame.str.slice(2)\n          })\n        }\n      }\n    }\n  \n    return root\n  }\n  \n  /**\n   * Creates a TokenSet from a string.\n   *\n   * The string may contain one or more wildcard characters (*)\n   * that will allow wildcard matching when intersecting with\n   * another TokenSet.\n   *\n   * @param {string} str - The string to create a TokenSet from.\n   * @returns {lunr.TokenSet}\n   */\n  lunr.TokenSet.fromString = function (str) {\n    var node = new lunr.TokenSet,\n        root = node\n  \n    /*\n     * Iterates through all characters within the passed string\n     * appending a node for each character.\n     *\n     * When a wildcard character is found then a self\n     * referencing edge is introduced to continually match\n     * any number of any characters.\n     */\n    for (var i = 0, len = str.length; i < len; i++) {\n      var char = str[i],\n          final = (i == len - 1)\n  \n      if (char == \"*\") {\n        node.edges[char] = node\n        node.final = final\n  \n      } else {\n        var next = new lunr.TokenSet\n        next.final = final\n  \n        node.edges[char] = next\n        node = next\n      }\n    }\n  \n    return root\n  }\n  \n  /**\n   * Converts this TokenSet into an array of strings\n   * contained within the TokenSet.\n   *\n   * @returns {string[]}\n   */\n  lunr.TokenSet.prototype.toArray = function () {\n    var words = []\n  \n    var stack = [{\n      prefix: \"\",\n      node: this\n    }]\n  \n    while (stack.length) {\n      var frame = stack.pop(),\n          edges = Object.keys(frame.node.edges),\n          len = edges.length\n  \n      if (frame.node.final) {\n        /* In Safari, at this point the prefix is sometimes corrupted, see:\n         * https://github.com/olivernn/lunr.js/issues/279 Calling any\n         * String.prototype method forces Safari to \"cast\" this string to what\n         * it's supposed to be, fixing the bug. */\n        frame.prefix.charAt(0)\n        words.push(frame.prefix)\n      }\n  \n      for (var i = 0; i < len; i++) {\n        var edge = edges[i]\n  \n        stack.push({\n          prefix: frame.prefix.concat(edge),\n          node: frame.node.edges[edge]\n        })\n      }\n    }\n  \n    return words\n  }\n  \n  /**\n   * Generates a string representation of a TokenSet.\n   *\n   * This is intended to allow TokenSets to be used as keys\n   * in objects, largely to aid the construction and minimisation\n   * of a TokenSet. As such it is not designed to be a human\n   * friendly representation of the TokenSet.\n   *\n   * @returns {string}\n   */\n  lunr.TokenSet.prototype.toString = function () {\n    // NOTE: Using Object.keys here as this.edges is very likely\n    // to enter 'hash-mode' with many keys being added\n    //\n    // avoiding a for-in loop here as it leads to the function\n    // being de-optimised (at least in V8). From some simple\n    // benchmarks the performance is comparable, but allowing\n    // V8 to optimize may mean easy performance wins in the future.\n  \n    if (this._str) {\n      return this._str\n    }\n  \n    var str = this.final ? '1' : '0',\n        labels = Object.keys(this.edges).sort(),\n        len = labels.length\n  \n    for (var i = 0; i < len; i++) {\n      var label = labels[i],\n          node = this.edges[label]\n  \n      str = str + label + node.id\n    }\n  \n    return str\n  }\n  \n  /**\n   * Returns a new TokenSet that is the intersection of\n   * this TokenSet and the passed TokenSet.\n   *\n   * This intersection will take into account any wildcards\n   * contained within the TokenSet.\n   *\n   * @param {lunr.TokenSet} b - An other TokenSet to intersect with.\n   * @returns {lunr.TokenSet}\n   */\n  lunr.TokenSet.prototype.intersect = function (b) {\n    var output = new lunr.TokenSet,\n        frame = undefined\n  \n    var stack = [{\n      qNode: b,\n      output: output,\n      node: this\n    }]\n  \n    while (stack.length) {\n      frame = stack.pop()\n  \n      // NOTE: As with the #toString method, we are using\n      // Object.keys and a for loop instead of a for-in loop\n      // as both of these objects enter 'hash' mode, causing\n      // the function to be de-optimised in V8\n      var qEdges = Object.keys(frame.qNode.edges),\n          qLen = qEdges.length,\n          nEdges = Object.keys(frame.node.edges),\n          nLen = nEdges.length\n  \n      for (var q = 0; q < qLen; q++) {\n        var qEdge = qEdges[q]\n  \n        for (var n = 0; n < nLen; n++) {\n          var nEdge = nEdges[n]\n  \n          if (nEdge == qEdge || qEdge == '*') {\n            var node = frame.node.edges[nEdge],\n                qNode = frame.qNode.edges[qEdge],\n                final = node.final && qNode.final,\n                next = undefined\n  \n            if (nEdge in frame.output.edges) {\n              // an edge already exists for this character\n              // no need to create a new node, just set the finality\n              // bit unless this node is already final\n              next = frame.output.edges[nEdge]\n              next.final = next.final || final\n  \n            } else {\n              // no edge exists yet, must create one\n              // set the finality bit and insert it\n              // into the output\n              next = new lunr.TokenSet\n              next.final = final\n              frame.output.edges[nEdge] = next\n            }\n  \n            stack.push({\n              qNode: qNode,\n              output: next,\n              node: node\n            })\n          }\n        }\n      }\n    }\n  \n    return output\n  }\n  lunr.TokenSet.Builder = function () {\n    this.previousWord = \"\"\n    this.root = new lunr.TokenSet\n    this.uncheckedNodes = []\n    this.minimizedNodes = {}\n  }\n  \n  lunr.TokenSet.Builder.prototype.insert = function (word) {\n    var node,\n        commonPrefix = 0\n  \n    if (word < this.previousWord) {\n      throw new Error (\"Out of order word insertion\")\n    }\n  \n    for (var i = 0; i < word.length && i < this.previousWord.length; i++) {\n      if (word[i] != this.previousWord[i]) break\n      commonPrefix++\n    }\n  \n    this.minimize(commonPrefix)\n  \n    if (this.uncheckedNodes.length == 0) {\n      node = this.root\n    } else {\n      node = this.uncheckedNodes[this.uncheckedNodes.length - 1].child\n    }\n  \n    for (var i = commonPrefix; i < word.length; i++) {\n      var nextNode = new lunr.TokenSet,\n          char = word[i]\n  \n      node.edges[char] = nextNode\n  \n      this.uncheckedNodes.push({\n        parent: node,\n        char: char,\n        child: nextNode\n      })\n  \n      node = nextNode\n    }\n  \n    node.final = true\n    this.previousWord = word\n  }\n  \n  lunr.TokenSet.Builder.prototype.finish = function () {\n    this.minimize(0)\n  }\n  \n  lunr.TokenSet.Builder.prototype.minimize = function (downTo) {\n    for (var i = this.uncheckedNodes.length - 1; i >= downTo; i--) {\n      var node = this.uncheckedNodes[i],\n          childKey = node.child.toString()\n  \n      if (childKey in this.minimizedNodes) {\n        node.parent.edges[node.char] = this.minimizedNodes[childKey]\n      } else {\n        // Cache the key for this node since\n        // we know it can't change anymore\n        node.child._str = childKey\n  \n        this.minimizedNodes[childKey] = node.child\n      }\n  \n      this.uncheckedNodes.pop()\n    }\n  }\n  /*!\n   * lunr.Index\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * An index contains the built index of all documents and provides a query interface\n   * to the index.\n   *\n   * Usually instances of lunr.Index will not be created using this constructor, instead\n   * lunr.Builder should be used to construct new indexes, or lunr.Index.load should be\n   * used to load previously built and serialized indexes.\n   *\n   * @constructor\n   * @param {Object} attrs - The attributes of the built search index.\n   * @param {Object} attrs.invertedIndex - An index of term/field to document reference.\n   * @param {Object<string, lunr.Vector>} attrs.fieldVectors - Field vectors\n   * @param {lunr.TokenSet} attrs.tokenSet - An set of all corpus tokens.\n   * @param {string[]} attrs.fields - The names of indexed document fields.\n   * @param {lunr.Pipeline} attrs.pipeline - The pipeline to use for search terms.\n   */\n  lunr.Index = function (attrs) {\n    this.invertedIndex = attrs.invertedIndex\n    this.fieldVectors = attrs.fieldVectors\n    this.tokenSet = attrs.tokenSet\n    this.fields = attrs.fields\n    this.pipeline = attrs.pipeline\n  }\n  \n  /**\n   * A result contains details of a document matching a search query.\n   * @typedef {Object} lunr.Index~Result\n   * @property {string} ref - The reference of the document this result represents.\n   * @property {number} score - A number between 0 and 1 representing how similar this document is to the query.\n   * @property {lunr.MatchData} matchData - Contains metadata about this match including which term(s) caused the match.\n   */\n  \n  /**\n   * Although lunr provides the ability to create queries using lunr.Query, it also provides a simple\n   * query language which itself is parsed into an instance of lunr.Query.\n   *\n   * For programmatically building queries it is advised to directly use lunr.Query, the query language\n   * is best used for human entered text rather than program generated text.\n   *\n   * At its simplest queries can just be a single term, e.g. `hello`, multiple terms are also supported\n   * and will be combined with OR, e.g `hello world` will match documents that contain either 'hello'\n   * or 'world', though those that contain both will rank higher in the results.\n   *\n   * Wildcards can be included in terms to match one or more unspecified characters, these wildcards can\n   * be inserted anywhere within the term, and more than one wildcard can exist in a single term. Adding\n   * wildcards will increase the number of documents that will be found but can also have a negative\n   * impact on query performance, especially with wildcards at the beginning of a term.\n   *\n   * Terms can be restricted to specific fields, e.g. `title:hello`, only documents with the term\n   * hello in the title field will match this query. Using a field not present in the index will lead\n   * to an error being thrown.\n   *\n   * Modifiers can also be added to terms, lunr supports edit distance and boost modifiers on terms. A term\n   * boost will make documents matching that term score higher, e.g. `foo^5`. Edit distance is also supported\n   * to provide fuzzy matching, e.g. 'hello~2' will match documents with hello with an edit distance of 2.\n   * Avoid large values for edit distance to improve query performance.\n   *\n   * Each term also supports a presence modifier. By default a term's presence in document is optional, however\n   * this can be changed to either required or prohibited. For a term's presence to be required in a document the\n   * term should be prefixed with a '+', e.g. `+foo bar` is a search for documents that must contain 'foo' and\n   * optionally contain 'bar'. Conversely a leading '-' sets the terms presence to prohibited, i.e. it must not\n   * appear in a document, e.g. `-foo bar` is a search for documents that do not contain 'foo' but may contain 'bar'.\n   *\n   * To escape special characters the backslash character '\\' can be used, this allows searches to include\n   * characters that would normally be considered modifiers, e.g. `foo\\~2` will search for a term \"foo~2\" instead\n   * of attempting to apply a boost of 2 to the search term \"foo\".\n   *\n   * @typedef {string} lunr.Index~QueryString\n   * @example <caption>Simple single term query</caption>\n   * hello\n   * @example <caption>Multiple term query</caption>\n   * hello world\n   * @example <caption>term scoped to a field</caption>\n   * title:hello\n   * @example <caption>term with a boost of 10</caption>\n   * hello^10\n   * @example <caption>term with an edit distance of 2</caption>\n   * hello~2\n   * @example <caption>terms with presence modifiers</caption>\n   * -foo +bar baz\n   */\n  \n  /**\n   * Performs a search against the index using lunr query syntax.\n   *\n   * Results will be returned sorted by their score, the most relevant results\n   * will be returned first.  For details on how the score is calculated, please see\n   * the {@link https://lunrjs.com/guides/searching.html#scoring|guide}.\n   *\n   * For more programmatic querying use lunr.Index#query.\n   *\n   * @param {lunr.Index~QueryString} queryString - A string containing a lunr query.\n   * @throws {lunr.QueryParseError} If the passed query string cannot be parsed.\n   * @returns {lunr.Index~Result[]}\n   */\n  lunr.Index.prototype.search = function (queryString) {\n    return this.query(function (query) {\n      var parser = new lunr.QueryParser(queryString, query)\n      parser.parse()\n    })\n  }\n  \n  /**\n   * A query builder callback provides a query object to be used to express\n   * the query to perform on the index.\n   *\n   * @callback lunr.Index~queryBuilder\n   * @param {lunr.Query} query - The query object to build up.\n   * @this lunr.Query\n   */\n  \n  /**\n   * Performs a query against the index using the yielded lunr.Query object.\n   *\n   * If performing programmatic queries against the index, this method is preferred\n   * over lunr.Index#search so as to avoid the additional query parsing overhead.\n   *\n   * A query object is yielded to the supplied function which should be used to\n   * express the query to be run against the index.\n   *\n   * Note that although this function takes a callback parameter it is _not_ an\n   * asynchronous operation, the callback is just yielded a query object to be\n   * customized.\n   *\n   * @param {lunr.Index~queryBuilder} fn - A function that is used to build the query.\n   * @returns {lunr.Index~Result[]}\n   */\n  lunr.Index.prototype.query = function (fn) {\n    // for each query clause\n    // * process terms\n    // * expand terms from token set\n    // * find matching documents and metadata\n    // * get document vectors\n    // * score documents\n  \n    var query = new lunr.Query(this.fields),\n        matchingFields = Object.create(null),\n        queryVectors = Object.create(null),\n        termFieldCache = Object.create(null),\n        requiredMatches = Object.create(null),\n        prohibitedMatches = Object.create(null)\n  \n    /*\n     * To support field level boosts a query vector is created per\n     * field. An empty vector is eagerly created to support negated\n     * queries.\n     */\n    for (var i = 0; i < this.fields.length; i++) {\n      queryVectors[this.fields[i]] = new lunr.Vector\n    }\n  \n    fn.call(query, query)\n  \n    for (var i = 0; i < query.clauses.length; i++) {\n      /*\n       * Unless the pipeline has been disabled for this term, which is\n       * the case for terms with wildcards, we need to pass the clause\n       * term through the search pipeline. A pipeline returns an array\n       * of processed terms. Pipeline functions may expand the passed\n       * term, which means we may end up performing multiple index lookups\n       * for a single query term.\n       */\n      var clause = query.clauses[i],\n          terms = null,\n          clauseMatches = lunr.Set.complete\n  \n      if (clause.usePipeline) {\n        terms = this.pipeline.runString(clause.term, {\n          fields: clause.fields\n        })\n      } else {\n        terms = [clause.term]\n      }\n  \n      for (var m = 0; m < terms.length; m++) {\n        var term = terms[m]\n  \n        /*\n         * Each term returned from the pipeline needs to use the same query\n         * clause object, e.g. the same boost and or edit distance. The\n         * simplest way to do this is to re-use the clause object but mutate\n         * its term property.\n         */\n        clause.term = term\n  \n        /*\n         * From the term in the clause we create a token set which will then\n         * be used to intersect the indexes token set to get a list of terms\n         * to lookup in the inverted index\n         */\n        var termTokenSet = lunr.TokenSet.fromClause(clause),\n            expandedTerms = this.tokenSet.intersect(termTokenSet).toArray()\n  \n        /*\n         * If a term marked as required does not exist in the tokenSet it is\n         * impossible for the search to return any matches. We set all the field\n         * scoped required matches set to empty and stop examining any further\n         * clauses.\n         */\n        if (expandedTerms.length === 0 && clause.presence === lunr.Query.presence.REQUIRED) {\n          for (var k = 0; k < clause.fields.length; k++) {\n            var field = clause.fields[k]\n            requiredMatches[field] = lunr.Set.empty\n          }\n  \n          break\n        }\n  \n        for (var j = 0; j < expandedTerms.length; j++) {\n          /*\n           * For each term get the posting and termIndex, this is required for\n           * building the query vector.\n           */\n          var expandedTerm = expandedTerms[j],\n              posting = this.invertedIndex[expandedTerm],\n              termIndex = posting._index\n  \n          for (var k = 0; k < clause.fields.length; k++) {\n            /*\n             * For each field that this query term is scoped by (by default\n             * all fields are in scope) we need to get all the document refs\n             * that have this term in that field.\n             *\n             * The posting is the entry in the invertedIndex for the matching\n             * term from above.\n             */\n            var field = clause.fields[k],\n                fieldPosting = posting[field],\n                matchingDocumentRefs = Object.keys(fieldPosting),\n                termField = expandedTerm + \"/\" + field,\n                matchingDocumentsSet = new lunr.Set(matchingDocumentRefs)\n  \n            /*\n             * if the presence of this term is required ensure that the matching\n             * documents are added to the set of required matches for this clause.\n             *\n             */\n            if (clause.presence == lunr.Query.presence.REQUIRED) {\n              clauseMatches = clauseMatches.union(matchingDocumentsSet)\n  \n              if (requiredMatches[field] === undefined) {\n                requiredMatches[field] = lunr.Set.complete\n              }\n            }\n  \n            /*\n             * if the presence of this term is prohibited ensure that the matching\n             * documents are added to the set of prohibited matches for this field,\n             * creating that set if it does not yet exist.\n             */\n            if (clause.presence == lunr.Query.presence.PROHIBITED) {\n              if (prohibitedMatches[field] === undefined) {\n                prohibitedMatches[field] = lunr.Set.empty\n              }\n  \n              prohibitedMatches[field] = prohibitedMatches[field].union(matchingDocumentsSet)\n  \n              /*\n               * Prohibited matches should not be part of the query vector used for\n               * similarity scoring and no metadata should be extracted so we continue\n               * to the next field\n               */\n              continue\n            }\n  \n            /*\n             * The query field vector is populated using the termIndex found for\n             * the term and a unit value with the appropriate boost applied.\n             * Using upsert because there could already be an entry in the vector\n             * for the term we are working with. In that case we just add the scores\n             * together.\n             */\n            queryVectors[field].upsert(termIndex, clause.boost, function (a, b) { return a + b })\n  \n            /**\n             * If we've already seen this term, field combo then we've already collected\n             * the matching documents and metadata, no need to go through all that again\n             */\n            if (termFieldCache[termField]) {\n              continue\n            }\n  \n            for (var l = 0; l < matchingDocumentRefs.length; l++) {\n              /*\n               * All metadata for this term/field/document triple\n               * are then extracted and collected into an instance\n               * of lunr.MatchData ready to be returned in the query\n               * results\n               */\n              var matchingDocumentRef = matchingDocumentRefs[l],\n                  matchingFieldRef = new lunr.FieldRef (matchingDocumentRef, field),\n                  metadata = fieldPosting[matchingDocumentRef],\n                  fieldMatch\n  \n              if ((fieldMatch = matchingFields[matchingFieldRef]) === undefined) {\n                matchingFields[matchingFieldRef] = new lunr.MatchData (expandedTerm, field, metadata)\n              } else {\n                fieldMatch.add(expandedTerm, field, metadata)\n              }\n  \n            }\n  \n            termFieldCache[termField] = true\n          }\n        }\n      }\n  \n      /**\n       * If the presence was required we need to update the requiredMatches field sets.\n       * We do this after all fields for the term have collected their matches because\n       * the clause terms presence is required in _any_ of the fields not _all_ of the\n       * fields.\n       */\n      if (clause.presence === lunr.Query.presence.REQUIRED) {\n        for (var k = 0; k < clause.fields.length; k++) {\n          var field = clause.fields[k]\n          requiredMatches[field] = requiredMatches[field].intersect(clauseMatches)\n        }\n      }\n    }\n  \n    /**\n     * Need to combine the field scoped required and prohibited\n     * matching documents into a global set of required and prohibited\n     * matches\n     */\n    var allRequiredMatches = lunr.Set.complete,\n        allProhibitedMatches = lunr.Set.empty\n  \n    for (var i = 0; i < this.fields.length; i++) {\n      var field = this.fields[i]\n  \n      if (requiredMatches[field]) {\n        allRequiredMatches = allRequiredMatches.intersect(requiredMatches[field])\n      }\n  \n      if (prohibitedMatches[field]) {\n        allProhibitedMatches = allProhibitedMatches.union(prohibitedMatches[field])\n      }\n    }\n  \n    var matchingFieldRefs = Object.keys(matchingFields),\n        results = [],\n        matches = Object.create(null)\n  \n    /*\n     * If the query is negated (contains only prohibited terms)\n     * we need to get _all_ fieldRefs currently existing in the\n     * index. This is only done when we know that the query is\n     * entirely prohibited terms to avoid any cost of getting all\n     * fieldRefs unnecessarily.\n     *\n     * Additionally, blank MatchData must be created to correctly\n     * populate the results.\n     */\n    if (query.isNegated()) {\n      matchingFieldRefs = Object.keys(this.fieldVectors)\n  \n      for (var i = 0; i < matchingFieldRefs.length; i++) {\n        var matchingFieldRef = matchingFieldRefs[i]\n        var fieldRef = lunr.FieldRef.fromString(matchingFieldRef)\n        matchingFields[matchingFieldRef] = new lunr.MatchData\n      }\n    }\n  \n    for (var i = 0; i < matchingFieldRefs.length; i++) {\n      /*\n       * Currently we have document fields that match the query, but we\n       * need to return documents. The matchData and scores are combined\n       * from multiple fields belonging to the same document.\n       *\n       * Scores are calculated by field, using the query vectors created\n       * above, and combined into a final document score using addition.\n       */\n      var fieldRef = lunr.FieldRef.fromString(matchingFieldRefs[i]),\n          docRef = fieldRef.docRef\n  \n      if (!allRequiredMatches.contains(docRef)) {\n        continue\n      }\n  \n      if (allProhibitedMatches.contains(docRef)) {\n        continue\n      }\n  \n      var fieldVector = this.fieldVectors[fieldRef],\n          score = queryVectors[fieldRef.fieldName].similarity(fieldVector),\n          docMatch\n  \n      if ((docMatch = matches[docRef]) !== undefined) {\n        docMatch.score += score\n        docMatch.matchData.combine(matchingFields[fieldRef])\n      } else {\n        var match = {\n          ref: docRef,\n          score: score,\n          matchData: matchingFields[fieldRef]\n        }\n        matches[docRef] = match\n        results.push(match)\n      }\n    }\n  \n    /*\n     * Sort the results objects by score, highest first.\n     */\n    return results.sort(function (a, b) {\n      return b.score - a.score\n    })\n  }\n  \n  /**\n   * Prepares the index for JSON serialization.\n   *\n   * The schema for this JSON blob will be described in a\n   * separate JSON schema file.\n   *\n   * @returns {Object}\n   */\n  lunr.Index.prototype.toJSON = function () {\n    var invertedIndex = Object.keys(this.invertedIndex)\n      .sort()\n      .map(function (term) {\n        return [term, this.invertedIndex[term]]\n      }, this)\n  \n    var fieldVectors = Object.keys(this.fieldVectors)\n      .map(function (ref) {\n        return [ref, this.fieldVectors[ref].toJSON()]\n      }, this)\n  \n    return {\n      version: lunr.version,\n      fields: this.fields,\n      fieldVectors: fieldVectors,\n      invertedIndex: invertedIndex,\n      pipeline: this.pipeline.toJSON()\n    }\n  }\n  \n  /**\n   * Loads a previously serialized lunr.Index\n   *\n   * @param {Object} serializedIndex - A previously serialized lunr.Index\n   * @returns {lunr.Index}\n   */\n  lunr.Index.load = function (serializedIndex) {\n    var attrs = {},\n        fieldVectors = {},\n        serializedVectors = serializedIndex.fieldVectors,\n        invertedIndex = {},\n        serializedInvertedIndex = serializedIndex.invertedIndex,\n        tokenSetBuilder = new lunr.TokenSet.Builder,\n        pipeline = lunr.Pipeline.load(serializedIndex.pipeline)\n  \n    if (serializedIndex.version != lunr.version) {\n      lunr.utils.warn(\"Version mismatch when loading serialised index. Current version of lunr '\" + lunr.version + \"' does not match serialized index '\" + serializedIndex.version + \"'\")\n    }\n  \n    for (var i = 0; i < serializedVectors.length; i++) {\n      var tuple = serializedVectors[i],\n          ref = tuple[0],\n          elements = tuple[1]\n  \n      fieldVectors[ref] = new lunr.Vector(elements)\n    }\n  \n    for (var i = 0; i < serializedInvertedIndex.length; i++) {\n      var tuple = serializedInvertedIndex[i],\n          term = tuple[0],\n          posting = tuple[1]\n  \n      tokenSetBuilder.insert(term)\n      invertedIndex[term] = posting\n    }\n  \n    tokenSetBuilder.finish()\n  \n    attrs.fields = serializedIndex.fields\n  \n    attrs.fieldVectors = fieldVectors\n    attrs.invertedIndex = invertedIndex\n    attrs.tokenSet = tokenSetBuilder.root\n    attrs.pipeline = pipeline\n  \n    return new lunr.Index(attrs)\n  }\n  /*!\n   * lunr.Builder\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * lunr.Builder performs indexing on a set of documents and\n   * returns instances of lunr.Index ready for querying.\n   *\n   * All configuration of the index is done via the builder, the\n   * fields to index, the document reference, the text processing\n   * pipeline and document scoring parameters are all set on the\n   * builder before indexing.\n   *\n   * @constructor\n   * @property {string} _ref - Internal reference to the document reference field.\n   * @property {string[]} _fields - Internal reference to the document fields to index.\n   * @property {object} invertedIndex - The inverted index maps terms to document fields.\n   * @property {object} documentTermFrequencies - Keeps track of document term frequencies.\n   * @property {object} documentLengths - Keeps track of the length of documents added to the index.\n   * @property {lunr.tokenizer} tokenizer - Function for splitting strings into tokens for indexing.\n   * @property {lunr.Pipeline} pipeline - The pipeline performs text processing on tokens before indexing.\n   * @property {lunr.Pipeline} searchPipeline - A pipeline for processing search terms before querying the index.\n   * @property {number} documentCount - Keeps track of the total number of documents indexed.\n   * @property {number} _b - A parameter to control field length normalization, setting this to 0 disabled normalization, 1 fully normalizes field lengths, the default value is 0.75.\n   * @property {number} _k1 - A parameter to control how quickly an increase in term frequency results in term frequency saturation, the default value is 1.2.\n   * @property {number} termIndex - A counter incremented for each unique term, used to identify a terms position in the vector space.\n   * @property {array} metadataWhitelist - A list of metadata keys that have been whitelisted for entry in the index.\n   */\n  lunr.Builder = function () {\n    this._ref = \"id\"\n    this._fields = Object.create(null)\n    this._documents = Object.create(null)\n    this.invertedIndex = Object.create(null)\n    this.fieldTermFrequencies = {}\n    this.fieldLengths = {}\n    this.tokenizer = lunr.tokenizer\n    this.pipeline = new lunr.Pipeline\n    this.searchPipeline = new lunr.Pipeline\n    this.documentCount = 0\n    this._b = 0.75\n    this._k1 = 1.2\n    this.termIndex = 0\n    this.metadataWhitelist = []\n  }\n  \n  /**\n   * Sets the document field used as the document reference. Every document must have this field.\n   * The type of this field in the document should be a string, if it is not a string it will be\n   * coerced into a string by calling toString.\n   *\n   * The default ref is 'id'.\n   *\n   * The ref should _not_ be changed during indexing, it should be set before any documents are\n   * added to the index. Changing it during indexing can lead to inconsistent results.\n   *\n   * @param {string} ref - The name of the reference field in the document.\n   */\n  lunr.Builder.prototype.ref = function (ref) {\n    this._ref = ref\n  }\n  \n  /**\n   * A function that is used to extract a field from a document.\n   *\n   * Lunr expects a field to be at the top level of a document, if however the field\n   * is deeply nested within a document an extractor function can be used to extract\n   * the right field for indexing.\n   *\n   * @callback fieldExtractor\n   * @param {object} doc - The document being added to the index.\n   * @returns {?(string|object|object[])} obj - The object that will be indexed for this field.\n   * @example <caption>Extracting a nested field</caption>\n   * function (doc) { return doc.nested.field }\n   */\n  \n  /**\n   * Adds a field to the list of document fields that will be indexed. Every document being\n   * indexed should have this field. Null values for this field in indexed documents will\n   * not cause errors but will limit the chance of that document being retrieved by searches.\n   *\n   * All fields should be added before adding documents to the index. Adding fields after\n   * a document has been indexed will have no effect on already indexed documents.\n   *\n   * Fields can be boosted at build time. This allows terms within that field to have more\n   * importance when ranking search results. Use a field boost to specify that matches within\n   * one field are more important than other fields.\n   *\n   * @param {string} fieldName - The name of a field to index in all documents.\n   * @param {object} attributes - Optional attributes associated with this field.\n   * @param {number} [attributes.boost=1] - Boost applied to all terms within this field.\n   * @param {fieldExtractor} [attributes.extractor] - Function to extract a field from a document.\n   * @throws {RangeError} fieldName cannot contain unsupported characters '/'\n   */\n  lunr.Builder.prototype.field = function (fieldName, attributes) {\n    if (/\\//.test(fieldName)) {\n      throw new RangeError (\"Field '\" + fieldName + \"' contains illegal character '/'\")\n    }\n  \n    this._fields[fieldName] = attributes || {}\n  }\n  \n  /**\n   * A parameter to tune the amount of field length normalisation that is applied when\n   * calculating relevance scores. A value of 0 will completely disable any normalisation\n   * and a value of 1 will fully normalise field lengths. The default is 0.75. Values of b\n   * will be clamped to the range 0 - 1.\n   *\n   * @param {number} number - The value to set for this tuning parameter.\n   */\n  lunr.Builder.prototype.b = function (number) {\n    if (number < 0) {\n      this._b = 0\n    } else if (number > 1) {\n      this._b = 1\n    } else {\n      this._b = number\n    }\n  }\n  \n  /**\n   * A parameter that controls the speed at which a rise in term frequency results in term\n   * frequency saturation. The default value is 1.2. Setting this to a higher value will give\n   * slower saturation levels, a lower value will result in quicker saturation.\n   *\n   * @param {number} number - The value to set for this tuning parameter.\n   */\n  lunr.Builder.prototype.k1 = function (number) {\n    this._k1 = number\n  }\n  \n  /**\n   * Adds a document to the index.\n   *\n   * Before adding fields to the index the index should have been fully setup, with the document\n   * ref and all fields to index already having been specified.\n   *\n   * The document must have a field name as specified by the ref (by default this is 'id') and\n   * it should have all fields defined for indexing, though null or undefined values will not\n   * cause errors.\n   *\n   * Entire documents can be boosted at build time. Applying a boost to a document indicates that\n   * this document should rank higher in search results than other documents.\n   *\n   * @param {object} doc - The document to add to the index.\n   * @param {object} attributes - Optional attributes associated with this document.\n   * @param {number} [attributes.boost=1] - Boost applied to all terms within this document.\n   */\n  lunr.Builder.prototype.add = function (doc, attributes) {\n    var docRef = doc[this._ref],\n        fields = Object.keys(this._fields)\n  \n    this._documents[docRef] = attributes || {}\n    this.documentCount += 1\n  \n    for (var i = 0; i < fields.length; i++) {\n      var fieldName = fields[i],\n          extractor = this._fields[fieldName].extractor,\n          field = extractor ? extractor(doc) : doc[fieldName],\n          tokens = this.tokenizer(field, {\n            fields: [fieldName]\n          }),\n          terms = this.pipeline.run(tokens),\n          fieldRef = new lunr.FieldRef (docRef, fieldName),\n          fieldTerms = Object.create(null)\n  \n      this.fieldTermFrequencies[fieldRef] = fieldTerms\n      this.fieldLengths[fieldRef] = 0\n  \n      // store the length of this field for this document\n      this.fieldLengths[fieldRef] += terms.length\n  \n      // calculate term frequencies for this field\n      for (var j = 0; j < terms.length; j++) {\n        var term = terms[j]\n  \n        if (fieldTerms[term] == undefined) {\n          fieldTerms[term] = 0\n        }\n  \n        fieldTerms[term] += 1\n  \n        // add to inverted index\n        // create an initial posting if one doesn't exist\n        if (this.invertedIndex[term] == undefined) {\n          var posting = Object.create(null)\n          posting[\"_index\"] = this.termIndex\n          this.termIndex += 1\n  \n          for (var k = 0; k < fields.length; k++) {\n            posting[fields[k]] = Object.create(null)\n          }\n  \n          this.invertedIndex[term] = posting\n        }\n  \n        // add an entry for this term/fieldName/docRef to the invertedIndex\n        if (this.invertedIndex[term][fieldName][docRef] == undefined) {\n          this.invertedIndex[term][fieldName][docRef] = Object.create(null)\n        }\n  \n        // store all whitelisted metadata about this token in the\n        // inverted index\n        for (var l = 0; l < this.metadataWhitelist.length; l++) {\n          var metadataKey = this.metadataWhitelist[l],\n              metadata = term.metadata[metadataKey]\n  \n          if (this.invertedIndex[term][fieldName][docRef][metadataKey] == undefined) {\n            this.invertedIndex[term][fieldName][docRef][metadataKey] = []\n          }\n  \n          this.invertedIndex[term][fieldName][docRef][metadataKey].push(metadata)\n        }\n      }\n  \n    }\n  }\n  \n  /**\n   * Calculates the average document length for this index\n   *\n   * @private\n   */\n  lunr.Builder.prototype.calculateAverageFieldLengths = function () {\n  \n    var fieldRefs = Object.keys(this.fieldLengths),\n        numberOfFields = fieldRefs.length,\n        accumulator = {},\n        documentsWithField = {}\n  \n    for (var i = 0; i < numberOfFields; i++) {\n      var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\n          field = fieldRef.fieldName\n  \n      documentsWithField[field] || (documentsWithField[field] = 0)\n      documentsWithField[field] += 1\n  \n      accumulator[field] || (accumulator[field] = 0)\n      accumulator[field] += this.fieldLengths[fieldRef]\n    }\n  \n    var fields = Object.keys(this._fields)\n  \n    for (var i = 0; i < fields.length; i++) {\n      var fieldName = fields[i]\n      accumulator[fieldName] = accumulator[fieldName] / documentsWithField[fieldName]\n    }\n  \n    this.averageFieldLength = accumulator\n  }\n  \n  /**\n   * Builds a vector space model of every document using lunr.Vector\n   *\n   * @private\n   */\n  lunr.Builder.prototype.createFieldVectors = function () {\n    var fieldVectors = {},\n        fieldRefs = Object.keys(this.fieldTermFrequencies),\n        fieldRefsLength = fieldRefs.length,\n        termIdfCache = Object.create(null)\n  \n    for (var i = 0; i < fieldRefsLength; i++) {\n      var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\n          fieldName = fieldRef.fieldName,\n          fieldLength = this.fieldLengths[fieldRef],\n          fieldVector = new lunr.Vector,\n          termFrequencies = this.fieldTermFrequencies[fieldRef],\n          terms = Object.keys(termFrequencies),\n          termsLength = terms.length\n  \n  \n      var fieldBoost = this._fields[fieldName].boost || 1,\n          docBoost = this._documents[fieldRef.docRef].boost || 1\n  \n      for (var j = 0; j < termsLength; j++) {\n        var term = terms[j],\n            tf = termFrequencies[term],\n            termIndex = this.invertedIndex[term]._index,\n            idf, score, scoreWithPrecision\n  \n        if (termIdfCache[term] === undefined) {\n          idf = lunr.idf(this.invertedIndex[term], this.documentCount)\n          termIdfCache[term] = idf\n        } else {\n          idf = termIdfCache[term]\n        }\n  \n        score = idf * ((this._k1 + 1) * tf) / (this._k1 * (1 - this._b + this._b * (fieldLength / this.averageFieldLength[fieldName])) + tf)\n        score *= fieldBoost\n        score *= docBoost\n        scoreWithPrecision = Math.round(score * 1000) / 1000\n        // Converts 1.23456789 to 1.234.\n        // Reducing the precision so that the vectors take up less\n        // space when serialised. Doing it now so that they behave\n        // the same before and after serialisation. Also, this is\n        // the fastest approach to reducing a number's precision in\n        // JavaScript.\n  \n        fieldVector.insert(termIndex, scoreWithPrecision)\n      }\n  \n      fieldVectors[fieldRef] = fieldVector\n    }\n  \n    this.fieldVectors = fieldVectors\n  }\n  \n  /**\n   * Creates a token set of all tokens in the index using lunr.TokenSet\n   *\n   * @private\n   */\n  lunr.Builder.prototype.createTokenSet = function () {\n    this.tokenSet = lunr.TokenSet.fromArray(\n      Object.keys(this.invertedIndex).sort()\n    )\n  }\n  \n  /**\n   * Builds the index, creating an instance of lunr.Index.\n   *\n   * This completes the indexing process and should only be called\n   * once all documents have been added to the index.\n   *\n   * @returns {lunr.Index}\n   */\n  lunr.Builder.prototype.build = function () {\n    this.calculateAverageFieldLengths()\n    this.createFieldVectors()\n    this.createTokenSet()\n  \n    return new lunr.Index({\n      invertedIndex: this.invertedIndex,\n      fieldVectors: this.fieldVectors,\n      tokenSet: this.tokenSet,\n      fields: Object.keys(this._fields),\n      pipeline: this.searchPipeline\n    })\n  }\n  \n  /**\n   * Applies a plugin to the index builder.\n   *\n   * A plugin is a function that is called with the index builder as its context.\n   * Plugins can be used to customise or extend the behaviour of the index\n   * in some way. A plugin is just a function, that encapsulated the custom\n   * behaviour that should be applied when building the index.\n   *\n   * The plugin function will be called with the index builder as its argument, additional\n   * arguments can also be passed when calling use. The function will be called\n   * with the index builder as its context.\n   *\n   * @param {Function} plugin The plugin to apply.\n   */\n  lunr.Builder.prototype.use = function (fn) {\n    var args = Array.prototype.slice.call(arguments, 1)\n    args.unshift(this)\n    fn.apply(this, args)\n  }\n  /**\n   * Contains and collects metadata about a matching document.\n   * A single instance of lunr.MatchData is returned as part of every\n   * lunr.Index~Result.\n   *\n   * @constructor\n   * @param {string} term - The term this match data is associated with\n   * @param {string} field - The field in which the term was found\n   * @param {object} metadata - The metadata recorded about this term in this field\n   * @property {object} metadata - A cloned collection of metadata associated with this document.\n   * @see {@link lunr.Index~Result}\n   */\n  lunr.MatchData = function (term, field, metadata) {\n    var clonedMetadata = Object.create(null),\n        metadataKeys = Object.keys(metadata || {})\n  \n    // Cloning the metadata to prevent the original\n    // being mutated during match data combination.\n    // Metadata is kept in an array within the inverted\n    // index so cloning the data can be done with\n    // Array#slice\n    for (var i = 0; i < metadataKeys.length; i++) {\n      var key = metadataKeys[i]\n      clonedMetadata[key] = metadata[key].slice()\n    }\n  \n    this.metadata = Object.create(null)\n  \n    if (term !== undefined) {\n      this.metadata[term] = Object.create(null)\n      this.metadata[term][field] = clonedMetadata\n    }\n  }\n  \n  /**\n   * An instance of lunr.MatchData will be created for every term that matches a\n   * document. However only one instance is required in a lunr.Index~Result. This\n   * method combines metadata from another instance of lunr.MatchData with this\n   * objects metadata.\n   *\n   * @param {lunr.MatchData} otherMatchData - Another instance of match data to merge with this one.\n   * @see {@link lunr.Index~Result}\n   */\n  lunr.MatchData.prototype.combine = function (otherMatchData) {\n    var terms = Object.keys(otherMatchData.metadata)\n  \n    for (var i = 0; i < terms.length; i++) {\n      var term = terms[i],\n          fields = Object.keys(otherMatchData.metadata[term])\n  \n      if (this.metadata[term] == undefined) {\n        this.metadata[term] = Object.create(null)\n      }\n  \n      for (var j = 0; j < fields.length; j++) {\n        var field = fields[j],\n            keys = Object.keys(otherMatchData.metadata[term][field])\n  \n        if (this.metadata[term][field] == undefined) {\n          this.metadata[term][field] = Object.create(null)\n        }\n  \n        for (var k = 0; k < keys.length; k++) {\n          var key = keys[k]\n  \n          if (this.metadata[term][field][key] == undefined) {\n            this.metadata[term][field][key] = otherMatchData.metadata[term][field][key]\n          } else {\n            this.metadata[term][field][key] = this.metadata[term][field][key].concat(otherMatchData.metadata[term][field][key])\n          }\n  \n        }\n      }\n    }\n  }\n  \n  /**\n   * Add metadata for a term/field pair to this instance of match data.\n   *\n   * @param {string} term - The term this match data is associated with\n   * @param {string} field - The field in which the term was found\n   * @param {object} metadata - The metadata recorded about this term in this field\n   */\n  lunr.MatchData.prototype.add = function (term, field, metadata) {\n    if (!(term in this.metadata)) {\n      this.metadata[term] = Object.create(null)\n      this.metadata[term][field] = metadata\n      return\n    }\n  \n    if (!(field in this.metadata[term])) {\n      this.metadata[term][field] = metadata\n      return\n    }\n  \n    var metadataKeys = Object.keys(metadata)\n  \n    for (var i = 0; i < metadataKeys.length; i++) {\n      var key = metadataKeys[i]\n  \n      if (key in this.metadata[term][field]) {\n        this.metadata[term][field][key] = this.metadata[term][field][key].concat(metadata[key])\n      } else {\n        this.metadata[term][field][key] = metadata[key]\n      }\n    }\n  }\n  /**\n   * A lunr.Query provides a programmatic way of defining queries to be performed\n   * against a {@link lunr.Index}.\n   *\n   * Prefer constructing a lunr.Query using the {@link lunr.Index#query} method\n   * so the query object is pre-initialized with the right index fields.\n   *\n   * @constructor\n   * @property {lunr.Query~Clause[]} clauses - An array of query clauses.\n   * @property {string[]} allFields - An array of all available fields in a lunr.Index.\n   */\n  lunr.Query = function (allFields) {\n    this.clauses = []\n    this.allFields = allFields\n  }\n  \n  /**\n   * Constants for indicating what kind of automatic wildcard insertion will be used when constructing a query clause.\n   *\n   * This allows wildcards to be added to the beginning and end of a term without having to manually do any string\n   * concatenation.\n   *\n   * The wildcard constants can be bitwise combined to select both leading and trailing wildcards.\n   *\n   * @constant\n   * @default\n   * @property {number} wildcard.NONE - The term will have no wildcards inserted, this is the default behaviour\n   * @property {number} wildcard.LEADING - Prepend the term with a wildcard, unless a leading wildcard already exists\n   * @property {number} wildcard.TRAILING - Append a wildcard to the term, unless a trailing wildcard already exists\n   * @see lunr.Query~Clause\n   * @see lunr.Query#clause\n   * @see lunr.Query#term\n   * @example <caption>query term with trailing wildcard</caption>\n   * query.term('foo', { wildcard: lunr.Query.wildcard.TRAILING })\n   * @example <caption>query term with leading and trailing wildcard</caption>\n   * query.term('foo', {\n   *   wildcard: lunr.Query.wildcard.LEADING | lunr.Query.wildcard.TRAILING\n   * })\n   */\n  \n  lunr.Query.wildcard = new String (\"*\")\n  lunr.Query.wildcard.NONE = 0\n  lunr.Query.wildcard.LEADING = 1\n  lunr.Query.wildcard.TRAILING = 2\n  \n  /**\n   * Constants for indicating what kind of presence a term must have in matching documents.\n   *\n   * @constant\n   * @enum {number}\n   * @see lunr.Query~Clause\n   * @see lunr.Query#clause\n   * @see lunr.Query#term\n   * @example <caption>query term with required presence</caption>\n   * query.term('foo', { presence: lunr.Query.presence.REQUIRED })\n   */\n  lunr.Query.presence = {\n    /**\n     * Term's presence in a document is optional, this is the default value.\n     */\n    OPTIONAL: 1,\n  \n    /**\n     * Term's presence in a document is required, documents that do not contain\n     * this term will not be returned.\n     */\n    REQUIRED: 2,\n  \n    /**\n     * Term's presence in a document is prohibited, documents that do contain\n     * this term will not be returned.\n     */\n    PROHIBITED: 3\n  }\n  \n  /**\n   * A single clause in a {@link lunr.Query} contains a term and details on how to\n   * match that term against a {@link lunr.Index}.\n   *\n   * @typedef {Object} lunr.Query~Clause\n   * @property {string[]} fields - The fields in an index this clause should be matched against.\n   * @property {number} [boost=1] - Any boost that should be applied when matching this clause.\n   * @property {number} [editDistance] - Whether the term should have fuzzy matching applied, and how fuzzy the match should be.\n   * @property {boolean} [usePipeline] - Whether the term should be passed through the search pipeline.\n   * @property {number} [wildcard=lunr.Query.wildcard.NONE] - Whether the term should have wildcards appended or prepended.\n   * @property {number} [presence=lunr.Query.presence.OPTIONAL] - The terms presence in any matching documents.\n   */\n  \n  /**\n   * Adds a {@link lunr.Query~Clause} to this query.\n   *\n   * Unless the clause contains the fields to be matched all fields will be matched. In addition\n   * a default boost of 1 is applied to the clause.\n   *\n   * @param {lunr.Query~Clause} clause - The clause to add to this query.\n   * @see lunr.Query~Clause\n   * @returns {lunr.Query}\n   */\n  lunr.Query.prototype.clause = function (clause) {\n    if (!('fields' in clause)) {\n      clause.fields = this.allFields\n    }\n  \n    if (!('boost' in clause)) {\n      clause.boost = 1\n    }\n  \n    if (!('usePipeline' in clause)) {\n      clause.usePipeline = true\n    }\n  \n    if (!('wildcard' in clause)) {\n      clause.wildcard = lunr.Query.wildcard.NONE\n    }\n  \n    if ((clause.wildcard & lunr.Query.wildcard.LEADING) && (clause.term.charAt(0) != lunr.Query.wildcard)) {\n      clause.term = \"*\" + clause.term\n    }\n  \n    if ((clause.wildcard & lunr.Query.wildcard.TRAILING) && (clause.term.slice(-1) != lunr.Query.wildcard)) {\n      clause.term = \"\" + clause.term + \"*\"\n    }\n  \n    if (!('presence' in clause)) {\n      clause.presence = lunr.Query.presence.OPTIONAL\n    }\n  \n    this.clauses.push(clause)\n  \n    return this\n  }\n  \n  /**\n   * A negated query is one in which every clause has a presence of\n   * prohibited. These queries require some special processing to return\n   * the expected results.\n   *\n   * @returns boolean\n   */\n  lunr.Query.prototype.isNegated = function () {\n    for (var i = 0; i < this.clauses.length; i++) {\n      if (this.clauses[i].presence != lunr.Query.presence.PROHIBITED) {\n        return false\n      }\n    }\n  \n    return true\n  }\n  \n  /**\n   * Adds a term to the current query, under the covers this will create a {@link lunr.Query~Clause}\n   * to the list of clauses that make up this query.\n   *\n   * The term is used as is, i.e. no tokenization will be performed by this method. Instead conversion\n   * to a token or token-like string should be done before calling this method.\n   *\n   * The term will be converted to a string by calling `toString`. Multiple terms can be passed as an\n   * array, each term in the array will share the same options.\n   *\n   * @param {object|object[]} term - The term(s) to add to the query.\n   * @param {object} [options] - Any additional properties to add to the query clause.\n   * @returns {lunr.Query}\n   * @see lunr.Query#clause\n   * @see lunr.Query~Clause\n   * @example <caption>adding a single term to a query</caption>\n   * query.term(\"foo\")\n   * @example <caption>adding a single term to a query and specifying search fields, term boost and automatic trailing wildcard</caption>\n   * query.term(\"foo\", {\n   *   fields: [\"title\"],\n   *   boost: 10,\n   *   wildcard: lunr.Query.wildcard.TRAILING\n   * })\n   * @example <caption>using lunr.tokenizer to convert a string to tokens before using them as terms</caption>\n   * query.term(lunr.tokenizer(\"foo bar\"))\n   */\n  lunr.Query.prototype.term = function (term, options) {\n    if (Array.isArray(term)) {\n      term.forEach(function (t) { this.term(t, lunr.utils.clone(options)) }, this)\n      return this\n    }\n  \n    var clause = options || {}\n    clause.term = term.toString()\n  \n    this.clause(clause)\n  \n    return this\n  }\n  lunr.QueryParseError = function (message, start, end) {\n    this.name = \"QueryParseError\"\n    this.message = message\n    this.start = start\n    this.end = end\n  }\n  \n  lunr.QueryParseError.prototype = new Error\n  lunr.QueryLexer = function (str) {\n    this.lexemes = []\n    this.str = str\n    this.length = str.length\n    this.pos = 0\n    this.start = 0\n    this.escapeCharPositions = []\n  }\n  \n  lunr.QueryLexer.prototype.run = function () {\n    var state = lunr.QueryLexer.lexText\n  \n    while (state) {\n      state = state(this)\n    }\n  }\n  \n  lunr.QueryLexer.prototype.sliceString = function () {\n    var subSlices = [],\n        sliceStart = this.start,\n        sliceEnd = this.pos\n  \n    for (var i = 0; i < this.escapeCharPositions.length; i++) {\n      sliceEnd = this.escapeCharPositions[i]\n      subSlices.push(this.str.slice(sliceStart, sliceEnd))\n      sliceStart = sliceEnd + 1\n    }\n  \n    subSlices.push(this.str.slice(sliceStart, this.pos))\n    this.escapeCharPositions.length = 0\n  \n    return subSlices.join('')\n  }\n  \n  lunr.QueryLexer.prototype.emit = function (type) {\n    this.lexemes.push({\n      type: type,\n      str: this.sliceString(),\n      start: this.start,\n      end: this.pos\n    })\n  \n    this.start = this.pos\n  }\n  \n  lunr.QueryLexer.prototype.escapeCharacter = function () {\n    this.escapeCharPositions.push(this.pos - 1)\n    this.pos += 1\n  }\n  \n  lunr.QueryLexer.prototype.next = function () {\n    if (this.pos >= this.length) {\n      return lunr.QueryLexer.EOS\n    }\n  \n    var char = this.str.charAt(this.pos)\n    this.pos += 1\n    return char\n  }\n  \n  lunr.QueryLexer.prototype.width = function () {\n    return this.pos - this.start\n  }\n  \n  lunr.QueryLexer.prototype.ignore = function () {\n    if (this.start == this.pos) {\n      this.pos += 1\n    }\n  \n    this.start = this.pos\n  }\n  \n  lunr.QueryLexer.prototype.backup = function () {\n    this.pos -= 1\n  }\n  \n  lunr.QueryLexer.prototype.acceptDigitRun = function () {\n    var char, charCode\n  \n    do {\n      char = this.next()\n      charCode = char.charCodeAt(0)\n    } while (charCode > 47 && charCode < 58)\n  \n    if (char != lunr.QueryLexer.EOS) {\n      this.backup()\n    }\n  }\n  \n  lunr.QueryLexer.prototype.more = function () {\n    return this.pos < this.length\n  }\n  \n  lunr.QueryLexer.EOS = 'EOS'\n  lunr.QueryLexer.FIELD = 'FIELD'\n  lunr.QueryLexer.TERM = 'TERM'\n  lunr.QueryLexer.EDIT_DISTANCE = 'EDIT_DISTANCE'\n  lunr.QueryLexer.BOOST = 'BOOST'\n  lunr.QueryLexer.PRESENCE = 'PRESENCE'\n  \n  lunr.QueryLexer.lexField = function (lexer) {\n    lexer.backup()\n    lexer.emit(lunr.QueryLexer.FIELD)\n    lexer.ignore()\n    return lunr.QueryLexer.lexText\n  }\n  \n  lunr.QueryLexer.lexTerm = function (lexer) {\n    if (lexer.width() > 1) {\n      lexer.backup()\n      lexer.emit(lunr.QueryLexer.TERM)\n    }\n  \n    lexer.ignore()\n  \n    if (lexer.more()) {\n      return lunr.QueryLexer.lexText\n    }\n  }\n  \n  lunr.QueryLexer.lexEditDistance = function (lexer) {\n    lexer.ignore()\n    lexer.acceptDigitRun()\n    lexer.emit(lunr.QueryLexer.EDIT_DISTANCE)\n    return lunr.QueryLexer.lexText\n  }\n  \n  lunr.QueryLexer.lexBoost = function (lexer) {\n    lexer.ignore()\n    lexer.acceptDigitRun()\n    lexer.emit(lunr.QueryLexer.BOOST)\n    return lunr.QueryLexer.lexText\n  }\n  \n  lunr.QueryLexer.lexEOS = function (lexer) {\n    if (lexer.width() > 0) {\n      lexer.emit(lunr.QueryLexer.TERM)\n    }\n  }\n  \n  // This matches the separator used when tokenising fields\n  // within a document. These should match otherwise it is\n  // not possible to search for some tokens within a document.\n  //\n  // It is possible for the user to change the separator on the\n  // tokenizer so it _might_ clash with any other of the special\n  // characters already used within the search string, e.g. :.\n  //\n  // This means that it is possible to change the separator in\n  // such a way that makes some words unsearchable using a search\n  // string.\n  lunr.QueryLexer.termSeparator = lunr.tokenizer.separator\n  \n  lunr.QueryLexer.lexText = function (lexer) {\n    while (true) {\n      var char = lexer.next()\n  \n      if (char == lunr.QueryLexer.EOS) {\n        return lunr.QueryLexer.lexEOS\n      }\n  \n      // Escape character is '\\'\n      if (char.charCodeAt(0) == 92) {\n        lexer.escapeCharacter()\n        continue\n      }\n  \n      if (char == \":\") {\n        return lunr.QueryLexer.lexField\n      }\n  \n      if (char == \"~\") {\n        lexer.backup()\n        if (lexer.width() > 0) {\n          lexer.emit(lunr.QueryLexer.TERM)\n        }\n        return lunr.QueryLexer.lexEditDistance\n      }\n  \n      if (char == \"^\") {\n        lexer.backup()\n        if (lexer.width() > 0) {\n          lexer.emit(lunr.QueryLexer.TERM)\n        }\n        return lunr.QueryLexer.lexBoost\n      }\n  \n      // \"+\" indicates term presence is required\n      // checking for length to ensure that only\n      // leading \"+\" are considered\n      if (char == \"+\" && lexer.width() === 1) {\n        lexer.emit(lunr.QueryLexer.PRESENCE)\n        return lunr.QueryLexer.lexText\n      }\n  \n      // \"-\" indicates term presence is prohibited\n      // checking for length to ensure that only\n      // leading \"-\" are considered\n      if (char == \"-\" && lexer.width() === 1) {\n        lexer.emit(lunr.QueryLexer.PRESENCE)\n        return lunr.QueryLexer.lexText\n      }\n  \n      if (char.match(lunr.QueryLexer.termSeparator)) {\n        return lunr.QueryLexer.lexTerm\n      }\n    }\n  }\n  \n  lunr.QueryParser = function (str, query) {\n    this.lexer = new lunr.QueryLexer (str)\n    this.query = query\n    this.currentClause = {}\n    this.lexemeIdx = 0\n  }\n  \n  lunr.QueryParser.prototype.parse = function () {\n    this.lexer.run()\n    this.lexemes = this.lexer.lexemes\n  \n    var state = lunr.QueryParser.parseClause\n  \n    while (state) {\n      state = state(this)\n    }\n  \n    return this.query\n  }\n  \n  lunr.QueryParser.prototype.peekLexeme = function () {\n    return this.lexemes[this.lexemeIdx]\n  }\n  \n  lunr.QueryParser.prototype.consumeLexeme = function () {\n    var lexeme = this.peekLexeme()\n    this.lexemeIdx += 1\n    return lexeme\n  }\n  \n  lunr.QueryParser.prototype.nextClause = function () {\n    var completedClause = this.currentClause\n    this.query.clause(completedClause)\n    this.currentClause = {}\n  }\n  \n  lunr.QueryParser.parseClause = function (parser) {\n    var lexeme = parser.peekLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    switch (lexeme.type) {\n      case lunr.QueryLexer.PRESENCE:\n        return lunr.QueryParser.parsePresence\n      case lunr.QueryLexer.FIELD:\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm\n      default:\n        var errorMessage = \"expected either a field or a term, found \" + lexeme.type\n  \n        if (lexeme.str.length >= 1) {\n          errorMessage += \" with value '\" + lexeme.str + \"'\"\n        }\n  \n        throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parsePresence = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    switch (lexeme.str) {\n      case \"-\":\n        parser.currentClause.presence = lunr.Query.presence.PROHIBITED\n        break\n      case \"+\":\n        parser.currentClause.presence = lunr.Query.presence.REQUIRED\n        break\n      default:\n        var errorMessage = \"unrecognised presence operator'\" + lexeme.str + \"'\"\n        throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      var errorMessage = \"expecting term or field, found nothing\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.FIELD:\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm\n      default:\n        var errorMessage = \"expecting term or field, found '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parseField = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    if (parser.query.allFields.indexOf(lexeme.str) == -1) {\n      var possibleFields = parser.query.allFields.map(function (f) { return \"'\" + f + \"'\" }).join(', '),\n          errorMessage = \"unrecognised field '\" + lexeme.str + \"', possible fields: \" + possibleFields\n  \n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    parser.currentClause.fields = [lexeme.str]\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      var errorMessage = \"expecting term, found nothing\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm\n      default:\n        var errorMessage = \"expecting term, found '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parseTerm = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    parser.currentClause.term = lexeme.str.toLowerCase()\n  \n    if (lexeme.str.indexOf(\"*\") != -1) {\n      parser.currentClause.usePipeline = false\n    }\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      parser.nextClause()\n      return\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause()\n        return lunr.QueryParser.parseTerm\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause()\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause()\n        return lunr.QueryParser.parsePresence\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parseEditDistance = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    var editDistance = parseInt(lexeme.str, 10)\n  \n    if (isNaN(editDistance)) {\n      var errorMessage = \"edit distance must be numeric\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    parser.currentClause.editDistance = editDistance\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      parser.nextClause()\n      return\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause()\n        return lunr.QueryParser.parseTerm\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause()\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause()\n        return lunr.QueryParser.parsePresence\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parseBoost = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    var boost = parseInt(lexeme.str, 10)\n  \n    if (isNaN(boost)) {\n      var errorMessage = \"boost must be numeric\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    parser.currentClause.boost = boost\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      parser.nextClause()\n      return\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause()\n        return lunr.QueryParser.parseTerm\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause()\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause()\n        return lunr.QueryParser.parsePresence\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n    /**\n     * export the module via AMD, CommonJS or as a browser global\n     * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\n     */\n    ;(function (root, factory) {\n      if (typeof define === 'function' && define.amd) {\n        // AMD. Register as an anonymous module.\n        define(factory)\n      } else if (typeof exports === 'object') {\n        /**\n         * Node. Does not work with strict CommonJS, but\n         * only CommonJS-like enviroments that support module.exports,\n         * like Node.\n         */\n        module.exports = factory()\n      } else {\n        // Browser globals (root is window)\n        root.lunr = factory()\n      }\n    }(this, function () {\n      /**\n       * Just return a value to define the module export.\n       * This example returns an object, but the module\n       * can return a function as the exported value.\n       */\n      return lunr\n    }))\n  })();","document.addEventListener('DOMContentLoaded', function () {\n  var searchButton = document.querySelector('.mdc-icon-button.search')\n  var searchCancelButton = document.querySelector('.mdc-icon-button.search-arrow-back')\n  var searchClearButton = document.querySelector('.mdc-icon-button.search-clear-query')\n\n  function clearSearch() {\n    var searchInput = document.getElementById('search-input')\n    searchInput.value = '';\n    searchInput.dispatchEvent(new KeyboardEvent('keydown')); // trigger rerender of results\n  }\n\n  function enterOrSpacebarPressed(e) {\n    // Need both, 'keyCode' and 'which' to work in all browsers.\n    var code = e.keyCode || e.which;\n    var enterKey = 13;\n    var spaceKey = 32;\n\n    return (code === enterKey || code === spaceKey);\n  }\n\n  function toggleSearch() {\n    var mainContainer = document.querySelector('main')\n    var navContainer = document.querySelector('div.nav-container')\n    var searchResult = document.querySelector('.search-result-dropdown-menu')\n    var toolbarContainer = document.querySelector('.toolbar')\n    if(searchResult.classList.contains('hide')){\n      searchResult.classList.remove('hide')\n      mainContainer.classList.add('hide')\n      navContainer.classList.add('hide')\n      toolbarContainer.classList.add('hide')\n    } else{\n      searchResult.classList.add('hide')\n      mainContainer.classList.remove('hide')\n\n      // Toolbar should stay hidden on desktop and navbar should stay hidden on mobile.\n      if (window.innerWidth > 1024) {\n        navContainer.classList.remove('hide')\n      } else {\n        toolbarContainer.classList.remove('hide')\n      }\n    }\n\n    var regularTopBar = document.querySelector('.mdc-top-app-bar__row')\n    var searchTopBar = document.querySelector('.mdc-top-app-bar__row.sdp-top-app-bar__search')\n    if(regularTopBar.classList.contains('hide')){\n      regularTopBar.classList.remove('hide')\n      searchTopBar.classList.add('hide')\n    } else{\n      regularTopBar.classList.add('hide')\n      searchTopBar.classList.remove('hide')\n    }\n  }\n\n  // Add event listeners to search icon\n  searchButton.addEventListener('click', toggleSearch)\n  searchButton.addEventListener('keypress', function (e) {\n    if (enterOrSpacebarPressed(e)) {\n      toggleSearch()\n    }\n  })\n  if ('ontouchstart' in window) {\n    searchButton.addEventListener('ontouchstart', toggleSearch)\n  }\n\n  // Add event listeners to search back/cancel icon\n  searchCancelButton.addEventListener('click', toggleSearch)\n  searchCancelButton.addEventListener('keypress', function (e) {\n    if (enterOrSpacebarPressed(e)) {\n      toggleSearch()\n    }\n  })\n  if ('ontouchstart' in window) {\n    searchCancelButton.addEventListener('ontouchstart', toggleSearch)\n  }\n\n  // Add event listeners to clear search button\n  searchClearButton.addEventListener('click', clearSearch)\n  searchClearButton.addEventListener('keypress', function (e) {\n    if (enterOrSpacebarPressed(e)) {\n      clearSearch()\n    }\n  })\n  if ('ontouchstart' in window) {\n    searchClearButton.addEventListener('ontouchstart', clearSearch)\n  }\n});\n\n\n/* eslint-env browser */\nwindow.antoraLunr = (function (lunr) {\n  var searchInput = document.getElementById('search-input')\n  var searchResult = document.createElement('div')\n  var body = document.querySelector('.body')\n  searchResult.classList.add('search-result-dropdown-menu')\n  searchResult.classList.add('hide')\n  body.insertBefore(searchResult, body.firstChild)\n\n  function highlightText (doc, position) {\n    var hits = []\n    var start = position[0]\n    var length = position[1]\n\n    var text = doc.text\n    var highlightSpan = document.createElement('span')\n    highlightSpan.classList.add('search-result-highlight')\n    highlightSpan.innerText = text.substr(start, length)\n\n    var end = start + length\n    var textEnd = text.length - 1\n    var contextOffset = 15\n    var contextAfter = end + contextOffset > textEnd ? textEnd : end + contextOffset\n    var contextBefore = start - contextOffset < 0 ? 0 : start - contextOffset\n    if (start === 0 && end === textEnd) {\n      hits.push(highlightSpan)\n    } else if (start === 0) {\n      hits.push(highlightSpan)\n      hits.push(document.createTextNode(text.substr(end, contextAfter)))\n    } else if (end === textEnd) {\n      hits.push(document.createTextNode(text.substr(0, start)))\n      hits.push(highlightSpan)\n    } else {\n      hits.push(document.createTextNode('...' + text.substr(contextBefore, start - contextBefore)))\n      hits.push(highlightSpan)\n      hits.push(document.createTextNode(text.substr(end, contextAfter - end) + '...'))\n    }\n    return hits\n  }\n\n  function highlightTitle (hash, doc, position) {\n    var hits = []\n    var start = position[0]\n    var length = position[1]\n\n    var highlightSpan = document.createElement('span')\n    highlightSpan.classList.add('search-result-highlight')\n    var title\n    if (hash) {\n      title = doc.titles.filter(function (item) {\n        return item.id === hash\n      })[0].text\n    } else {\n      title = doc.title\n    }\n    highlightSpan.innerText = title.substr(start, length)\n\n    var end = start + length\n    var titleEnd = title.length - 1\n    if (start === 0 && end === titleEnd) {\n      hits.push(highlightSpan)\n    } else if (start === 0) {\n      hits.push(highlightSpan)\n      hits.push(document.createTextNode(title.substr(length, titleEnd)))\n    } else if (end === titleEnd) {\n      hits.push(document.createTextNode(title.substr(0, start)))\n      hits.push(highlightSpan)\n    } else {\n      hits.push(document.createTextNode(title.substr(0, start)))\n      hits.push(highlightSpan)\n      hits.push(document.createTextNode(title.substr(end, titleEnd)))\n    }\n    return hits\n  }\n\n  function highlightHit (metadata, hash, doc) {\n    var hits = []\n    for (var token in metadata) {\n      var fields = metadata[token]\n      for (var field in fields) {\n        var positions = fields[field]\n        if (positions.position) {\n          var position = positions.position[0] // only higlight the first match\n          if (field === 'title') {\n            hits = highlightTitle(hash, doc, position)\n          } else if (field === 'text') {\n            hits = highlightText(doc, position)\n          }\n        }\n      }\n    }\n    return hits\n  }\n\n  function createSearchResult(result, store, searchResultDataset) {\n    result.forEach(function (item) {\n      var url = item.ref\n      var hash\n      if (url.includes('#')) {\n        hash = url.substring(url.indexOf('#') + 1)\n        url = url.replace('#' + hash, '')\n      }\n      var doc = store[url]\n      var metadata = item.matchData.metadata\n      var hits = highlightHit(metadata, hash, doc)\n      searchResultDataset.appendChild(createSearchResultItem(doc, item, hits))\n    })\n  }\n\n  function createSearchResultItem (doc, item, hits) {\n    var documentTitle = document.createElement('div')\n    documentTitle.classList.add('search-result-document-title')\n    documentTitle.innerText = doc.title\n    var documentHit = document.createElement('div')\n    documentHit.classList.add('search-result-document-hit')\n    var documentHitLink = document.createElement('a')\n    documentHitLink.href = item.ref\n    documentHit.appendChild(documentHitLink)\n    hits.forEach(function (hit) {\n      documentHitLink.appendChild(hit)\n    })\n    var searchResultItem = document.createElement('div')\n    searchResultItem.classList.add('search-result-item')\n    searchResultItem.appendChild(documentTitle)\n    searchResultItem.appendChild(documentHit)\n    return searchResultItem\n  }\n\n  function createNoResult (text) {\n    var searchResultItem = document.createElement('div')\n    searchResultItem.classList.add('search-result-item')\n    var documentHit = document.createElement('div')\n    documentHit.classList.add('search-result-document-hit')\n    var message = document.createElement('strong')\n    message.innerText = 'No results found for query \"' + text + '\"'\n    documentHit.appendChild(message)\n    searchResultItem.appendChild(documentHit)\n    return searchResultItem\n  }\n\n  function search (index, text) {\n    // execute an exact match search\n    var result = index.search(text)\n    if (result.length > 0) {\n      return result\n    }\n    // no result, use a begins with search\n    result = index.search(text + '*')\n    if (result.length > 0) {\n      return result\n    }\n    // no result, use a contains search\n    result = index.search('*' + text + '*')\n    return result\n  }\n\n  function searchIndex (index, store, text) {\n    // reset search result\n    while (searchResult.firstChild) {\n      searchResult.removeChild(searchResult.firstChild)\n    }\n    if (text.trim() === '') {\n      return\n    }\n    var result = search(index, text)\n    var searchResultDataset = document.createElement('div')\n    searchResultDataset.classList.add('search-result-dataset')\n    searchResult.appendChild(searchResultDataset)\n    if (result.length > 0) {\n      createSearchResult(result, store, searchResultDataset)\n    } else {\n      searchResultDataset.appendChild(createNoResult(text))\n    }\n  }\n\n  function debounce (func, wait, immediate) {\n    var timeout\n    return function () {\n      var context = this\n      var args = arguments\n      var later = function () {\n        timeout = null\n        if (!immediate) func.apply(context, args)\n      }\n      var callNow = immediate && !timeout\n      clearTimeout(timeout)\n      timeout = setTimeout(later, wait)\n      if (callNow) func.apply(context, args)\n    }\n  }\n\n  function init (data) {\n    var index = Object.assign({index: lunr.Index.load(data.index), store: data.store})\n    var search = debounce(function () {\n      searchIndex(index.index, index.store, searchInput.value)\n    }, 100)\n    // TODO listen to blur, focus and input events\n    searchInput.addEventListener('keydown', search)\n  }\n\n  return {\n    init: init,\n  }\n})(window.lunr)\n"]}